-- MySQL dump 10.13  Distrib 8.0.20, for Win64 (x86_64)
--
-- Host: localhost    Database: vr_test_database
-- ------------------------------------------------------
-- Server version	8.0.20

/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!50503 SET NAMES utf8 */;
/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;
/*!40103 SET TIME_ZONE='+00:00' */;
/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;
/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;
/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;

--
-- Table structure for table `technique_image`
--

DROP TABLE IF EXISTS `technique_image`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `technique_image` (
  `id` int NOT NULL AUTO_INCREMENT,
  `technique_id` int NOT NULL,
  `image` varchar(255) NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=155 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `technique_image`
--

LOCK TABLES `technique_image` WRITE;
/*!40000 ALTER TABLE `technique_image` DISABLE KEYS */;
INSERT INTO `technique_image` VALUES (1,1,'/images/Virtual Hand/1.png'),(2,2,'/images/PRISM/1.png'),(3,2,'/images/PRISM/2.png'),(4,3,'/images/DIOD/1.png'),(5,4,'/images/Hook/1.png'),(6,5,'/images/Starfish/1.png'),(7,5,'/images/Starfish/2.png'),(8,6,'/images/3D Bubble Cursor/1.png'),(9,6,'/images/3D Bubble Cursor/2.png'),(10,6,'/images/3D Bubble Cursor/3.png'),(11,7,'/images/VHGM/1.png'),(12,7,'/images/VHGM/2.png'),(13,8,'/images/Select Ahead/1.png'),(14,11,'/images/Go-Go/1.png'),(15,13,'/images/Go-Go + PRISM/1.png'),(16,13,'/images/Go-Go + PRISM/2.png'),(17,14,'/images/Go-Go + Follow-Me/1.png'),(18,17,'/images/Spindle/1.png'),(19,17,'/images/Spindle/2.png'),(20,18,'/images/Spindle + Wheel/1.png'),(21,18,'/images/Spindle/2.png'),(22,18,'/images/Spindle/2.png'),(23,19,'/images/World-in-Miniature/1.png'),(24,19,'/images/World-in-Miniature/2.png'),(25,19,'/images/World-in-Miniature/3.png'),(26,20,'/images/SSWIM/1.png'),(27,21,'/images/SSWIM+S/1.png'),(28,21,'/images/SSWIM+S/2.png'),(29,22,'/images/Third Arm/1.png'),(30,22,'/images/Third Arm/2.png'),(31,23,'/images/Third Arm/1.png'),(32,23,'/images/Third Arm/2.png'),(33,24,'/images/Third Arm/1.png'),(34,24,'/images/Third Arm/2.png'),(35,25,'/images/Crank Handle/1.png'),(36,25,'/images/Crank Handle/2.png'),(37,26,'/images/Hover/1.png'),(38,27,'/images/Hover/1.png'),(39,28,'/images/Push/1.png'),(40,29,'/images/Push/1.png'),(41,30,'/images/Grab-And-Carry-And-Scale/1.png'),(42,30,'/images/Grab-And-Carry-And-Scale/2.png'),(43,31,'/images/Virtual Hand Finger-based/1.png'),(44,32,'/images/Rigid-Body Fingers/1.png'),(45,32,'/images/Rigid-Body Fingers/2.png'),(46,33,'/images/Intent Driven Selection/1.png'),(47,33,'/images/Intent Driven Selection/2.png'),(48,34,'/images/Extendo Hands/1.png'),(49,34,'/images/Extendo Hands/2.png'),(50,34,'/images/Extendo Hands/3.png'),(51,35,'/images/Crank Handle/1.png'),(52,35,'/images/Crank Handle/2.png'),(53,36,'/images/Knob/1.png'),(54,36,'/images/Knob/2.png'),(55,36,'/images/Knob/3.png'),(56,37,'/images/Voodoo Dolls/1.png'),(57,37,'/images/Voodoo Dolls/2.png'),(58,37,'/images/Voodoo Dolls/3.png'),(59,39,'/images/Handle-Bar/1.png'),(60,39,'/images/Handle-Bar/2.png'),(61,39,'/images/Handle-Bar/3.png'),(62,40,'/images/Slide-And-Turn/1.png'),(63,43,'/images/6-DOF Hand/1.png'),(64,50,'/images/3-DOF Hand/1.png'),(65,51,'/images/Air TRS/1.png'),(66,52,'/images/Grab-And-Twirl/1.png'),(67,53,'/images/Automatic Adjustments/1.png'),(68,53,'/images/Automatic Adjustments/2.png'),(69,53,'/images/Automatic Adjustments/3.png'),(70,54,'/images/Ray-Casting/1.JPG'),(71,55,'/images/Ray-Casting/1.JPG'),(72,56,'/images/Head-Based Selection/1.png'),(73,57,'/images/Head-Based Selection/1.png'),(74,57,'/images/Head-Based Selection/2.png'),(75,57,'/images/Head-Based Selection/3.png'),(76,58,'/images/Eye-based Selection/1.png'),(77,59,'/images/Eye-based Selection/1.png'),(78,60,'/images/Finite Ray-Casting/1.png'),(79,62,'/images/Image-Plane Pointing/1.png'),(80,62,'/images/Image-Plane Pointing/2.png'),(81,62,'/images/Image-Plane Pointing/3.png'),(82,63,'/images/Depth Ray/1.png'),(83,64,'/images/Lock Ray/1.png'),(84,65,'/images/Flower Ray/1.png'),(85,66,'/images/Smart Ray/1.png'),(86,68,'/images/Sticky Ray/1.png'),(87,68,'/images/Sticky Ray/2.png'),(88,69,'/images/VOTE/1.png'),(89,71,'/images/Adaptive Pointing/1.png'),(90,72,'/images/Smoothed Pointing/1.png'),(91,73,'/images/ARM/1.png'),(92,74,'/images/Discrete Zoom/1.png'),(93,75,'/images/Continuous Zoom/1.png'),(94,76,'/images/Summoning Selection/1.png'),(95,76,'/images/Summoning Selection/2.png'),(96,76,'/images/Summoning Selection/3.png'),(97,77,'/images/EZCursorVR/1.png'),(98,78,'/images/RayCursor/1.png'),(99,78,'/images/RayCursor/2.png'),(100,79,'/images/Dynamic Scaling/1.png'),(101,80,'/images/Forced Disocclusion/1.png'),(102,81,'/images/Mesh-Grab/1.png'),(103,82,'/images/Arcball-3D/1.png'),(104,83,'/images/Framing Hands/1.png'),(105,84,'/images/iSith/1.png'),(106,84,'/images/iSith/2.png'),(107,84,'/images/iSith/3.png'),(108,84,'/images/iSith/4.png'),(109,85,'/images/Bimanual Fishing Reel + Scale/1.png'),(110,85,'/images/Bimanual Fishing Reel + Scale/2.png'),(111,86,'/images/Flexible Pointer/1.png'),(112,87,'/images/Raycasting from the eye/1.png'),(113,88,'/images/Flashlight/1.png'),(114,88,'/images/Flashlight/2.png'),(115,89,'/images/IntenSelect/1.png'),(116,89,'/images/IntenSelect/2.png'),(117,90,'/images/Guidance Ray/1.png'),(118,91,'/images/Shadow Cone Selection/1.png'),(119,92,'/images/Enhanced Cone Selection/1.png'),(120,93,'/images/Aperture Selection/1.png'),(121,94,'/images/Precious/1.png'),(122,95,'/images/Marker Cone/1.png'),(123,96,'/images/Menu Cone/1.png'),(124,97,'/images/SenseShapes/1.png'),(125,98,'/images/Probabilistic Pointing/1.png'),(126,99,'/images/SQUAD/1.png'),(127,99,'/images/SQUAD/2.png'),(128,100,'/images/Expand/1.png'),(129,100,'/images/Expand/2.png'),(130,100,'/images/Expand/3.png'),(131,100,'/images/Expand/4.png'),(132,101,'/images/Action-At-A-Distance/1.png'),(133,102,'/images/Scaled HOMER/3.png'),(134,102,'/images/Scaled HOMER/4.png'),(135,103,'/images/Scaled HOMER/3.png'),(136,103,'/images/Scaled HOMER/4.png'),(137,104,'/images/Scaled HOMER/1.png'),(138,104,'/images/Scaled HOMER/2.png'),(139,104,'/images/Scaled HOMER/3.png'),(140,104,'/images/Scaled HOMER/4.png'),(141,105,'/images/Scaled HOMER/1.png'),(142,105,'/images/Scaled HOMER/2.png'),(143,105,'/images/Scaled HOMER/3.png'),(144,105,'/images/Scaled HOMER/4.png'),(145,107,'/images/Seamless Remote/1.png'),(146,107,'/images/Seamless Remote/2.png'),(147,108,'/images/Grasping Object/1.png'),(148,109,'/images/GitDVR-G/1.png'),(149,110,'/images/Precise GITDVR-G/1.png'),(150,111,'/images/Gaze-Supported Mid-Air Gestures/1.png'),(151,112,'/images/Gaze + Pinch/1.png'),(152,113,'/images/Gaze + Pinch/1.png'),(153,114,'/images/Asymmetric Bimanual Gestural Interface/1.png'),(154,114,'/images/Asymmetric Bimanual Gestural Interface/2.png');
/*!40000 ALTER TABLE `technique_image` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `technique_objective_manipulation`
--

DROP TABLE IF EXISTS `technique_objective_manipulation`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `technique_objective_manipulation` (
  `id` int NOT NULL,
  `technique_id` int DEFAULT NULL,
  `task_type` varchar(45) DEFAULT NULL,
  `distance` varchar(45) DEFAULT NULL,
  `manipulation_amount` varchar(45) DEFAULT NULL,
  `mean_time` float DEFAULT NULL,
  `precision_position` float DEFAULT NULL,
  `precision_rotation` float DEFAULT NULL,
  `precision_scale` float DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `technique_objective_manipulation`
--

LOCK TABLES `technique_objective_manipulation` WRITE;
/*!40000 ALTER TABLE `technique_objective_manipulation` DISABLE KEYS */;
INSERT INTO `technique_objective_manipulation` VALUES (1,17,'Positioning','0,6','Low',4.00637,0.856458,0.82404,0.895917),(2,17,'Positioning','0,6','Medium',7.04854,0.867375,0.834751,0.912167),(3,17,'Positioning','0,6','High',8.02017,0.86325,0.764555,0.937),(4,17,'Rotating','0,6','Low',9.49392,0.847208,0.701016,0.945875),(5,17,'Rotating','0,6','Medium',12.7958,0.790625,0.725572,0.886792),(6,17,'Rotating','0,6','High',12.2364,0.832458,0.805191,0.914708),(7,17,'Scaling','0,6','Low',3.28675,0.823167,0.898484,0.877667),(8,17,'Scaling','0,6','Medium',3.73792,0.778,0.875427,0.819792),(9,17,'Scaling','0,6','High',5.08838,0.753875,0.909195,0.796792),(10,17,'PositioningRotating','0,6','Low',9.00742,0.822125,0.685194,0.895833),(11,17,'PositioningRotating','0,6','Medium',10.7412,0.825875,0.714328,0.908583),(12,17,'PositioningRotating','0,6','High',12.1934,0.800458,0.679379,0.895667),(13,17,'PositioningRotatingScaling','0,6','Low',8.79604,0.806958,0.765226,0.884708),(14,17,'PositioningRotatingScaling','0,6','Medium',10.5439,0.879958,0.674978,0.92375),(15,17,'PositioningRotatingScaling','0,6','High',13.4738,0.740125,0.746152,0.823125),(16,1,'Positioning','0,6','Low',3.70762,0.892667,0.781924,1),(17,1,'Positioning','0,6','Medium',4.61233,0.868125,0.806538,1),(18,1,'Positioning','0,6','High',4.75421,0.870042,0.78349,1),(19,1,'Rotating','0,6','Low',5.75867,0.884667,0.764987,1),(20,1,'Rotating','0,6','Medium',7.16762,0.873042,0.774547,1),(21,1,'Rotating','0,6','High',8.67933,0.887417,0.819031,1),(22,1,'PositioningRotating','0,6','Low',4.98979,0.878583,0.784597,1),(23,1,'PositioningRotating','0,6','Medium',6.11525,0.883292,0.795455,1),(24,1,'PositioningRotating','0,6','High',7.42737,0.88175,0.799811,1),(25,13,'Positioning','0,6','Low',4.77904,0.79675,0.75976,1),(26,13,'Positioning','0,6','Medium',6.63717,0.852458,0.784298,1),(27,13,'Positioning','0,6','High',7.73283,0.745042,0.715036,1),(28,13,'Rotating','0,6','Low',7.65712,0.824833,0.64033,1),(29,13,'Rotating','0,6','Medium',10.9798,0.854208,0.716186,1),(30,13,'Rotating','0,6','High',14.0984,0.861609,0.630959,1),(31,13,'PositioningRotating','0,6','Low',6.05954,0.784958,0.652269,1),(32,13,'PositioningRotating','0,6','Medium',10.1931,0.824708,0.666662,1),(33,13,'PositioningRotating','0,6','High',11.1203,0.843042,0.653512,1),(34,13,'Positioning','3','Low',3.94863,0.60875,0.695848,1),(35,13,'Positioning','3','Medium',4.53717,0.537583,0.682245,1),(36,13,'Positioning','3','High',5.76779,0.648042,0.679,1),(37,13,'Rotating','3','Low',7.03025,0.579667,0.620001,1),(38,13,'Rotating','3','Medium',11.9134,0.674208,0.624622,1),(39,13,'Rotating','3','High',11.6871,0.635333,0.682327,1),(40,13,'PositioningRotating','3','Low',9.79721,0.640958,0.689173,1),(41,13,'PositioningRotating','3','Medium',11.4506,0.603333,0.549485,1),(42,13,'PositioningRotating','3','High',16.9142,0.598217,0.482344,1),(43,13,'Positioning','6','Low',4.43825,0.572958,0.595499,1),(44,13,'Positioning','6','Medium',5.36708,0.551917,0.639119,1),(45,13,'Positioning','6','High',5.27838,0.612792,0.577881,1),(46,13,'Rotating','6','Low',9.64479,0.630083,0.591642,1),(47,13,'Rotating','6','Medium',19.1226,0.576947,0.47552,1),(48,13,'Rotating','6','High',15.118,0.483952,0.595668,1),(49,13,'PositioningRotating','6','Low',11.1033,0.501696,0.603826,1),(50,13,'PositioningRotating','6','Medium',16.192,0.597208,0.569518,1),(51,13,'PositioningRotating','6','High',17.121,0.623227,0.533205,1),(52,85,'Positioning','0,6','Low',3.44129,0.875833,0.987714,1),(53,85,'Positioning','0,6','Medium',5.86621,0.847333,0.924143,0.997792),(54,85,'Positioning','0,6','High',5.294,0.818565,0.987227,1),(55,85,'Rotating','0,6','Low',12.7177,0.808773,0.677227,1),(56,85,'Rotating','0,6','Medium',15.9295,0.86755,0.703919,1),(57,85,'Rotating','0,6','High',15.5266,0.835435,0.674055,1),(58,85,'Scaling','0,6','Low',4.90096,0.869625,0.98867,0.935042),(59,85,'Scaling','0,6','Medium',6.35183,0.832083,0.991019,0.879792),(60,85,'Scaling','0,6','High',6.44212,0.753375,0.977435,0.847667),(61,85,'PositioningRotating','0,6','Low',10.642,0.838087,0.699384,0.993478),(62,85,'PositioningRotating','0,6','Medium',15.882,0.843143,0.663926,1),(63,85,'PositioningRotating','0,6','High',14.6706,0.827913,0.737197,0.996957),(64,85,'PositioningRotatingScaling','0,6','Low',15.2778,0.803826,0.745313,0.906348),(65,85,'PositioningRotatingScaling','0,6','Medium',17.5454,0.818696,0.615337,0.922391),(66,85,'PositioningRotatingScaling','0,6','High',19.8417,0.711095,0.801166,0.837524),(67,85,'Positioning','3','Low',3.10788,0.757417,0.99844,1),(68,85,'Positioning','3','Medium',4.74871,0.420833,0.967938,0.993042),(69,85,'Positioning','3','High',4.00029,0.487083,0.971522,1),(70,85,'Rotating','3','Low',7.90425,0.742042,0.691609,1),(71,85,'Rotating','3','Medium',11.0909,0.770083,0.674951,1),(72,85,'Rotating','3','High',11.8174,0.753208,0.647143,1),(73,85,'Scaling','3','Low',5.17938,0.777083,0.988082,0.908917),(74,85,'Scaling','3','Medium',5.47617,0.751833,0.989714,0.876958),(75,85,'Scaling','3','High',6.76025,0.770667,0.975934,0.886042),(76,85,'PositioningRotating','3','Low',9.00583,0.73775,0.661719,1),(77,85,'PositioningRotating','3','Medium',12.6418,0.534083,0.693052,1),(78,85,'PositioningRotating','3','High',15.3165,0.57075,0.555501,1),(79,85,'PositioningRotatingScaling','3','Low',13.5588,0.708917,0.651187,0.907542),(80,85,'PositioningRotatingScaling','3','Medium',15.0438,0.559167,0.728915,0.91975),(81,85,'PositioningRotatingScaling','3','High',18.1668,0.603348,0.676209,0.907348),(82,85,'Positioning','6','Low',4.02933,0.725958,0.977631,1),(83,85,'Positioning','6','Medium',5.11013,0.572458,0.974963,0.993083),(84,85,'Positioning','6','High',10.2055,0.40325,0.961489,0.990125),(85,85,'Rotating','6','Low',9.13437,0.681304,0.592476,1),(86,85,'Rotating','6','Medium',13.3169,0.661956,0.555618,1),(87,85,'Rotating','6','High',14.1156,0.632048,0.648359,1),(88,85,'Scaling','6','Low',5.59446,0.595167,0.998283,0.817708),(89,85,'Scaling','6','Medium',6.75008,0.704478,0.993759,0.862565),(90,85,'Scaling','6','High',7.23721,0.635625,0.997677,0.844875),(91,85,'PositioningRotating','6','Low',11.2903,0.689636,0.617216,1),(92,85,'PositioningRotating','6','Medium',12.0479,0.523625,0.536389,0.991875),(93,85,'PositioningRotating','6','High',19.4027,0.477105,0.551932,1),(94,85,'PositioningRotatingScaling','6','Low',12.1275,0.616833,0.705193,0.882708),(95,85,'PositioningRotatingScaling','6','Medium',16.3387,0.537458,0.690745,0.867708),(96,85,'PositioningRotatingScaling','6','High',18.7253,0.462,0.75711,0.860739),(97,21,'Positioning','0,6','Low',1.99054,0.761542,0.804272,1),(98,21,'Positioning','0,6','Medium',2.50104,0.638083,0.706211,0.999917),(99,21,'Positioning','0,6','High',2.95983,0.66825,0.688315,0.999958),(100,21,'Rotating','0,6','Low',6.38796,0.580304,0.651661,0.998869),(101,21,'Rotating','0,6','Medium',8.41887,0.671333,0.711712,0.986208),(102,21,'Rotating','0,6','High',8.98392,0.647,0.625275,0.997917),(103,21,'Scaling','0,6','Low',6.58287,0.548708,0.798565,0.889583),(104,21,'Scaling','0,6','Medium',8.04467,0.485375,0.770832,0.775583),(105,21,'Scaling','0,6','High',9.27683,0.519391,0.791219,0.738652),(106,21,'PositioningRotating','0,6','Low',5.74967,0.700131,0.708601,0.999956),(107,21,'PositioningRotating','0,6','Medium',7.70733,0.630333,0.674659,0.982),(108,21,'PositioningRotating','0,6','High',7.08087,0.642125,0.638736,0.99975),(109,21,'PositioningRotatingScaling','0,6','Low',10.2279,0.571043,0.721387,0.835391),(110,21,'PositioningRotatingScaling','0,6','Medium',13.4154,0.686044,0.682467,0.902304),(111,21,'PositioningRotatingScaling','0,6','High',13.5693,0.372522,0.763261,0.746261),(112,21,'Positioning','3','Low',3.27654,0.603125,0.817549,1),(113,21,'Positioning','3','Medium',3.49183,0.588042,0.750898,0.990958),(114,21,'Positioning','3','High',3.03867,0.558208,0.708015,1),(115,21,'Rotating','3','Low',4.56358,0.620542,0.682513,1),(116,21,'Rotating','3','Medium',8.18875,0.613391,0.633815,1),(117,21,'Rotating','3','High',9.23783,0.592417,0.701598,1),(118,21,'Scaling','3','Low',8.41675,0.55913,0.826963,0.736609),(119,21,'Scaling','3','Medium',6.65858,0.582333,0.759682,0.773333),(120,21,'Scaling','3','High',8.72521,0.479458,0.831067,0.76975),(121,21,'PositioningRotating','3','Low',5.07017,0.57275,0.697112,1),(122,21,'PositioningRotating','3','Medium',6.46537,0.666917,0.615803,1),(123,21,'PositioningRotating','3','High',9.60063,0.578833,0.623658,0.994375),(124,21,'PositioningRotatingScaling','3','Low',10.4584,0.54887,0.667147,0.837),(125,21,'PositioningRotatingScaling','3','Medium',10.9101,0.597875,0.723144,0.887167),(126,21,'PositioningRotatingScaling','3','High',14.9126,0.574905,0.687182,0.818762),(127,21,'Positioning','6','Low',2.2085,0.622083,0.804658,0.998667),(128,21,'Positioning','6','Medium',2.765,0.584333,0.722232,1),(129,21,'Positioning','6','High',3.00292,0.628125,0.710611,1),(130,21,'Rotating','6','Low',4.35588,0.601167,0.605942,0.999958),(131,21,'Rotating','6','Medium',8.54608,0.562583,0.664485,0.999625),(132,21,'Rotating','6','High',7.28421,0.593458,0.640047,0.999625),(133,21,'Scaling','6','Low',5.56446,0.636667,0.83493,0.766875),(134,21,'Scaling','6','Medium',5.79708,0.478708,0.809062,0.763958),(135,21,'Scaling','6','High',7.74475,0.498208,0.786833,0.689875),(136,21,'PositioningRotating','6','Low',5.79375,0.650917,0.658234,0.999917),(137,21,'PositioningRotating','6','Medium',7.79608,0.564208,0.631688,0.994708),(138,21,'PositioningRotating','6','High',7.16854,0.579667,0.633407,1),(139,21,'PositioningRotatingScaling','6','Low',6.92125,0.503792,0.732609,0.842333),(140,21,'PositioningRotatingScaling','6','Medium',12.3065,0.496391,0.763918,0.821435),(141,21,'PositioningRotatingScaling','6','High',13.7948,0.430333,0.743104,0.8055),(142,105,'Positioning','0,6','Low',4.83962,0.829375,0.711497,0.993208),(143,105,'Positioning','0,6','Medium',7.56583,0.871958,0.749408,0.991667),(144,105,'Positioning','0,6','High',9.18338,0.792565,0.710698,0.996044),(145,105,'Rotating','0,6','Low',7.80171,0.878478,0.751492,1),(146,105,'Rotating','0,6','Medium',9.54558,0.802167,0.721226,0.9815),(147,105,'Rotating','0,6','High',8.53304,0.845458,0.703942,0.994125),(148,105,'Scaling','0,6','Low',2.34867,0.882333,0.847867,0.883167),(149,105,'Scaling','0,6','Medium',2.54854,0.8395,0.79464,0.819625),(150,105,'Scaling','0,6','High',3.12767,0.836917,0.846755,0.849042),(151,105,'PositioningRotating','0,6','Low',7.53604,0.839435,0.714507,1),(152,105,'PositioningRotating','0,6','Medium',8.29488,0.813792,0.655653,0.997417),(153,105,'PositioningRotating','0,6','High',10.9252,0.812667,0.702672,0.979833),(154,105,'PositioningRotatingScaling','0,6','Low',10.1717,0.774833,0.643055,0.907083),(155,105,'PositioningRotatingScaling','0,6','Medium',10.7161,0.832125,0.542052,0.931958),(156,105,'PositioningRotatingScaling','0,6','High',10.6533,0.588304,0.709149,0.740087),(157,105,'Positioning','3','Low',2.98233,0.604667,0.683731,0.989833),(158,105,'Positioning','3','Medium',6.18325,0.57213,0.624079,0.951478),(159,105,'Positioning','3','High',6.30304,0.717417,0.664625,0.976917),(160,105,'Rotating','3','Low',6.68729,0.627708,0.669145,0.997917),(161,105,'Rotating','3','Medium',8.16417,0.66075,0.599556,0.990708),(162,105,'Rotating','3','High',10.847,0.670708,0.62843,0.996792),(163,105,'Scaling','3','Low',1.44042,0.922625,0.950674,0.841417),(164,105,'Scaling','3','Medium',1.75908,0.912042,0.933161,0.833833),(165,105,'Scaling','3','High',2.20558,0.8785,0.928218,0.719125),(166,105,'PositioningRotating','3','Low',6.85158,0.645958,0.595572,0.989917),(167,105,'PositioningRotating','3','Medium',9.5225,0.564083,0.587729,0.988917),(168,105,'PositioningRotating','3','High',11.3407,0.638333,0.499187,0.988417),(169,105,'PositioningRotatingScaling','3','Low',7.86308,0.676833,0.660283,0.835833),(170,105,'PositioningRotatingScaling','3','Medium',9.63875,0.648667,0.71896,0.838167),(171,105,'PositioningRotatingScaling','3','High',13.168,0.619083,0.636052,0.876708),(172,105,'Positioning','6','Low',4.92433,0.615458,0.6119,0.996167),(173,105,'Positioning','6','Medium',6.64971,0.540667,0.546968,0.983917),(174,105,'Positioning','6','High',6.12704,0.644042,0.500656,0.987792),(175,105,'Rotating','6','Low',12.1055,0.503652,0.542741,0.943783),(176,105,'Rotating','6','Medium',12.9967,0.563227,0.531002,0.986955),(177,105,'Rotating','6','High',14.2187,0.523333,0.590891,0.967),(178,105,'Scaling','6','Low',2.35175,0.90975,0.940061,0.799),(179,105,'Scaling','6','Medium',2.13138,0.905625,0.932705,0.748375),(180,105,'Scaling','6','High',1.86354,0.8285,0.954914,0.735333),(181,105,'PositioningRotating','6','Low',10.5975,0.466087,0.55297,0.96713),(182,105,'PositioningRotating','6','Medium',13.7074,0.642391,0.524306,0.970739),(183,105,'PositioningRotating','6','High',14.6154,0.617857,0.407904,0.978286),(184,105,'PositioningRotatingScaling','6','Low',9.64817,0.56575,0.591374,0.774458),(185,105,'PositioningRotatingScaling','6','Medium',11.0847,0.557583,0.672398,0.729833),(186,105,'PositioningRotatingScaling','6','High',13.5407,0.610667,0.63012,0.799625),(187,25,'Positioning','0,6','Low',3.78529,0.874292,0.96361,1),(188,25,'Positioning','0,6','Medium',6.11529,0.84887,0.949382,1),(189,25,'Positioning','0,6','High',6.42308,0.777542,0.861595,1),(190,25,'Rotating','0,6','Low',14.3995,0.8362,0.673623,1),(191,25,'Rotating','0,6','Medium',23.4678,0.821875,0.466483,1),(192,25,'Rotating','0,6','High',22.7595,0.829067,0.391141,1),(193,25,'PositioningRotating','0,6','Low',15.2841,0.794381,0.538666,1),(194,25,'PositioningRotating','0,6','Medium',22.8048,0.722895,0.432167,1),(195,25,'PositioningRotating','0,6','High',23.1676,0.812529,0.414297,1),(196,25,'Positioning','3','Low',2.57483,0.726167,0.981088,1),(197,25,'Positioning','3','Medium',3.47154,0.63975,0.978244,1),(198,25,'Positioning','3','High',5.71454,0.568792,0.962609,1),(199,25,'Rotating','3','Low',9.37075,0.654826,0.539582,1),(200,25,'Rotating','3','Medium',23.0042,0.623529,0.314649,1),(201,25,'Rotating','3','High',19.5345,0.579579,0.479493,1),(202,25,'PositioningRotating','3','Low',11.1325,0.683957,0.529042,1),(203,25,'PositioningRotating','3','Medium',21.4565,0.668647,0.528391,1),(204,25,'PositioningRotating','3','High',23.0534,0.6012,0.485235,1),(205,25,'Positioning','6','Low',3.53446,0.551792,0.968067,1),(206,25,'Positioning','6','Medium',5.38758,0.582875,0.987387,1),(207,25,'Positioning','6','High',6.34821,0.639333,0.946801,1),(208,25,'Rotating','6','Low',8.76408,0.608792,0.576622,1),(209,25,'Rotating','6','Medium',23.9722,0.595231,0.434582,1),(210,25,'Rotating','6','High',22.6783,0.618857,0.368973,1),(211,25,'PositioningRotating','6','Low',14.1861,0.65175,0.587758,1),(212,25,'PositioningRotating','6','Medium',21.8349,0.578941,0.357623,1),(213,25,'PositioningRotating','6','High',24.1233,0.56875,0.441952,1),(214,104,'Positioning','0,6','Low',5.91913,0.859958,0.704074,1),(215,104,'Positioning','0,6','Medium',7.67133,0.843375,0.73502,1),(216,104,'Positioning','0,6','High',8.98896,0.765833,0.629029,1),(217,104,'Rotating','0,6','Low',8.74129,0.874125,0.720761,1),(218,104,'Rotating','0,6','Medium',11.1119,0.818125,0.661675,1),(219,104,'Rotating','0,6','High',11.2882,0.854609,0.75808,1),(220,104,'PositioningRotating','0,6','Low',8.1175,0.818125,0.694746,1),(221,104,'PositioningRotating','0,6','Medium',9.10029,0.811125,0.732493,1),(222,104,'PositioningRotating','0,6','High',10.823,0.822417,0.722219,1),(223,104,'Positioning','3','Low',5.18108,0.657125,0.678011,1),(224,104,'Positioning','3','Medium',6.33104,0.603,0.640358,1),(225,104,'Positioning','3','High',7.44321,0.56725,0.571182,1),(226,104,'Rotating','3','Low',9.51742,0.637208,0.554978,1),(227,104,'Rotating','3','Medium',12.5595,0.683333,0.608029,1),(228,104,'Rotating','3','High',13.6217,0.624174,0.644966,1),(229,104,'PositioningRotating','3','Low',10.3098,0.684667,0.570592,1),(230,104,'PositioningRotating','3','Medium',13.2957,0.680958,0.661482,1),(231,104,'PositioningRotating','3','High',15.4896,0.542826,0.59,1),(232,104,'Positioning','6','Low',5.19746,0.652542,0.492568,1),(233,104,'Positioning','6','Medium',8.42838,0.478417,0.541224,1),(234,104,'Positioning','6','High',9.33821,0.546833,0.542232,1),(235,104,'Rotating','6','Low',13.8259,0.512304,0.48235,1),(236,104,'Rotating','6','Medium',19.4696,0.482048,0.371561,1),(237,104,'Rotating','6','High',18.6888,0.547818,0.496415,1),(238,104,'PositioningRotating','6','Low',14.8382,0.661609,0.457001,1),(239,104,'PositioningRotating','6','Medium',20.7326,0.481458,0.555156,1),(240,104,'PositioningRotating','6','High',21.3792,0.643842,0.492186,1);
/*!40000 ALTER TABLE `technique_objective_manipulation` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `technique_objective_selection`
--

DROP TABLE IF EXISTS `technique_objective_selection`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `technique_objective_selection` (
  `id` int NOT NULL,
  `technique_id` int DEFAULT NULL,
  `distance` varchar(45) DEFAULT NULL,
  `object_size` varchar(45) DEFAULT NULL,
  `density` varchar(45) DEFAULT NULL,
  `mean_time` float DEFAULT NULL,
  `misses` int DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `technique_objective_selection`
--

LOCK TABLES `technique_objective_selection` WRITE;
/*!40000 ALTER TABLE `technique_objective_selection` DISABLE KEYS */;
INSERT INTO `technique_objective_selection` VALUES (1,17,'0,6','15','No',0.822067,3),(2,17,'0,6','10','No',0.9534,5),(3,17,'0,6','5','No',1.0822,4),(4,17,'0,6','15','10',0.966,1),(5,17,'0,6','10','10',0.935033,2),(6,17,'0,6','5','10',1.01457,0),(7,17,'0,6','15','5',0.832533,0),(8,17,'0,6','10','5',0.863867,1),(9,17,'0,6','5','5',1.0651,4),(10,1,'0,6','15','No',0.719667,3),(11,1,'0,6','10','No',0.790967,5),(12,1,'0,6','5','No',0.9636,7),(13,1,'0,6','15','10',0.888233,5),(14,1,'0,6','10','10',0.798667,2),(15,1,'0,6','5','10',0.959,2),(16,1,'0,6','15','5',0.817133,6),(17,1,'0,6','10','5',0.7885,2),(18,1,'0,6','5','5',0.8998,2),(19,13,'0,6','15','No',1.4048,1),(20,13,'0,6','10','No',1.64107,5),(21,13,'0,6','5','No',1.9828,1),(22,13,'0,6','15','10',1.73397,2),(23,13,'0,6','10','10',1.7065,5),(24,13,'0,6','5','10',1.99743,4),(25,13,'0,6','15','5',1.30333,1),(26,13,'0,6','10','5',1.56937,3),(27,13,'0,6','5','5',1.86137,1),(28,13,'3','15','No',2.1381,7),(29,13,'3','10','No',2.32877,3),(30,13,'3','5','No',3.08453,0),(31,13,'3','15','10',2.29177,3),(32,13,'3','10','10',2.45877,5),(33,13,'3','5','10',2.6493,8),(34,13,'3','15','5',2.25543,4),(35,13,'3','10','5',2.33217,3),(36,13,'3','5','5',2.9583,1),(37,13,'6','15','No',3.0343,10),(38,13,'6','10','No',4.2073,5),(39,13,'6','5','No',5.6736,7),(40,13,'6','15','10',3.55977,13),(41,13,'6','10','10',3.90377,11),(42,13,'6','5','10',4.85923,4),(43,13,'6','15','5',3.16947,4),(44,13,'6','10','5',3.27463,6),(45,13,'6','5','5',6.70597,6),(46,100,'0,6','15','No',0.656933,1),(47,100,'0,6','10','No',0.6365,0),(48,100,'0,6','5','No',0.745167,1),(49,100,'0,6','15','10',0.8831,1),(50,100,'0,6','10','10',0.858333,0),(51,100,'0,6','5','10',0.972867,0),(52,100,'0,6','15','5',0.788767,0),(53,100,'0,6','10','5',0.793767,0),(54,100,'0,6','5','5',1.783,2),(55,100,'3','15','No',0.584,0),(56,100,'3','10','No',0.6019,0),(57,100,'3','5','No',0.6283,1),(58,100,'3','15','10',1.84873,1),(59,100,'3','10','10',1.7434,0),(60,100,'3','5','10',2.0769,1),(61,100,'3','15','5',1.8484,2),(62,100,'3','10','5',1.82387,0),(63,100,'3','5','5',2.24587,0),(64,100,'6','15','No',0.656633,0),(65,100,'6','10','No',0.688333,2),(66,100,'6','5','No',0.6914,0),(67,100,'6','15','10',1.90073,4),(68,100,'6','10','10',1.99227,2),(69,100,'6','5','10',2.36473,2),(70,100,'6','15','5',1.96873,0),(71,100,'6','10','5',1.9405,0),(72,100,'6','5','5',2.76803,3),(73,85,'0,6','15','No',0.618467,0),(74,85,'0,6','10','No',0.668667,1),(75,85,'0,6','5','No',0.956833,4),(76,85,'0,6','15','10',0.7919,2),(77,85,'0,6','10','10',0.778933,1),(78,85,'0,6','5','10',0.9783,1),(79,85,'0,6','15','5',0.6508,0),(80,85,'0,6','10','5',0.7052,2),(81,85,'0,6','5','5',0.9492,3),(82,85,'3','15','No',0.931767,6),(83,85,'3','10','No',1.22533,11),(84,85,'3','5','No',1.90347,27),(85,85,'3','15','10',0.990767,3),(86,85,'3','10','10',1.20553,8),(87,85,'3','5','10',1.84507,15),(88,85,'3','15','5',1.0441,3),(89,85,'3','10','5',1.1703,5),(90,85,'3','5','5',1.80847,13),(91,85,'6','15','No',1.32953,8),(92,85,'6','10','No',2.63803,31),(93,85,'6','5','No',7.08577,82),(94,85,'6','15','10',1.65097,16),(95,85,'6','10','10',2.4463,31),(96,85,'6','5','10',8.1294,77),(97,85,'6','15','5',1.62043,14),(98,85,'6','10','5',2.39747,16),(99,85,'6','5','5',5.47823,52),(100,21,'0,6','15','No',0.625433,0),(101,21,'0,6','10','No',0.706233,0),(102,21,'0,6','5','No',0.725,0),(103,21,'0,6','15','10',0.904433,2),(104,21,'0,6','10','10',0.931133,0),(105,21,'0,6','5','10',1.52407,2),(106,21,'0,6','15','5',0.972967,0),(107,21,'0,6','10','5',0.9592,0),(108,21,'0,6','5','5',1.5134,10),(109,21,'3','15','No',0.945233,0),(110,21,'3','10','No',1.0277,1),(111,21,'3','5','No',1.26247,5),(112,21,'3','15','10',1.191,1),(113,21,'3','10','10',1.40083,2),(114,21,'3','5','10',1.63097,3),(115,21,'3','15','5',1.32197,0),(116,21,'3','10','5',1.72837,8),(117,21,'3','5','5',2.4471,14),(118,21,'6','15','No',1.50597,4),(119,21,'6','10','No',1.6365,2),(120,21,'6','5','No',3.03593,1),(121,21,'6','15','10',1.57503,0),(122,21,'6','10','10',1.95103,0),(123,21,'6','5','10',2.81167,3),(124,21,'6','15','5',1.6759,3),(125,21,'6','10','5',2.20713,1),(126,21,'6','5','5',2.88403,10),(127,105,'0,6','15','No',0.600233,1),(128,105,'0,6','10','No',0.651633,2),(129,105,'0,6','5','No',0.904533,6),(130,105,'0,6','15','10',0.730367,0),(131,105,'0,6','10','10',0.732933,1),(132,105,'0,6','5','10',0.9183,2),(133,105,'0,6','15','5',0.629933,0),(134,105,'0,6','10','5',0.611733,0),(135,105,'0,6','5','5',0.8639,1),(136,105,'3','15','No',0.783,1),(137,105,'3','10','No',1.05323,5),(138,105,'3','5','No',1.85923,16),(139,105,'3','15','10',0.882933,1),(140,105,'3','10','10',1.1678,9),(141,105,'3','5','10',1.72287,12),(142,105,'3','15','5',0.893867,3),(143,105,'3','10','5',1.11423,3),(144,105,'3','5','5',1.57377,5),(145,105,'6','15','No',1.26777,9),(146,105,'6','10','No',2.04047,24),(147,105,'6','5','No',7.00233,63),(148,105,'6','15','10',1.39187,6),(149,105,'6','10','10',2.0441,30),(150,105,'6','5','10',4.36667,49),(151,105,'6','15','5',1.4385,10),(152,105,'6','10','5',2.24377,22),(153,105,'6','5','5',8.38493,80),(154,89,'0,6','15','No',0.605467,0),(155,89,'0,6','10','No',0.6191,0),(156,89,'0,6','5','No',0.713167,0),(157,89,'0,6','15','10',0.797967,0),(158,89,'0,6','10','10',0.741967,0),(159,89,'0,6','5','10',0.845767,2),(160,89,'0,6','15','5',0.6816,0),(161,89,'0,6','10','5',0.720367,1),(162,89,'0,6','5','5',0.8315,0),(163,89,'3','15','No',0.6061,0),(164,89,'3','10','No',0.662867,0),(165,89,'3','5','No',0.6598,0),(166,89,'3','15','10',0.922633,3),(167,89,'3','10','10',0.994633,6),(168,89,'3','5','10',1.19703,10),(169,89,'3','15','5',1.01873,3),(170,89,'3','10','5',1.1058,7),(171,89,'3','5','5',1.2616,5),(172,89,'6','15','No',0.689667,0),(173,89,'6','10','No',0.769267,0),(174,89,'6','5','No',0.7532,0),(175,89,'6','15','10',1.08897,2),(176,89,'6','10','10',1.28377,5),(177,89,'6','5','10',1.4493,3),(178,89,'6','15','5',1.32627,6),(179,89,'6','10','5',1.77953,7),(180,89,'6','5','5',1.9173,15),(181,57,'0,6','15','No',1.62067,0),(182,57,'0,6','10','No',1.63487,0),(183,57,'0,6','5','No',2.07017,0),(184,57,'0,6','15','10',1.80753,0),(185,57,'0,6','10','10',1.77247,0),(186,57,'0,6','5','10',2.29317,0),(187,57,'0,6','15','5',1.58123,0),(188,57,'0,6','10','5',1.59463,0),(189,57,'0,6','5','5',1.97207,0),(190,57,'3','15','No',1.8202,0),(191,57,'3','10','No',2.03303,0),(192,57,'3','5','No',2.63063,0),(193,57,'3','15','10',1.85377,0),(194,57,'3','10','10',1.8632,0),(195,57,'3','5','10',3.07093,0),(196,57,'3','15','5',1.80753,0),(197,57,'3','10','5',2.0128,0),(198,57,'3','5','5',2.83417,0),(199,57,'6','15','No',2.17387,0),(200,57,'6','10','No',2.46733,0),(201,57,'6','5','No',6.5845,0),(202,57,'6','15','10',2.1646,1),(203,57,'6','10','10',2.52223,0),(204,57,'6','5','10',5.21633,0),(205,57,'6','15','5',2.08687,0),(206,57,'6','10','5',2.56577,0),(207,57,'6','5','5',6.95527,0),(208,88,'0,6','15','No',0.558133,0),(209,88,'0,6','10','No',0.594567,0),(210,88,'0,6','5','No',0.694967,1),(211,88,'0,6','15','10',0.8307,0),(212,88,'0,6','10','10',0.706233,0),(213,88,'0,6','5','10',0.806533,0),(214,88,'0,6','15','5',0.670133,0),(215,88,'0,6','10','5',0.674867,0),(216,88,'0,6','5','5',0.8262,1),(217,88,'3','15','No',0.6319,0),(218,88,'3','10','No',0.629933,1),(219,88,'3','5','No',0.639567,1),(220,88,'3','15','10',0.805767,1),(221,88,'3','10','10',0.9292,4),(222,88,'3','5','10',1.1605,0),(223,88,'3','15','5',0.915467,2),(224,88,'3','10','5',1.0351,3),(225,88,'3','5','5',1.43003,9),(226,88,'6','15','No',0.6906,1),(227,88,'6','10','No',0.686567,1),(228,88,'6','5','No',0.756367,0),(229,88,'6','15','10',1.2588,7),(230,88,'6','10','10',1.5071,10),(231,88,'6','5','10',1.57233,9),(232,88,'6','15','5',1.47223,9),(233,88,'6','10','5',1.65873,6),(234,88,'6','5','5',2.1176,21);
/*!40000 ALTER TABLE `technique_objective_selection` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `technique_source`
--

DROP TABLE IF EXISTS `technique_source`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `technique_source` (
  `id` int NOT NULL AUTO_INCREMENT,
  `technique_id` int NOT NULL,
  `url` varchar(255) NOT NULL,
  `description` varchar(255) NOT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=274 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `technique_source`
--

LOCK TABLES `technique_source` WRITE;
/*!40000 ALTER TABLE `technique_source` DISABLE KEYS */;
INSERT INTO `technique_source` VALUES (1,1,'https://www.pearson.com/us/higher-education/program/La-Viola-3-D-User-Interfaces-Theory-and-Practice-2nd-Edition/PGM101825.html','3D User Interfaces: Theory and Practice, 2nd Edition'),(2,1,'https://dl.acm.org/citation.cfm?id=897820','Virtual Environment Interaction Techniques'),(3,1,'https://doi.org/10.1145/237091.237102','Bild 1 (The go-go interaction technique: non-linear mapping for direct manipulation in VR)'),(4,2,'https://doi.org/10.1145/1229855.1229857','PRISM interaction for enhancing control in immersive virtual environments'),(5,2,'https://doi.org/10.1145/1229855.1229857','Bild 1 (PRISM interaction for enhancing control in immersive virtual environments)'),(6,2,'https://doi.org/10.1145/1229855.1229857','Bild 2 (PRISM interaction for enhancing control in immersive virtual environments)'),(7,3,'https://dl.acm.org/citation.cfm?doid=1889863.1889891','Dynamic decomposition and integration of degrees of freedom for 3-D positioning'),(8,4,'https://doi.org/10.1109/3DUI.2013.6550208','Hook: Heuristics for selecting 3D moving objects in dense target environments'),(9,4,'https://doi.org/10.1109/3DUI.2013.6550208','Bild 1 (Hook: Heuristics for selecting 3D moving objects in dense target environments)'),(10,5,'https://doi.org/10.1145/2407336.2407356','Starfish: a selection technique for dense virtual environments'),(11,5,'https://doi.org/10.1145/2407336.2407356','Bild 1 (Starfish: a selection technique for dense virtual environments)'),(12,5,'https://doi.org/10.1145/2407336.2407356','Bild 2 (Starfish: a selection technique for dense virtual environments)'),(13,6,'https://doi.org/10.1016/j.ijhcs.2008.09.001','Multimodal selection techniques for dense and occluded 3D virtual environments'),(14,6,'https://www.pearson.com/us/higher-education/program/La-Viola-3-D-User-Interfaces-Theory-and-Practice-2nd-Edition/PGM101825.html','3D User Interfaces: Theory and Practice, 2nd Edition'),(15,6,'https://www.pearson.com/us/higher-education/program/La-Viola-3-D-User-Interfaces-Theory-and-Practice-2nd-Edition/PGM101825.html','Bild 1 (3D User Interfaces: Theory and Practice, 2nd Edition)'),(16,6,'https://doi.org/10.1016/j.ijhcs.2008.09.001','Bild 2 (Multimodal selection techniques for dense and occluded 3D virtual environments)'),(17,6,'https://doi.org/10.1016/j.ijhcs.2008.09.001','Bild 3 (Multimodal selection techniques for dense and occluded 3D virtual environments)'),(18,7,'https://doi.org/10.1109/MCG.2014.20','3D Object Manipulation Using Virtual Handles with a Grabbing Metaphor'),(19,7,'https://doi.org/10.1109/MCG.2014.20','Bild 1 (3D Object Manipulation Using Virtual Handles with a Grabbing Metaphor)'),(20,7,'https://doi.org/10.1109/MCG.2014.20','Bild 2 (3D Object Manipulation Using Virtual Handles with a Grabbing Metaphor)'),(21,8,'https://doi.org/10.1145/2350046.2350060','Select Ahead: Efficient Object Selection Technique using Tendency of Recent Cursor Movements'),(22,8,'https://doi.org/10.1145/2350046.2350060','Bild 1 (Select Ahead: Efficient Object Selection Technique using Tendency of Recent Cursor Movements)'),(23,9,'http://dx.doi.org/10.2312/EGVE/JVRC09/001-008','Designing 3D Selection Techniques Using Ballistic and Corrective Movements'),(24,10,'http://dx.doi.org/10.2312/EGVE/JVRC09/001-008','Designing 3D Selection Techniques Using Ballistic and Corrective Movements'),(25,11,'https://doi.org/10.1145/237091.237102','The go-go interaction technique: non-linear mapping for direct manipulation in VR'),(26,11,'https://dl.acm.org/citation.cfm?id=897820','Bild 1 (Virtual Environment Interaction Techniques)'),(27,12,'https://doi.org/10.1145/253284.253301','An evaluation of techniques for grabbing and manipulating remote objects in immersive virtual environments'),(28,13,'https://ijvr.eu/article/view/2859','Increasing Precision for Extended Reach 3D Manipulation'),(29,13,'https://ijvr.eu/article/view/2859','Bild 1 (Increasing Precision for Extended Reach 3D Manipulation)'),(30,13,'https://ijvr.eu/article/view/2859','Bild 2 (Increasing Precision for Extended Reach 3D Manipulation)'),(31,14,'https://doi.org/10.1145/1128923.1128945','FOLLOW-ME: a new 3D interaction technique based on virtual guides and granularity of interaction'),(32,14,'https://doi.org/10.1145/1128923.1128945','Bild 1 (FOLLOW-ME: a new 3D interaction technique based on virtual guides and granularity of interaction)'),(33,15,'https://doi.org/10.1145/253284.253301','An evaluation of techniques for grabbing and manipulating remote objects in immersive virtual environments'),(34,16,'https://doi.org/10.1145/258734.258747','Moving objects in space: exploiting proprioception in virtual-environment interaction'),(35,17,'https://doi.org/10.1162/pres.1995.4.4.403','A Two-Handed Interface for Object Manipulation in Virtual Environments'),(36,17,'https://www.pearson.com/us/higher-education/program/La-Viola-3-D-User-Interfaces-Theory-and-Practice-2nd-Edition/PGM101825.html','3D User Interfaces: Theory and Practice, 2nd Edition'),(37,17,'#','Bild 1 (eigene Darstellung)'),(38,17,'#','Bild 2 (eigene Darstellung)'),(39,18,'https://doi.org/10.1109/3DUI.2015.7131738','Evaluation of a bimanual simultaneous 7DOF interaction technique in virtual environments'),(40,18,'https://www.pearson.com/us/higher-education/program/La-Viola-3-D-User-Interfaces-Theory-and-Practice-2nd-Edition/PGM101825.html','Bild 1 (3D User Interfaces: Theory and Practice, 2nd Edition)'),(41,18,'#','Bild 2 (eigene Darstellung)'),(42,18,'#','Bild 3 (eigene Darstellung)'),(43,19,'https://doi.org/10.1145/223904.223938','Virtual reality on a WIM: interactive worlds in miniature'),(44,19,'https://doi.org/10.1145/223904.223938','Bild 1 (Virtual reality on a WIM: interactive worlds in miniature)'),(45,19,'https://dl.acm.org/citation.cfm?id=897822','Bild 2 (ISAAC: A Virtual Environment Tool for the Interactive Construction of Virtual Worlds)'),(46,19,'#','Bild 3 (eigene Darstellung)'),(47,20,'https://doi.org/10.20870/IJVR.2006.5.2.2683','New directions in 3D user interfaces'),(48,20,'https://doi.org/10.20870/IJVR.2006.5.2.2683','Bild 1 (New directions in 3D user interfaces)'),(49,21,'#','Bild 1 (eigene Darstellung)'),(50,21,'#','Bild 2 (eigene Darstellung)'),(51,22,'https://doi.org/10.1162/PRES_a_00251','Evaluating Control Schemes for the Third Arm of an Avatar'),(52,22,'https://doi.org/10.1162/PRES_a_00251','Bild 1 (Evaluating Control Schemes for the Third Arm of an Avatar)'),(53,22,'https://doi.org/10.1162/PRES_a_00251','Bild 2 (Evaluating Control Schemes for the Third Arm of an Avatar)'),(54,23,'https://doi.org/10.1162/PRES_a_00251','Evaluating Control Schemes for the Third Arm of an Avatar'),(55,23,'https://doi.org/10.1162/PRES_a_00251','Bild 1 (Evaluating Control Schemes for the Third Arm of an Avatar)'),(56,23,'https://doi.org/10.1162/PRES_a_00251','Bild 2 (Evaluating Control Schemes for the Third Arm of an Avatar)'),(57,24,'https://doi.org/10.1162/PRES_a_00251','Evaluating Control Schemes for the Third Arm of an Avatar'),(58,24,'https://doi.org/10.1162/PRES_a_00251','Bild 1 (Evaluating Control Schemes for the Third Arm of an Avatar)'),(59,24,'https://doi.org/10.1162/PRES_a_00251','Bild 2 (Evaluating Control Schemes for the Third Arm of an Avatar)'),(60,25,'https://doi.org/10.1162/PRES_a_00207','Design Choices and Their Implications for 3D Mid-Air Manipulation Techniques'),(61,25,'https://doi.org/10.1162/PRES_a_00207','Bild 1 (Design Choices and Their Implications for 3D Mid-Air Manipulation Techniques)'),(62,25,'https://doi.org/10.1162/PRES_a_00207','Bild 2 (Design Choices and Their Implications for 3D Mid-Air Manipulation Techniques)'),(63,26,'https://doi.org/10.1007/978-3-642-39405-8_17','A Study of Navigation and Selection Techniques in Virtual Environments Using Microsoft Kinect®'),(64,26,'https://doi.org/10.1007/978-3-642-39405-8_17','Bild 1 (A Study of Navigation and Selection Techniques in Virtual Environments Using Microsoft Kinect®)'),(65,27,'https://doi.org/10.1007/978-3-642-39405-8_17','A Study of Navigation and Selection Techniques in Virtual Environments Using Microsoft Kinect®'),(66,27,'https://doi.org/10.1007/978-3-642-39405-8_17','Bild 1 (A Study of Navigation and Selection Techniques in Virtual Environments Using Microsoft Kinect®)'),(67,28,'https://doi.org/10.1007/978-3-642-39405-8_17','A Study of Navigation and Selection Techniques in Virtual Environments Using Microsoft Kinect®'),(68,28,'https://doi.org/10.1007/978-3-642-39405-8_17','Bild 1 (A Study of Navigation and Selection Techniques in Virtual Environments Using Microsoft Kinect®)'),(69,29,'https://doi.org/10.1007/978-3-642-39405-8_17','A Study of Navigation and Selection Techniques in Virtual Environments Using Microsoft Kinect®'),(70,29,'https://doi.org/10.1007/978-3-642-39405-8_17','Bild 1 (A Study of Navigation and Selection Techniques in Virtual Environments Using Microsoft Kinect®)'),(71,30,'https://store.steampowered.com/app/250820/SteamVR/','SteamVR Home'),(72,30,'https://store.steampowered.com/app/250820/SteamVR/','Bild 1 (SteamVR Home)'),(73,30,'https://store.steampowered.com/app/250820/SteamVR/','Bild 2 (SteamVR Home)'),(74,31,'https://www.pearson.com/us/higher-education/program/La-Viola-3-D-User-Interfaces-Theory-and-Practice-2nd-Edition/PGM101825.html','3D User Interfaces: Theory and Practice, 2nd Edition'),(75,31,'#','Bild 1 (eigene Darstellung)'),(76,32,'https://doi.org/10.1109/VR.2005.1492758','Realistic virtual grasping'),(77,32,'https://www.pearson.com/us/higher-education/program/La-Viola-3-D-User-Interfaces-Theory-and-Practice-2nd-Edition/PGM101825.html','Bild 1 (3D User Interfaces: Theory and Practice, 2nd Edition)'),(78,32,'https://doi.org/10.1109/VR.2005.1492758','Bild 2 (Realistic virtual grasping)'),(79,33,'https://ieeexplore.ieee.org/document/7131736','IDS: The intent driven selection method for natural user interface'),(80,33,'https://ieeexplore.ieee.org/document/7131736','Bild 1 (IDS: The intent driven selection method for natural user interface)'),(81,33,'https://ieeexplore.ieee.org/document/7131736','Bild 2 (IDS: The intent driven selection method for natural user interface)'),(82,34,'https://www.roadtovr.com/exclusive-summoning-superpowers-designing-vr-interactions-at-a-distance/3/','Summoning & Superpowers – Designing VR Interactions at a Distance'),(83,34,'https://www.roadtovr.com/exclusive-summoning-superpowers-designing-vr-interactions-at-a-distance/3/','Bild 1 (Summoning & Superpowers – Designing VR Interactions at a Distance)'),(84,34,'https://www.roadtovr.com/exclusive-summoning-superpowers-designing-vr-interactions-at-a-distance/3/','Bild 2 (Summoning & Superpowers – Designing VR Interactions at a Distance)'),(85,34,'https://www.roadtovr.com/exclusive-summoning-superpowers-designing-vr-interactions-at-a-distance/3/','Bild 3 (Summoning & Superpowers – Designing VR Interactions at a Distance)'),(86,35,'https://doi.org/10.1162/PRES_a_00207','Design Choices and Their Implications for 3D Mid-Air Manipulation Techniques'),(87,35,'https://doi.org/10.1162/PRES_a_00207','Bild 1 (Design Choices and Their Implications for 3D Mid-Air Manipulation Techniques)'),(88,35,'https://doi.org/10.1162/PRES_a_00207','Bild 2 (Design Choices and Their Implications for 3D Mid-Air Manipulation Techniques)'),(89,36,'https://doi.org/10.2312/stag.20171225','Single-Handed vs. Two Handed Manipulation in Virtual Reality: A Novel Metaphor and Experimental Comparisons'),(90,36,'https://doi.org/10.2312/stag.20171225','Bild 1 (Single-Handed vs. Two Handed Manipulation in Virtual Reality: A Novel Metaphor and Experimental Comparisons)'),(91,36,'https://doi.org/10.2312/stag.20171225','Bild 2 (Single-Handed vs. Two Handed Manipulation in Virtual Reality: A Novel Metaphor and Experimental Comparisons)'),(92,36,'https://doi.org/10.2312/stag.20171225','Bild 3 (Single-Handed vs. Two Handed Manipulation in Virtual Reality: A Novel Metaphor and Experimental Comparisons)'),(93,37,'http://doi.acm.org/10.1145/300523.300540','Voodoo dolls: seamless interaction at multiple scales in virtual environments'),(94,37,'http://doi.acm.org/10.1145/300523.300540','Bild 1 (Voodoo dolls: seamless interaction at multiple scales in virtual environments)'),(95,37,'http://doi.acm.org/10.1145/300523.300540','Bild 2 (Voodoo dolls: seamless interaction at multiple scales in virtual environments)'),(96,37,'http://doi.acm.org/10.1145/300523.300540','Bild 3 (Voodoo dolls: seamless interaction at multiple scales in virtual environments)'),(97,38,'https://doi.org/10.1145/253284.253315','Two-handed direct manipulation on the responsive workbench'),(98,39,'https://doi.org/10.1145/2207676.2208585','A handle bar metaphor for virtual object manipulation with mid-air interaction'),(99,39,'https://doi.org/10.1145/2207676.2208585','Bild 1 (A handle bar metaphor for virtual object manipulation with mid-air interaction)'),(100,39,'https://doi.org/10.1145/2207676.2208585','Bild 2 (A handle bar metaphor for virtual object manipulation with mid-air interaction)'),(101,39,'https://doi.org/10.1145/2207676.2208585','Bild 3 (A handle bar metaphor for virtual object manipulation with mid-air interaction)'),(102,40,'https://doi.org/10.1145/253284.253315','Two-handed direct manipulation on the responsive workbench'),(103,40,'https://doi.org/10.1145/253284.253315','Bild 1 (Two-handed direct manipulation on the responsive workbench)'),(104,41,'https://doi.org/10.1145/253284.253315','Two-handed direct manipulation on the responsive workbench'),(105,42,'https://doi.org/10.1145/253284.253315','Two-handed direct manipulation on the responsive workbench'),(106,43,'https://ieeexplore.ieee.org/document/6798833','Mid-air interactions above stereoscopic interactive tables'),(107,43,'https://ieeexplore.ieee.org/document/6798833','Bild 1 (Mid-air interactions above stereoscopic interactive tables)'),(108,44,'https://doi.org/10.1145/253284.253315','Two-handed direct manipulation on the responsive workbench'),(109,45,'https://doi.org/10.1145/253284.253315','Two-handed direct manipulation on the responsive workbench'),(110,46,'https://doi.org/10.1145/253284.253315','Two-handed direct manipulation on the responsive workbench'),(111,47,'https://doi.org/10.1145/253284.253315','Two-handed direct manipulation on the responsive workbench'),(112,48,'https://doi.org/10.1145/253284.253315','Two-handed direct manipulation on the responsive workbench'),(113,49,'https://doi.org/10.1145/253284.253315','Two-handed direct manipulation on the responsive workbench'),(114,50,'https://ieeexplore.ieee.org/document/6798833','Mid-air interactions above stereoscopic interactive tables'),(115,50,'https://ieeexplore.ieee.org/document/6798833','Bild 1 (Mid-air interactions above stereoscopic interactive tables)'),(116,51,'https://ieeexplore.ieee.org/document/6798833','Mid-air interactions above stereoscopic interactive tables'),(117,51,'https://ieeexplore.ieee.org/document/6798833','Bild 1 (Mid-air interactions above stereoscopic interactive tables)'),(118,52,'https://doi.org/10.1145/253284.253315','Two-handed direct manipulation on the responsive workbench'),(119,53,'https://doi.org/10.1145/1128923.1128943','Automatic adjustments for efficient and precise positioning and release of virtual objects'),(120,53,'https://doi.org/10.1145/1128923.1128943','Bild 1 (Automatic adjustments for efficient and precise positioning and release of virtual objects)'),(121,53,'https://doi.org/10.1145/1128923.1128943','Bild 2 (Automatic adjustments for efficient and precise positioning and release of virtual objects)'),(122,53,'https://doi.org/10.1145/1128923.1128943','Bild 3 (Automatic adjustments for efficient and precise positioning and release of virtual objects)'),(123,54,'https://www.pearson.com/us/higher-education/program/La-Viola-3-D-User-Interfaces-Theory-and-Practice-2nd-Edition/PGM101825.html','3D User Interfaces: Theory and Practice, 2nd Edition'),(124,54,'#','Bild 1 (eigene Darstellung)'),(125,55,'https://www.pearson.com/us/higher-education/program/La-Viola-3-D-User-Interfaces-Theory-and-Practice-2nd-Edition/PGM101825.html','3D User Interfaces: Theory and Practice, 2nd Edition'),(126,55,'#','Bild 1 (eigene Darstellung)'),(127,56,'https://dl.acm.org/doi/book/10.5555/897820','Virtual Environment Interaction Techniques'),(128,56,'#','Bild 1 (eigene Darstellung)'),(129,57,'https://dl.acm.org/doi/book/10.5555/897820','Virtual Environment Interaction Techniques'),(130,57,'#','Bild 1 (eigene Darstellung)'),(131,57,'#','Bild 2 (eigene Darstellung)'),(132,57,'#','Bild 3 (eigene Darstellung)'),(133,58,'https://dl.acm.org/citation.cfm?id=3132182','The eyes don\'t have it: an empirical comparison of head-based and eye-based selection in virtual reality'),(134,58,'#','Bild 1 (eigene Darstellung)'),(135,59,'https://dl.acm.org/citation.cfm?id=3132182','The eyes don\'t have it: an empirical comparison of head-based and eye-based selection in virtual reality'),(136,59,'#','Bild 1 (eigene Darstellung)'),(137,60,'http://nbn-resolving.de/urn:nbn:de:0070-pub-18944367','Navigating and selecting in the virtual supermarket: review and update of classic interaction techniques'),(138,60,'http://nbn-resolving.de/urn:nbn:de:0070-pub-18944367','Bild 1 (Navigating and selecting in the virtual supermarket: review and update of classic interaction techniques)'),(139,61,'https://doi.org/10.1145/253284.253301','An evaluation of techniques for grabbing and manipulating remote objects in immersive virtual environments'),(140,62,'https://doi.org/10.1145/253284.253303','Image plane interaction techniques in 3D immersive environments'),(141,62,'https://doi.org/10.1145/253284.253303','Bild 1 (Image plane interaction techniques in 3D immersive environments)'),(142,62,'https://doi.org/10.1145/253284.253303','Bild 2 (Image plane interaction techniques in 3D immersive environments)'),(143,62,'https://doi.org/10.1145/253284.253303','Bild 3 (Image plane interaction techniques in 3D immersive environments)'),(144,63,'https://doi.org/10.1145/1166253.1166257','The Design and Evaluation of Selection Techniques for 3D Volumetric Displays'),(145,63,'https://doi.org/10.1145/1166253.1166257','Bild 1 (The Design and Evaluation of Selection Techniques for 3D Volumetric Displays)'),(146,64,'https://doi.org/10.1145/1166253.1166257','The Design and Evaluation of Selection Techniques for 3D Volumetric Displays'),(147,64,'https://doi.org/10.1145/1166253.1166257','Bild 1 (The Design and Evaluation of Selection Techniques for 3D Volumetric Displays)'),(148,65,'https://doi.org/10.1145/1166253.1166257','The Design and Evaluation of Selection Techniques for 3D Volumetric Displays'),(149,65,'https://doi.org/10.1145/1166253.1166257','Bild 1 (The Design and Evaluation of Selection Techniques for 3D Volumetric Displays)'),(150,66,'https://doi.org/10.1145/1166253.1166257','The Design and Evaluation of Selection Techniques for 3D Volumetric Displays'),(151,66,'https://doi.org/10.1145/1166253.1166257','Bild 1 (The Design and Evaluation of Selection Techniques for 3D Volumetric Displays)'),(152,67,'https://doi.org/10.1109/3DUI.2013.6550205','Optimal 3D selection technique assignment using real-time contextual analysis'),(153,67,'https://www.pearson.com/us/higher-education/program/La-Viola-3-D-User-Interfaces-Theory-and-Practice-2nd-Edition/PGM101825.html','3D User Interfaces: Theory and Practice, 2nd Edition'),(154,68,'https://doi.org/10.1007/1-4020-4179-9_46','Object selection in virtual environments using an improved virtual pointer metaphor'),(155,68,'https://www.researchgate.net/publication/229041692_3DUI_flavors_beyond_vanilla','3DUI flavors beyond vanilla'),(156,68,'https://doi.org/10.1007/1-4020-4179-9_46','Bild 1 (Object selection in virtual environments using an improved virtual pointer metaphor)'),(157,68,'https://www.researchgate.net/publication/229041692_3DUI_flavors_beyond_vanilla','Bild 2 (3DUI flavors beyond vanilla)'),(158,69,'https://doi.org/10.1016/j.ijhcs.2018.07.003','VOTE: A ray-casting study of vote-oriented technique enhancements'),(159,69,'https://doi.org/10.1016/j.ijhcs.2018.07.003','Bild 1 (VOTE: A ray-casting study of vote-oriented technique enhancements)'),(160,70,'https://doi.org/10.1145/1229855.1229857','PRISM interaction for enhancing control in immersive virtual environments'),(161,71,'https://doi.org/10.1007/978-3-642-03655-2_73','Adaptive Pointing – Design and Evaluation of a Precision Enhancing Technique for Absolute Pointing Devices'),(162,71,'https://doi.org/10.1007/978-3-642-03655-2_73','Bild 1 (Adaptive Pointing – Design and Evaluation of a Precision Enhancing Technique for Absolute Pointing Devices)'),(163,72,'https://doi.org/10.1016/j.ijhcs.2011.12.001','Design and comparative evaluation of Smoothed Pointing: A velocity-oriented remote pointing enhancement technique'),(164,72,'https://doi.org/10.1016/j.ijhcs.2011.12.001','Bild 1 (Design and comparative evaluation of Smoothed Pointing: A velocity-oriented remote pointing enhancement technique)'),(165,73,'https://www.sciencedirect.com/science/article/abs/pii/S1071581910000637','A human motor behavior model for distal pointing tasks'),(166,73,'https://www.sciencedirect.com/science/article/abs/pii/S1071581910000637','Bild 1 (A human motor behavior model for distal pointing tasks)'),(167,74,'https://doi.org/10.1016/j.ijhcs.2013.03.003','Design and evaluation of 3D selection techniques based on progressive refinement'),(168,74,'https://doi.org/10.1016/j.ijhcs.2013.03.003','Bild 1 (Design and evaluation of 3D selection techniques based on progressive refinement)'),(169,75,'https://doi.org/10.1016/j.ijhcs.2013.03.003','Design and evaluation of 3D selection techniques based on progressive refinement'),(170,75,'https://doi.org/10.1016/j.ijhcs.2013.03.003','Bild 1 (Design and evaluation of 3D selection techniques based on progressive refinement)'),(171,76,'https://www.roadtovr.com/exclusive-summoning-superpowers-designing-vr-interactions-at-a-distance','Summoning & Superpowers – Designing VR Interactions at a Distance'),(172,76,'https://www.roadtovr.com/exclusive-summoning-superpowers-designing-vr-interactions-at-a-distance','Bild 1 (Summoning & Superpowers – Designing VR Interactions at a Distance)'),(173,76,'https://www.roadtovr.com/exclusive-summoning-superpowers-designing-vr-interactions-at-a-distance','Bild 2 (Summoning & Superpowers – Designing VR Interactions at a Distance)'),(174,76,'https://www.roadtovr.com/exclusive-summoning-superpowers-designing-vr-interactions-at-a-distance','Bild 3 (Summoning & Superpowers – Designing VR Interactions at a Distance)'),(175,77,'https://doi.org/10.20380/GI2018.17','EZCursorVR: 2D Selection with Virtual Reality Head-Mounted Displays'),(176,77,'https://doi.org/10.20380/GI2018.17','Bild 1 (EZCursorVR: 2D Selection with Virtual Reality Head-Mounted Displays)'),(177,78,'https://doi.org/10.1145/3290605.3300331','RayCursor: a 3D Pointing Facilitation Technique based on Raycasting'),(178,78,'https://doi.org/10.1145/3290605.3300331','Bild 1 (RayCursor: a 3D Pointing Facilitation Technique based on Raycasting)'),(179,78,'https://doi.org/10.1145/3290605.3300331','Bild 2 (RayCursor: a 3D Pointing Facilitation Technique based on Raycasting)'),(180,79,'https://doi.org/10.1007/978-3-540-85412-8_5','Improving 3D Selection in VEs through Expanding Targets and Forced Disocclusion'),(181,79,'https://doi.org/10.1007/978-3-540-85412-8_5','Bild 1 (Improving 3D Selection in VEs through Expanding Targets and Forced Disocclusion)'),(182,80,'https://doi.org/10.1007/978-3-540-85412-8_5','Improving 3D Selection in VEs through Expanding Targets and Forced Disocclusion'),(183,80,'https://doi.org/10.1007/978-3-540-85412-8_5','Bild 1 (Improving 3D Selection in VEs through Expanding Targets and Forced Disocclusion)'),(184,81,'https://doi.org/10.1145/2525194.2525198','Mesh-Grab and Arcball-3D: Ray-based 6-DOF Object Manipulation'),(185,81,'https://doi.org/10.1145/2525194.2525198','Bild 1 (Mesh-Grab and Arcball-3D: Ray-based 6-DOF Object Manipulation)'),(186,82,'https://doi.org/10.1145/2525194.2525198','Mesh-Grab and Arcball-3D: Ray-based 6-DOF Object Manipulation'),(187,82,'https://doi.org/10.1145/2525194.2525198','Bild 1 (Mesh-Grab and Arcball-3D: Ray-based 6-DOF Object Manipulation)'),(188,83,'https://doi.org/10.1145/253284.253303','Image plane interaction techniques in 3D immersive environments'),(189,83,'https://doi.org/10.1145/253284.253303','Bild 1 (Image plane interaction techniques in 3D immersive environments)'),(190,84,'https://doi.org/10.1109/VR.2006.93','iSith - Intersection-based Spatial Interaction for Two Hands'),(191,84,'https://www.pearson.com/us/higher-education/program/La-Viola-3-D-User-Interfaces-Theory-and-Practice-2nd-Edition/PGM101825.html','3D User Interfaces: Theory and Practice, 2nd Edition'),(192,84,'https://doi.org/10.1109/VR.2006.93','Bild 1 (iSith - Intersection-based Spatial Interaction for Two Hands)'),(193,84,'https://doi.org/10.1109/VR.2006.93','Bild 2 (iSith - Intersection-based Spatial Interaction for Two Hands)'),(194,84,'https://doi.org/10.1109/VR.2006.93','Bild 3 (iSith - Intersection-based Spatial Interaction for Two Hands)'),(195,84,'https://www.pearson.com/us/higher-education/program/La-Viola-3-D-User-Interfaces-Theory-and-Practice-2nd-Edition/PGM101825.html','Bild 4 (3D User Interfaces: Theory and Practice, 2nd Edition)'),(196,85,'https://engagevr.io/','Engage'),(197,85,'#','Bild 1 (eigene Darstellung)'),(198,85,'#','Bild 2 (eigene Darstellung)'),(199,86,'http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.698.6913','The Flexible Pointer: An Interaction Technique for Augmented and Virtual Reality'),(200,86,'http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.698.6913','Bild 1 (The Flexible Pointer: An Interaction Technique for Augmented and Virtual Reality)'),(201,86,'http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.698.6913','Bild 2 (The Flexible Pointer: An Interaction Technique for Augmented and Virtual Reality)'),(202,87,'https://doi.org/10.1109/MCG.2009.117','Efficient 3D Pointing Selection in Cluttered Virtual Environments'),(203,87,'https://doi.org/10.1109/MCG.2009.117','Bild 1 (Efficient 3D Pointing Selection in Cluttered Virtual Environments)'),(204,88,'https://www.sciencedirect.com/science/article/abs/pii/0097849394900620','JDCAD. A highly interactive 3D modeling system'),(205,88,'https://www.sciencedirect.com/science/article/abs/pii/0097849394900620','Bild 1 (JDCAD. A highly interactive 3D modeling system)'),(206,88,'#','Bild 2 (eigene Darstellung)'),(207,89,'https://dl.acm.org/citation.cfm?id=2386013','IntenSelect: using dynamic object rating for assisting 3D object selection'),(208,89,'https://dl.acm.org/citation.cfm?id=2386013','Bild 1 (IntenSelect: using dynamic object rating for assisting 3D object selection)'),(209,89,'#','Bild 2 (eigene Darstellung)'),(210,90,'https://doi.org/10.1145/2534329.2534347','Guidance rays: 3D object selection based on multi-ray in dense scenario'),(211,90,'https://doi.org/10.1145/2534329.2534347','Bild 1 (Guidance rays: 3D object selection based on multi-ray in dense scenario)'),(212,91,'http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.128.148','3D Selection Strategies for Head Tracked and Non-Head Tracked Operation of Spatially Immersive Displays'),(213,91,'http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.128.148','Bild 1 (3D Selection Strategies for Head Tracked and Non-Head Tracked Operation of Spatially Immersive Displays)'),(214,92,'https://doi.org/10.1109/VR.2006.134','Towards a General Model for Selection in Virtual Environments'),(215,92,'https://doi.org/10.1109/VR.2006.134','Bild 1 (Towards a General Model for Selection in Virtual Environments)'),(216,93,'https://doi.org/10.1145/237091.237105','Aperture based selection for immersive virtual environments'),(217,93,'https://doi.org/10.1145/237091.237105','Bild 1 (Aperture based selection for immersive virtual environments)'),(218,94,'https://doi.org/10.1016/j.cag.2017.06.003','Design and evaluation of a novel out-of-reach selection technique for VR using iterative refinement'),(219,94,'https://doi.org/10.1016/j.cag.2017.06.003','Bild 1 (Design and evaluation of a novel out-of-reach selection technique for VR using iterative refinement)'),(220,95,'https://doi.org/10.1016/j.cag.2012.12.006','3D selection with freehand gesture'),(221,95,'https://doi.org/10.1016/j.cag.2012.12.006','Bild 1 (3D selection with freehand gesture)'),(222,96,'https://doi.org/10.1016/j.cag.2012.12.006','3D selection with freehand gesture'),(223,96,'https://doi.org/10.1016/j.cag.2012.12.006','Bild 1 (3D selection with freehand gesture)'),(224,97,'https://doi.org/10.1109/ISMAR.2003.1240730','SenseShapes: using statistical geometry for object selection in a multimodal augmented reality'),(225,97,'https://doi.org/10.1109/ISMAR.2003.1240730','Bild 1 (SenseShapes: using statistical geometry for object selection in a multimodal augmented reality)'),(226,98,'https://doi.org/10.1109/VR.2006.133','Toward Disambiguating Multiple Selections for Frustum-Based Pointing'),(227,98,'https://doi.org/10.1109/VR.2006.133','Bild 1 (Toward Disambiguating Multiple Selections for Frustum-Based Pointing)'),(228,99,'https://doi.org/10.1109/3DUI.2011.5759219','Rapid and accurate 3D selection by progressive refinement'),(229,99,'https://doi.org/10.1109/3DUI.2011.5759219','Bild 1 (Rapid and accurate 3D selection by progressive refinement)'),(230,99,'https://doi.org/10.1109/3DUI.2011.5759219','Bild 2 (Rapid and accurate 3D selection by progressive refinement)'),(231,100,'https://ieeexplore.ieee.org/document/6165145','Dense and dynamic 3D selection for game-based virtual environments'),(232,100,'https://ieeexplore.ieee.org/document/6165145','Bild 1 (Dense and dynamic 3D selection for game-based virtual environments)'),(233,100,'https://www.pearson.com/us/higher-education/program/La-Viola-3-D-User-Interfaces-Theory-and-Practice-2nd-Edition/PGM101825.html','Bild 2 (3D User Interfaces: Theory and Practice, 2nd Edition)'),(234,100,'#','Bild 3 (eigene Darstellung)'),(235,100,'#','Bild 4 (eigene Darstellung)'),(236,101,'https://dl.acm.org/citation.cfm?id=897822','ISAAC: A Virtual Environment Tool for the Interactive Construction of Virtual Worlds'),(237,101,'https://dl.acm.org/citation.cfm?id=897822','Bild 1 (ISAAC: A Virtual Environment Tool for the Interactive Construction of Virtual Worlds)'),(238,102,'https://doi.org/10.1145/253284.253301','An evaluation of techniques for grabbing and manipulating remote objects in immersive virtual environments'),(239,102,'#','Bild 1 (eigene Darstellung)'),(240,102,'#','Bild 2 (eigene Darstellung)'),(241,103,'https://doi.org/10.1145/253284.253301','An evaluation of techniques for grabbing and manipulating remote objects in immersive virtual environments'),(242,103,'#','Bild 1 (eigene Darstellung)'),(243,103,'#','Bild 2 (eigene Darstellung)'),(244,104,'https://doi.org/10.1145/1450579.1450585','Advantages of Velocity-Based Scaling for Distant 3D Manipulation'),(245,104,'https://doi.org/10.1145/1450579.1450585','Bild 1 (Advantages of Velocity-Based Scaling for Distant 3D Manipulation)'),(246,104,'https://doi.org/10.1145/1450579.1450585','Bild 2 (Advantages of Velocity-Based Scaling for Distant 3D Manipulation)'),(247,104,'#','Bild 3 (eigene Darstellung)'),(248,104,'#','Bild 4 (eigene Darstellung)'),(249,105,'https://doi.org/10.1145/1450579.1450585','Bild 1 (Advantages of Velocity-Based Scaling for Distant 3D Manipulation)'),(250,105,'https://doi.org/10.1145/1450579.1450585','Bild 2 (Advantages of Velocity-Based Scaling for Distant 3D Manipulation)'),(251,105,'#','Bild 3 (eigene Darstellung)'),(252,105,'#','Bild 4 (eigene Darstellung)'),(253,106,'https://www.pearson.com/us/higher-education/program/La-Viola-3-D-User-Interfaces-Theory-and-Practice-2nd-Edition/PGM101825.html','3D User Interfaces: Theory and Practice, 2nd Edition'),(254,106,'https://doi.org/10.1145/258734.258747','Moving objects in space: exploiting proprioception in virtual-environment interaction'),(255,107,'https://dl.gi.de/handle/20.500.12116/16890','Seamless Hand-Based Remote and Close Range Interaction in Immersive Virtual Environments'),(256,107,'https://dl.gi.de/handle/20.500.12116/16890','Bild 1 (Seamless Hand-Based Remote and Close Range Interaction in Immersive Virtual Environments)'),(257,107,'https://dl.gi.de/handle/20.500.12116/16890','Bild 2 (Seamless Hand-Based Remote and Close Range Interaction in Immersive Virtual Environments)'),(258,107,'https://dl.gi.de/handle/20.500.12116/16890','Bild 3 (Seamless Hand-Based Remote and Close Range Interaction in Immersive Virtual Environments)'),(259,108,'https://doi.org/10.1162/PRES_a_00207','Design Choices and Their Implications for 3D Mid-Air Manipulation Techniques'),(260,108,'https://doi.org/10.1162/PRES_a_00207','Bild 1 (Design Choices and Their Implications for 3D Mid-Air Manipulation Techniques)'),(261,109,'https://doi.org/10.1007/s11042-017-5205-9','Interaction techniques in desktop virtual environment: the study of visual feedback and precise manipulation method'),(262,109,'https://doi.org/10.1007/s11042-017-5205-9','Bild 1 (Interaction techniques in desktop virtual environment: the study of visual feedback and precise manipulation method)'),(263,110,'https://doi.org/10.1007/s11042-017-5205-9','Interaction techniques in desktop virtual environment: the study of visual feedback and precise manipulation method'),(264,110,'https://doi.org/10.1007/s11042-017-5205-9','Bild 1 (Interaction techniques in desktop virtual environment: the study of visual feedback and precise manipulation method)'),(265,111,'https://doi.org/10.1007/978-3-319-22668-2_25','An Empirical Investigation of Gaze Selection in Mid-Air Gestural 3D Manipulation'),(266,111,'https://doi.org/10.1007/978-3-319-22668-2_25','Bild 1 (An Empirical Investigation of Gaze Selection in Mid-Air Gestural 3D Manipulation)'),(267,112,'https://doi.org/10.1145/3131277.3132180','Gaze + pinch interaction in virtual reality'),(268,112,'https://doi.org/10.1145/3131277.3132180','Bild 1 (Gaze + pinch interaction in virtual reality)'),(269,113,'https://doi.org/10.1145/3131277.3132180','Gaze + pinch interaction in virtual reality'),(270,113,'https://doi.org/10.1145/3131277.3132180','Bild 1 (Gaze + pinch interaction in virtual reality)'),(271,114,'https://doi.org/10.1007/978-3-642-39405-8_23','An Asymmetric Bimanual Gestural Interface for Immersive Virtual Environments'),(272,114,'https://doi.org/10.1007/978-3-642-39405-8_23','Bild 1 (An Asymmetric Bimanual Gestural Interface for Immersive Virtual Environments)'),(273,114,'https://doi.org/10.1007/978-3-642-39405-8_23','Bild 2 (An Asymmetric Bimanual Gestural Interface for Immersive Virtual Environments)');
/*!40000 ALTER TABLE `technique_source` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `technique_subjective`
--

DROP TABLE IF EXISTS `technique_subjective`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `technique_subjective` (
  `id` int NOT NULL AUTO_INCREMENT,
  `technique_id` int DEFAULT NULL,
  `type` varchar(45) DEFAULT NULL,
  `usability` float DEFAULT NULL,
  `naturalness` float DEFAULT NULL,
  `fun` float DEFAULT NULL,
  `precision` float DEFAULT NULL,
  `speed` float DEFAULT NULL,
  `motion_sickness` float DEFAULT NULL,
  `nasa_workload` float DEFAULT NULL,
  `nasa_mental_demand` float DEFAULT NULL,
  `nasa_physical_demand` float DEFAULT NULL,
  `nasa_performance` float DEFAULT NULL,
  `nasa_effort` float DEFAULT NULL,
  `nasa_frustration` float DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=19 DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `technique_subjective`
--

LOCK TABLES `technique_subjective` WRITE;
/*!40000 ALTER TABLE `technique_subjective` DISABLE KEYS */;
INSERT INTO `technique_subjective` VALUES (1,17,'selection',76.5,3.5,3.3,3.3,4.3,1.2,8.02,4.4,13.5,6.3,12.4,3.5),(2,13,'selection',57,2.9,3,3,3.1,1.1,10.68,9.2,13.3,8.9,14.2,7.8),(3,100,'selection',85,2.6,4.2,4.2,4,1,4.96,5.1,4,6.4,6.2,3.1),(4,85,'selection',76.25,3.1,3.7,3.7,2.8,1.6,8.34,3.3,7.9,10.5,11.3,8.7),(5,21,'selection',67.5,2.7,4.1,4.1,4,1.4,8.36,10.8,8.4,6.1,12.1,4.4),(6,105,'selection',76.5,3.5,3.6,3.6,3.4,1.2,8.64,7,9.3,9.1,10.8,7),(7,89,'selection',86.5,3.1,4.4,4.4,4.4,1.5,4.88,3.3,5.2,5.8,6.9,3.2),(8,57,'selection',83.75,3.5,3.6,3.6,3.6,1.6,6.68,4.3,7.1,6.3,11.1,4.6),(9,88,'selection',91.5,3,4.2,4.2,3.6,1.2,4.7,4.6,4.4,5.2,6.1,3.2),(10,1,'selection',90.75,4.4,4.4,4.4,3.9,1.2,6.58,4.3,10.5,5.8,9,3.3),(11,17,'manipulation',87,3.9,4.7,4.1,4.4,1.1,5.98,6.5,7.6,5.7,7.2,2.9),(12,13,'manipulation',61.1364,3,3.45455,3.09091,3,1.63636,10.1818,9.90909,10.9091,9.09091,13.0909,7.90909),(13,25,'manipulation',30.2273,1.63636,1.90909,1.72727,1.81818,1.63636,13.3455,14.6364,12.1818,11.8182,14.8182,13.2727),(14,85,'manipulation',63.5,3,3.4,3.3,3.5,1.4,9.32,12.2,6.5,8.5,11.9,7.5),(15,21,'manipulation',64,2.6,4.1,3.5,3.8,1.5,8.32,11.9,6.5,8.2,10.4,4.6),(16,105,'manipulation',74,3.2,3.8,4,3.8,1.3,7.86,8.3,8.7,5.7,11.6,5),(17,104,'manipulation',58.25,3,3.2,2.9,3.2,1.4,9.18,7.6,10.8,7.7,11.6,8.2),(18,1,'manipulation',95.8333,4.33333,4.16667,4.25,4.66667,1.41667,5.16667,3.41667,7.91667,4.08333,8.66667,1.75);
/*!40000 ALTER TABLE `technique_subjective` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `techniques_new`
--

DROP TABLE IF EXISTS `techniques_new`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `techniques_new` (
  `id` int NOT NULL,
  `name` mediumtext,
  `description` longtext,
  `description_short` longtext,
  `description_study` longtext,
  `metaphor` varchar(45) DEFAULT NULL,
  `tasks` varchar(45) DEFAULT NULL,
  `constraints` mediumtext,
  `visual_feedback` longtext,
  `reach` varchar(45) DEFAULT NULL,
  `two_handedness` varchar(45) DEFAULT NULL,
  `tracked_body_parts` varchar(45) DEFAULT NULL,
  `minimum_dof` mediumtext,
  `maximum_dof` mediumtext,
  `minimum_dof_short` varchar(45) DEFAULT NULL,
  `maximum_dof_short` varchar(45) DEFAULT NULL,
  `one_d_input` mediumtext,
  `one_d_input_short` int DEFAULT NULL,
  `transformation_separation` varchar(45) DEFAULT NULL,
  `transformation_separation_short` varchar(45) DEFAULT NULL,
  `selection_mapping` varchar(45) DEFAULT NULL,
  `position_mapping` varchar(45) DEFAULT NULL,
  `rotation_mapping` varchar(45) DEFAULT NULL,
  `scaling_mapping` varchar(45) DEFAULT NULL,
  `progressive_refinement` varchar(45) DEFAULT NULL,
  `disambiguation_mechanism` varchar(45) DEFAULT NULL,
  `selection_indication` varchar(45) DEFAULT NULL,
  `release_indication` varchar(45) DEFAULT NULL,
  `fidelity_comparing_metaphor` mediumtext,
  `fidelity_kinematic` mediumtext,
  `fidelity_kinetic` mediumtext,
  `fidelity_anthropometric` mediumtext,
  `fidelity_dimensional` mediumtext,
  `fidelity_transfer` mediumtext,
  `fidelity_termination` mediumtext,
  `fidelity_overall_short` float DEFAULT NULL,
  `fidelity_kinematic_short` int DEFAULT NULL,
  `fidelity_kinetic_short` int DEFAULT NULL,
  `fidelity_anthropometric_short` int DEFAULT NULL,
  `fidelity_dimensional_short` int DEFAULT NULL,
  `fidelity_transfer_short` int DEFAULT NULL,
  `fidelity_termination_short` int DEFAULT NULL,
  `fidelity_overall` varchar(45) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `techniques_new`
--

LOCK TABLES `techniques_new` WRITE;
/*!40000 ALTER TABLE `techniques_new` DISABLE KEYS */;
INSERT INTO `techniques_new` VALUES (1,'Simple Virtual Hand','The virtual hand technique maps the movements of the real hand to a virtual representation. The virtual representation can be displayed as a human hand, a controller, or a simple geometrical object. An object can be selected by intersecting the virtual hand with the object and pressing a button. A similar technique is the Finger-based Virtual Hand, where not only the hand is tracked but also the fingers.','Creates a virtual representation of the real hand to allow a direct and natural interaction','The technique was implemented by displaying a virtual counterpart of the controller in VR in the same position. A small grey sphere at the top of the controller used as a selection point. Therefore, the participants could not use the whole controller to select objects. SteamVR, the framework we have built upon, inherently uses a simple disambiguation mechanism if the selection volume touches multiple selectable objects. In such cases, the object closest to the center of the selection volume is considered as the target object.','Grasping/Hand-based','Selection\nPositioning\nRotation','None','3D cursor (virtual hand)','Arm-length','Single-handed','Hand ','(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','1 Button (Selection)',1,'{P,R}','None','Isomorph','Isomorph','Isomorph','None','None','None','On Button Press','On Button Release','Grab, move and rotate an object with one hand','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand (no fingers)','(Px, Py, Pz, Rx, Ry, Rz)','1:1 position-to-position \n1:1 orientation-to-orientation','Release button',4.5,4,5,4,5,5,4,'High'),(2,'PRISM','PRISM is an extension of the simple virtual hand technique and uses a virtual representation of the real hand. If the real hand moves slowly, the velocity of the virtual representation is even more reduced. This allows for precise movements. The changed Control-Display Ratio can lead to an offset between the real hand and the virtual representation. Fast movements can resolve this offset.','Reduces the velocity of the virtual representation of the real hand on slow movements to increase the precision',NULL,'Grasping/Hand-based','Selection\nPositioning\nRotation','None','3D cursor (virtual hand)','Arm-length','Single-handed','Hand ','(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','1 Button (Selection)',1,'{P,R}','None','Velocity-oriented','Velocity-oriented','Velocity-oriented','None','None','None','On Button Press','On Button Release','Grab, move and rotate an object with one hand','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand (no fingers)','(Px, Py, Pz, Rx, Ry, Rz)','1:N position-to-position \n1:N orientation-to-orientation','Release button',4,4,5,4,5,2,4,'Mid-high'),(3,'DIOD','Dynamic Decomposition and Integration of Degrees of Freedom (DIOD) allows the positioning of objects on all three axes if the hand moves quickly. If the user moves the hand slowly, the technique progressively constrains the manipulation of the object from three to two and finally to one dimension, based on the velocity of the displacement regarding each dimension. ','Reduces the positioning of an object to one degree of freedom on slower movements',NULL,'Grasping/Hand-based','Selection\nPositioning','DoF reduction','3D cursor (virtual hand)','Arm-length','Single-handed','Hand ','(x, y, z)','(x, y, z)','Position','Position','1 Button (Selection)',1,'{P}, {Px}, {Py}, {Pz}','Full','Isomorph','Velocity-oriented','None','None','None','None','On Button Press','On Button Release','Grab, move and rotate an object with one hand','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand (no fingers)','(Px, Py, Pz), (Px), (Py), (Py)','1:N position-to-position ','Release button',3.66667,4,5,4,3,2,4,'Mid-high'),(4,'Hook','This technique supports the user in selecting moving objects. For each possible target, scores are calculated according to the distance between the cursor and the object. A list containing the closest targets over time is generated. The target with the highest score is highlighted by a cone originating from the cursor and ending at the target. Additionally, a bounding box enlarges the object.','Supports in selecting moving objects by heuristic calculations',NULL,'Grasping/Hand-based','Selection','Snap to object','3D cursor (point cursor) \nTarget highlighting (semi-transparent cone from cursor to target,  semi-transparent enlarged bounding box of target, change of color)','Arm-length','Single-handed','Hand ','(x, y, z)','(x, y, z)','Position','Position','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','Continuously','Behavioural','On Button Press','None','Grab an object with one hand','Move upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand (no fingers)','(Px, Py, Pz)','1:1 position-to-position ','Release button',4.33333,4,5,4,4,5,4,'Mid-high'),(5,'Starfish','The user controls the head of a starfish cursor like a 3D pointer. The branches of the starfish are dynamically rebuilt and move to nearby objects. The user can lock the cursor by pressing a button. Now the head can be moved by the user constrained by the surface of the starfish. If the head moves deeper into a branch the corresponding object can be selected.','A cursor in the form of a starfish with branches moving to nearby objects supports the selection of objects',NULL,'Grasping/Hand-based','Selection','Snap to object,\nDoF reduction','3D cursor (starfish)\nAdditional cursor (point cursor in starfish)\nAdopting cursor (branches of the starfish connect with the potential targets)','Arm-length','Single-handed','Hand ','(x, y, z)','(x, y, z)','Position','Position','1 Button (Selection)\n1 Button (Move Mode)',2,'-','None','Isomorph','None','None','None','Discrete/Multiple steps','Manual','On Button Press','None','Grab an object with one hand','Move upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand (no fingers)','(Px, Py, Pz)','1:1 position-to-position ','Release button',4.33333,4,5,4,4,5,4,'Mid-high'),(6,'3D Bubble Cursor','This technique is based on the virtual hand technique and uses a 3D bubble as a cursor. The radius of the cursor automatically resizes so that the bubble encapsulates only the nearest object. A second sphere highlights the target by surrounding it.','A 3D bubble cursor automatically resizes, so only one object is targeted at a time. ',NULL,'Grasping/Hand-based','Selection','Snap to object','3D cursor (sphere)\nAdopting cursor (dynamically resizing sphere such that only closest target is captured)\nTarget highlighting (semi-transparent sphere around target, change of color)','Arm-length','Single-handed','Hand ','(x, y, z)','(x, y, z)','Position','Position','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','Discrete/Single step','Heuristic','On Button Press','None','Grab an object with one hand','Move upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand (no fingers)','(Px, Py, Pz)','1:1 position-to-position ','Release button',4.33333,4,5,4,4,5,4,'Mid-high'),(7,'Virtual Handle with a Grabbing Metaphor','When the user triggers the selection of an object, an outer bounding sphere is generated around the object. The position of a virtual handle is determined by the intersection point of the ray originating from the hand and the outer bounding sphere. The position of the virtual handle solves as the center of manipulation. However, a second inner bounding sphere is generated to allow for a guided adjustment of the virtual rays between both bounding spheres. ','Allows for precise placement of the grabbing position (center of manipulation) on the bounding sphere of the object',NULL,'Grasping/Hand-based','Selection\nPositioning\nRotation','None','3D cursor (virtual hand)','Arm-length','Single-handed','Hand ','(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','1 Button (Selection)',1,'{P,R}','None','Isomorph','Isomorph','Isomorph','None','None','None','On Button Press','On Button Press','Grab, move and rotate an object with one hand','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand (no fingers)','(Px, Py, Pz, Rx, Ry, Rz)','1:1 position-to-position \n1:1 orientation-to-orientation','Release button',4.5,4,5,4,5,5,4,'High'),(8,'Select Ahead','This technique extends the virtual hand metaphor with a target prediction. While the cursor is approaching the target, the direction of the recent cursor movements shows a tendency oriented towards the target. Based on this tendency, the target object is predicted, and the user can select it before touching it. ','Uses the tendency of recent cursor movements to predict the target object for selection',NULL,'Grasping/Hand-based','Selection','Snap to object','3D cursor (point cursor) \nAdopting cursor (arrow indicating the tendency of recent cursor movements)\nTarget highlighting (change of color)','Arm-length','Single-handed','Hand ','(x, y, z)','(x, y, z)','Position','Position','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','Discrete/Single step','Heuristic','On Button Press','None','Grab an object with one hand','Move upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand (no fingers)','(Px, Py, Pz)','1:1 position-to-position ','Release button',4.33333,4,5,4,4,5,4,'Mid-high'),(9,'AutoWidth','This technique utilizes the transition from the ballistic phase (movements over greater distances) to the corrective phase (smaller precise movements) during a selection task. The target is predicted by the hand movements and expands to a fixed size to support the selection.','Expands the 3D target to a fixed size during the corrective phase of the aimed movement',NULL,'Grasping/Hand-based','Selection','Snap to object','3D cursor (point cursor) \nTarget highlighting (change of size)','Arm-length','Single-handed','Hand ','(x, y, z)','(x, y, z)','Position','Position','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','Discrete/Single step','Heuristic','On Button Press','None','Grab an object with one hand','Move upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand (no fingers)','(Px, Py, Pz)','1:1 position-to-position ','Release button',4.33333,4,5,4,4,5,4,'Mid-high'),(10,'AutoDistance','This technique utilizes the transition from the ballistic phase (movements over greater distances) to the corrective phase (smaller precise movements) during a selection task. The target is predicted by the hand movements, and the cursor is dragged toward the predicted 3D target and snaps to its center immediately after ending the ballistic phase.','The cursor is dragged toward the predicted 3D target and snaps to its center immediately after the end of the ballistic phase',NULL,'Grasping/Hand-based','Selection','Snap to object','3D cursor (point cursor) ','Arm-length','Single-handed','Hand ','(x, y, z)','(x, y, z)','Position','Position','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','Discrete/Single step','Heuristic','On Button Press','None','Grab an object with one hand','Move upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand (no fingers)','(Px, Py, Pz)','1:1 position-to-position ','Release button',4.33333,4,5,4,4,5,4,'Mid-high'),(11,'Go-Go','The Go-Go technique divides the space around the user into two parts. The area close to the user maps the movements of the real hand isomorphic to a virtual hand similar to the Simple Virtual Hand technique. In the outer area, the mapping is non-isomorph, and the user can interact with objects on a greater distance.','Extends the arm exponentially at a particular distance from the user to allow the interaction on a greater distance',NULL,'Grasping/Hand-based','Selection\nPositioning\nRotation','None','3D cursor (virtual hand)','Scaled','Single-handed','Hand ','(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','1 Button (Selection)',1,'{P,R}','None','Area-oriented','Area-oriented','Isomorph','None','None','None','On Button Press','On Button Release','Grab, move and rotate an object with one hand','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand (no fingers)','(Px, Py, Pz, Rx, Ry, Rz)','1:N position-to-position \n1:1 orientation-to-orientation','Release button',4.16667,4,5,4,5,3,4,'Mid-high'),(12,'Stretch Go-Go','“The space around the user is divided into three concentric regions, such that the user’s natural hand position is in the middle region. When the user stretches her hand out so that it lies in the outermost region, the arm begins to grow at a constant speed. If the arm is brought back into the innermost region, it retracts at that speed. In the middle region the arm length remains the same. Thus, physical hand position is mapped to virtual hand velocity, with three discrete velocities available. Using this technique, any arm length can be obtained.” [1]','The length of the arm is controlled by placing the hand in one of three regions around the user',NULL,'Grasping/Hand-based','Selection\nPositioning\nRotation','None','3D cursor (virtual hand)\nWidgets (Gauge visualizing the current region)','Infinite','Single-handed','Hand ','(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','1 Button (Selection)',1,'{P,R}','None','Remapped','Remapped','Isomorph','None','None','None','On Button Press','On Button Release','Grab, move and rotate an object with one hand','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand (no fingers)','(Px, Py, Pz, Rx, Ry, Rz)','1:N position-to-position \n1:1 orientation-to-orientation','Release button',4.16667,4,5,4,5,3,4,'Mid-high'),(13,'Go-Go + PRISM','This technique applies the Go-Go technique to increase the reach of the user. Therefore the space around the user is divided into two parts. The area close to the user maps the movements of the real hand isomorphic to a virtual hand similar to the Simple Virtual Hand technique. In the outer area, the mapping is non-isomorph, and the user can interact with objects on a greater distance. Additionally, PRISM is applied to the virtual hand position calculated by the Go-Go transfer function. If the real hand moves slowly, the velocity of the virtual representation is even more reduced. The goal is to increase the precision of slow hand movements as the Go-Go mapping drastically increases the input sensibility on greater distances.  ','Uses the Go-Go technique to extend the reach and PRISM to increase the precision','According to the definition of the technique (see source 1), the PRISM scaling is only applied to positional changes and not to rotational changes like it is done in the original PRISM technique. The Go-Go technique depends on the arm length of the user. Therefore, an initialization phase is needed where the user fully extends his arm. The Go-Go transfer function normally is applied according to the distance between the hand and the chest. However, with current VR-Systems the chest position can only be derived with the help of the head position. This results in the problem that small head movements influence the distance between head and hand and lead to unwanted positional changes of the virtual hand. In our implementation, the chest position is fixed after the initialization phase. Therefore, the user should move as little as possible which is not feasible for actual VR applications. The velocity of the hand is calculated by taking the difference of the current hand position and the hand position 0.5 seconds earlier. Following PRISM values were used: MinS = 0.001 m/s, SC = 0.3 m/s, and MaxS = 0.5 m/s. For GoGo k was calculated in dependence of the user\'s arm length so that every user was able to reach objects at a maximum distance of 720 cm. D was set to 2/3.','Grasping/Hand-based','Selection\nPositioning\nRotation','None','3D cursor (virtual hand)','Scaled','Single-handed','Hand ','(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','1 Button (Selection)',1,'{P,R}','None','Area-oriented, \nVelocity-oriented','Area-oriented, \nVelocity-oriented','Isomorph','None','None','None','On Button Press','On Button Release','Grab, move and rotate an object with one hand','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand (no fingers)','(Px, Py, Pz, Rx, Ry, Rz)','1:N position-to-position \n1:N orientation-to-orientation','Release button',4,4,5,4,5,2,4,'Mid-high'),(14,'Go-Go + Follow-Me','“The virtual environment is divided into three zones (free manipulation zone, scaled manipulation zone and precise manipulation zone). Each object of virtual environment which may be selected or manipulated has its own scaled manipulation zone and precise manipulation zone which are volumes surrounding the object.” [1] In the free manipulation zone, no adoptions are made to the mapping function. In the scaled manipulation zone, greater movements are translated to smaller movements. In the precise manipulation zone, the cursor is dragged to the object. Any technique can be used together with Follow-Me. In this case, the Go-Go technique was used.','Drags the cursor to a nearby object by using three zones around objects with different mappings',NULL,'Grasping/Hand-based','Selection\nPositioning\nRotation','DoF reduction','3D cursor (virtual hand)','Scaled','Single-handed','Hand ','(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','1 Button (Selection)',1,'{P,R}','None','Area-oriented,\nTarget-oriented','Area-oriented,\nTarget-oriented','Isomorph','None','None','None','On Button Press','On Button Release','Grab, move and rotate an object with one hand','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand (no fingers)','(Px, Py, Pz, Rx, Ry, Rz)','1:N position-to-position \n1:1 orientation-to-orientation','Release button',4.16667,4,5,4,5,3,4,'Mid-high'),(15,'Indirect Stretching','The arm can be stretched or retracted by using two buttons.','The arm can be stretched or retracted by using two buttons',NULL,'Grasping/Hand-based','Selection\nPositioning\nRotation','None','3D cursor (virtual hand)','Infinite','Single-handed','Hand ','(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','1 Button (Selection)\n2 Buttons (Arm Length)',3,'{P,R}','None','Remapped','Remapped','Isomorph','None','None','None','On Button Press','On Button Release','Grab, move and rotate an object with one hand','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry, Rz)','1:N position-and-1DInput-to-position \n1:1 orientation-to-orientation','Release button',4.16667,4,5,4,5,3,4,'Mid-high'),(16,'Extender Grab','“Changes in orientation of the user\'s hand are applied 1:1 to the object\'s orientation. Translations are scaled by a factor which depends upon the distance of the object from the user at the start of the grab. The further away the object, the larger the scale factor. By automatically setting the scale factor based on object distance, extender grab enables a large dynamic range of manipulation. No matter how far away an object lies, it can be brought to the user\'s side in a single operation.” [1]','Allows the interaction on long distances by using a scale factor for the mapping, which depends on the object distance',NULL,'Grasping/Hand-based','Positioning\nRotation','None','3D cursor (virtual hand)','Scaled','Single-handed','Hand ','(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','1 Button (Selection)',1,'{P,R}','None','None','Target-oriented','Isomorph','None','None','None','On Button Press','On Button Release','Grab, move and rotate an object with one hand','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand (no fingers)','(Px, Py, Pz, Rx, Ry, Rz)','1:N position-to-position \n1:1 orientation-to-orientation','Release button',4.16667,4,5,4,5,3,4,'Mid-high'),(17,'Spindle','The center between the two hands serves as the selection point. Pressing a button on both controllers simultaneously grabs the object. Moving the hands in the same direction positions the object, rotating the hands around each other rotates the objects, and moving the hands apart or together scales the object. A rotation around the axis between both hands is not possible.','Uses a sphere between both hands to select an object, and the movements of the hands allow to change the translation, rotation, and scale of the object','The implementation of the technique used in the study connects the two controllers with a white ray. The center of the ray marked with a small red sphere serving as the selection point. If this sphere touches an object, it can be selected by pressing the trigger of both controllers. While pressing the triggers moving the hands in the same direction positions the object, rotating the hands around each other rotates the objects, and moving the hands apart or together scales the object. A rotation around the axis between both hands is not possible. However, cycling movements with both controllers can be used to rotate the object around this axis.','Grasping/Hand-based','Selection\nPositioning\nRotation\nScaling','None','3D cursor (point cursor) ','Arm-length','Symmetric-synchron','First Hand \nSecond Hand ','(x, y, z)\n(x, y, z)','(x, y, z)\n(x, y, z)','Position','Position','2 Buttons (Selection)',2,'{P,Ryz,S}','None','Isomorph','Isomorph','Remapped','Distance','None','None','On Button Press','On Button Release','Grab, move, rotate and scale an object with two hands','Move and twist upper arms, forearms, and hands (no fingers)','Moderate muscle forces','Upper arms, forearms, and hands (no fingers)','(Px, Py, Pz, Ry, Rz, S)','1:1 position-to-position \n1:1 position-to-orientation (no Rx)\n1:1 distance-to-scale','Release button',4.16667,4,5,4,4,4,4,'Mid-high'),(18,'Spindle + Wheel','The center between the two hands serves as the selection point. Pressing a button on both controllers simultaneously grabs the object. Moving the hands in the same direction positions the object, rotating the hands around each other rotates the objects, and moving the hands apart or together scales the object. A rotation around the axis between both hands is possible by rotating the controller in the primary hand.','Uses a sphere between both hands to select an object, and the movements of the hands allow to change the translation, rotation, and scale of the object',NULL,'Grasping/Hand-based','Selection\nPositioning\nRotation\nScaling','None','3D cursor (point cursor) ','Arm-length','Asymmetric-synchron','First Hand \nSecond Hand ','(x, y, z)\n(x, y, z, rX)','(x, y, z)\n(x, y, z, rX)','Position\nRotation','Position\nRotation','2 Buttons (Selection)',2,'{P,R,S}','None','Isomorph','Isomorph','Isomorph, Remapped','Distance','None','None','On Button Press','On Button Release','Grab, move, rotate and scale an object with two hands','Move and twist upper arms, forearms, and hands (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand (no fingers)','(Px, Py, Pz, Rx, Ry, Rz, S)','1:1 position-to-position \n1:1 position-to-orientation (Ryz)\n1:1 orientation-to-orientation (Rx) \n1:1 distance-to-scale','Release button',4.16667,4,5,4,5,3,4,'Mid-high'),(19,'World In Miniature','The user holds a miniature model of the virtual environment in one of his hands. The other hand can manipulate the miniature objects. The changes are mapped to the actual objects in the virtual environment. The user can also move around by changing the position of a representation of him in the miniature model. ','One hand holds a miniature model of the virtual environment, and the other hand can interact with the miniature objects',NULL,'Grasping/Hand-based','Selection\nPositioning\nRotation','None','3D cursor (virtual hand)\nProxy objects (Miniature model of the virtual world)','Scaled','Asymmetric-synchron','First Hand \nSecond Hand ','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','1 Button (Selection)',1,'{P,R}','None','Remapped','Remapped','Remapped','None','None','None','On Button Press','On Button Release','Grab, move and rotate an object with one hand','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry, Rz)','1:1 proxy-position-to-position \n1:1 proxy-orientation-to-orientation','Release button',4.16667,4,5,4,5,3,4,'Mid-high'),(20,'Scaled Scrolling World In Miniature','The user holds a miniature model of the virtual environment in one of his hands. The other hand can manipulate the miniature objects. The changes are mapped to the actual objects in the virtual environment. Zooming is possible with a scroll wheel. The user can also move around by changing the position of a representation of him in the miniature model. Scrolling is possible by moving the user representation to an edge of the miniature model.','Allows the indirect interaction with the virtual objects through a miniature model (WIM). Additionally, it allows scaling and scrolling of the WIM',NULL,'Grasping/Hand-based','Selection\nPositioning\nRotation','None','3D cursor (point cursor)\nWidget (Arrow indicating the scrolling direction)','Infinite','Asymmetric-synchron','First Hand \nSecond Hand ','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','1 Button (Selection)\n1 Scrollwheel (Scale)',2,'{P,R}','None','Remapped','Remapped','Remapped','None','None','None','On Button Press','On Button Release','Grab, move and rotate an object with one hand','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry, Rz)','1:1 proxy-position-to-position \n1:1 proxy-orientation-to-orientation','Release button',4.16667,4,5,4,5,3,4,'Mid-high'),(21,'Scaled Scrolling World In Miniature + Scale','The user holds a miniature model of the virtual environment in one of his hands. The other hand can manipulate the miniature objects. The changes are mapped to the actual objects in the virtual environment. Zooming is possible by moving the thumb up or downwards on the touchpad. The miniature model can be moved by grabbing somewhere in the bounds of the model and moving the controller in the desired direction. Objects can be indirectly scaled by scaling the world while an object is grabbed. During this action, the size of the miniature model of the object does not change, which indirectly changes the size of the actual object.','Allows the indirect interaction with the virtual objects through a miniature model (WIM). Additionally, it allows scaling and scrolling of the WIM and scaling of objects','The implementation of the technique used in the study creates a miniature model of the environment in the secondary hand with a size of 50x50x50 cm. The bounds of the model are marked with white lines. The user can move the environment in the model by pressing and holding the trigger of the primary controller while the controller is inside of the bounds and then moving the controller in the desired direction. The floor of the miniature environment is anchored to the bottom of the model. The size of the model can be changed by moving the thumb upwards or downwards on the touchpad of the secondary controller. If the primary controller is inside the bounds of the model then the selection point (small grey sphere at the top of the controller) is considered as the center of scaling. Objects can be selected and moved by pressing and holding the trigger of the primary controller when the selection point touches an object. An object can be scaled by moving the thumb upwards or downwards on the touchpad of the secondary controller while the object is grabbed.','Grasping/Hand-based','Selection\nPositioning\nRotation\nScaling','None','3D cursor (point cursor)\nWidget (Arrow indicating the scrolling direction)','Infinite','Asymmetric-synchron','First Hand \nSecond Hand ','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','1 Button (Selection)\n1 Scrollwheel (Scale)',2,'{P,R}, {P,R,S}','Partial','Remapped','Remapped','Remapped','Remapped','None','None','On Button Press','On Button Release','Grab, move and rotate an object with one hand','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry, Rz), (Px, Py, Pz, Rx, Ry, Rz, S)','1:1 proxy-position-to-position \n1:1 proxy-orientation-to-orientation\n1:N 1DInput-to-scale','Release button',3.83333,4,5,4,4,2,4,'Mid-high'),(22,'Third Arm (Head)','Uses a longer third arm which originates at the center of the body and which is controlled by head movements.','Uses a longer third arm which originates at the center of the body and which is controlled by head movements',NULL,'Grasping/Hand-based','Selection','None','3D cursor (virtual hand)\nTarget highlighting (change of color)','Scaled','Asymmetric-synchron','First Hand \nSecond Hand \nHead','(x, y, z)\n(x, y, z)\n(x, y, z, rX, rY)','(x, y, z)\n(x, y, z)\n(x, y, z, rX, rY)','Position\nRotation','Position\nRotation','None',0,'-','None','Isomorph,\nRemapped','None','None','None','None','None','Dwell','None','Grab an object with one hand','Move upper arm, forearm, and hand (no fingers) and twist head','Moderate muscle forces','Upper arm, forearm, hand, and head','(Px, Py, Pz), Rotation','1:1 position-to-position \n1:1 orientation-to-position','None',2.5,2,5,2,2,3,1,'Moderate'),(23,'Third Arm (Unimanual)','Uses a longer third arm which originates at the center of the body and which is controlled by one of the hands.','Uses a longer third arm which originates at the center of the body and which is controlled by one of the hands',NULL,'Grasping/Hand-based','Selection','None','3D cursor (virtual hand)\nTarget highlighting (change of color)','Scaled','Asymmetric-synchron','First Hand \nSecond Hand \nHead','(x, y, z, rX)\n(x, y, z, rY)\n(x, y, z)','(x, y, z, rX)\n(x, y, z, rY)\n(x, y, z)','Position\nRotation','Position\nRotation','None',0,'-','None','Isomorph,\nRemapped','None','None','None','None','None','Dwell','None','Grab an object with one hand','Move upper arm and forearm and move and partially twist hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz), Rotation','1:1 position-to-position \n1:1 orientation-to-position','None',3,3,5,4,2,3,1,'Moderate'),(24,'Third Arm (Bimanual)','Uses a longer third arm which originates at the center of the body and which is controlled by both hands after a button is pressed. One arm controls the vertical movement of the third arm and the other arm controls the horizontal movements. ','Uses a longer third arm which originates at the center of the body and which is controlled by both hands',NULL,'Grasping/Hand-based','Selection','None','3D cursor (virtual hand)\nTarget highlighting (change of color)','Scaled','Asymmetric-synchron','First Hand \nSecond Hand \nHead','(x, y, z, rX, rY)\n(x, y, z)\n(x, y, z)','(x, y, z, rX, rY)\n(x, y, z)\n(x, y, z)','Position\nRotation','Position\nRotation','None',0,'-','None','Isomorph,\nRemapped','None','None','None','None','None','Dwell','None','Grab an object with one hand','Move upper arm and forearm and move and partially twist hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz), Rotation','1:1 position-to-position \n1:1 orientation-to-position','None',3,3,5,4,2,3,1,'Moderate'),(25,'Crank Handle (Controller)','The user can translate an object after pressing and holding a button. Releasing and pressing the button again switches to the rotation mode, where rotations on the three primarily axes are possible by moving the hand around the particular axis. The movements feel like turning a crank. To visually support the user, a bar is visible in the translation mode. In rotation mode, three crank handles are visible. One for each axis. Only the crank handle representing the axis the user currently rotates around is opaque. This technique das not directly support selection tasks as no object can be targeted.','Allows separated translation and rotation on each axis. Rotation is possible by rotating the hand around a primary axis like using a crank handle','The implementation of the technique used in the study displays a semi-transparent bar at the side of the object (left side for left-hander and right side for right-hander). Pressing and holding the trigger makes the bar opaque and the object can be moved according to the movements of the hand. Releasing the trigger and pressing it again in a time window of 0.6 seconds activates the rotation mode. Three semi-transparent crank handles, one for each axis, are displayed instead of the bar. If the hand rotates around one of these axes the object rotates accordingly. Releasing the trigger releases the object.','Grasping/Hand-based','Positioning\nRotation','DoF reduction','3D cursor (point cursor) \nWidget (bar on one side of the object indicating the current mode)','Infinite','Single-handed','Hand','(x, y, z)','(x, y, z)','Position','Position','1 Button (Selection)',1,'{P}, {Rx}, {Ry}, {Rz}','Full','None','Isomorph','Remapped','None','None','None','On Button Press','On Button Release','Grab and move an object with one hand and rotate it with the help of crank handles','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz), (Rx), (Ry), (Rz)','1:1 position-to-position \n1:1 position-to-orientation (constrained)','Release button',4.5,4,5,4,5,5,4,'High'),(26,'Hover (Selection)','“This technique is based on the idea that the user will focus her/his attention on an object when s/he wishes to select it. When the user wishes to select an object s/he needs to hover with the virtual hand over that object. A timer will appear and, once emptied, the object will be selected. When the virtual hand intercepts a selectable object a “pre-counter” is started, introduced to avoid the “Midas Touch” effect […]. This allows the user to freely move the virtual hand without actually triggering many visual timers all the time.” [1]','Allows the selection of objects by hovering over them',NULL,'Grasping/Hand-based','Selection','None','3D cursor (virtual hand)','Arm-length','Single-handed','Hand ','(x, y, z)','(x, y, z)','Position','Position','None',0,'-','None','Isomorph','None','None','None','None','None','Dwell','None','Grab an object with one hand','Move upper arm and forearm and move and partially twist hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand (no fingers)','(Px, Py, Pz)','1:1 position-to-position ','Move hand away',4,3,5,4,4,5,3,'Mid-high'),(27,'Hover (Manipulation)','“This technique is based on the idea that the user will focus her/his attention on an object when s/he wishes to select it. When the user wishes to select an object s/he needs to hover with the virtual hand over that object. A timer will appear and, once emptied, the object will be selected. When the virtual hand intercepts a selectable object a “pre-counter” is started, introduced to avoid the “Midas Touch” effect […]. This allows the user to freely move the virtual hand without actually triggering many visual timers all the time.” [1] The object is released if both hands are crossed.','Allows the selection of objects by hovering over them and the release of objects by crossing both hands',NULL,'Grasping/Hand-based','Selection\nPositioning\nRotation','None','3D cursor (virtual hand)','Arm-length','Asymmetric-synchron','First Hand \nSecond Hand ','(x, y, z, rX, rY)\n(x, y, z)','(x, y, z, rX, rY)\n(x, y, z)','Position\nRotation','Position\nRotation','None',0,'{P,R}','None','Isomorph','Isomorph','Isomorph','None','None','None','Dwell','Gesture','Grab, move and rotate an object with one hand','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand (no fingers)','(Px, Py, Pz, Rx, Ry, Rz)','1:1 position-to-position \n1:1 orientation-to-orientation','Gesture',4.33333,4,5,4,5,5,3,'Mid-high'),(28,'Push','“The idea for this technique came from having a virtual plane in front of the user […]. The user stretches her/his arm and, once it passes a certain threshold, the selection is triggered. The user must then withdraw her/his arm and may interact with the object. To release the object s/he repeats the gesture. The gesture of stretching the arm is detected through the arm’s angle, more specifically the angle between the vectors formed by the elbow to the wrist and the elbow to the shoulder […]. Once the angle reaches a pre-established limit, the system activates the selection (or de-selection).” [1]','Allows the selection of objects by a push gesture',NULL,'Grasping/Hand-based','Selection\nPositioning\nRotation','None','3D cursor (virtual hand)','Arm-length','Single-handed','Hand\nForearm\nUpper Arm','(x, y, z, rX, rY)\n(x, y, z)\n(x, y, z)','(x, y, z, rX, rY)\n(x, y, z)\n(x, y, z)','Position\nRotation','Position\nRotation','None',0,'{P,R}','None','Isomorph','Isomorph','Isomorph','None','None','None','Gesture','Gesture','Grab, move and rotate an object with one hand','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand (no fingers)','(Px, Py, Pz, Rx, Ry, Rz)','1:1 position-to-position \n1:1 orientation-to-orientation','Gesture',4.33333,4,5,4,5,5,3,'Mid-high'),(29,'Hold','“The idea for this technique came from having a virtual plane in front of the user […]. The user stretches her/his arm and, once it passes a certain threshold, the selection is triggered. The user must then withdraw her/his arm and may interact with the object. To release the object s/he repeats the gesture. The gesture of stretching the arm is detected through the arm’s angle, more specifically the angle between the vectors formed by the elbow to the wrist and the elbow to the shoulder […]. Once the angle reaches a pre-established limit, the system activates the selection […]. [The user] must maintain the arm stretched during the interaction. De-selection is done by withdrawing the arm. ” [1]','Allows the selection of objects by a push gesture and the arm needs to stay stretched during the interaction',NULL,'Grasping/Hand-based','Selection\nPositioning\nRotation','None','3D cursor (virtual hand)','Arm-length','Single-handed','Hand\nForearm\nUpper Arm','(x, y, z, rX, rY)\n(x, y, z)\n(x, y, z)','(x, y, z, rX, rY)\n(x, y, z)\n(x, y, z)','Position\nRotation','Position\nRotation','None',0,'{P,R}','None','Isomorph','Isomorph','Isomorph','None','None','None','Gesture','Gesture','Grab, move and rotate an object with one hand','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand (no fingers)','(Px, Py, Pz, Rx, Ry, Rz)','1:1 position-to-position \n1:1 orientation-to-orientation','Gesture',4.33333,4,5,4,5,5,3,'Mid-high'),(30,'Grab-And-Carry-And-Scale','Both hands are able to grab, move, and rotate an object. If the object is grabbed by one hand, the second hand can grab the object to scale it. The distance between both hands controls the size. If the object is grabbed by both hands, the center between both hands is the center of rotation, and it is not possible to rotate around the axis connecting both hands. A hand disappears if it grabs an object. This technique is used in the SteamVR Home application.','Allows single-handed and bimanual manipulation of objects',NULL,'Grasping/Hand-based','Selection\nPositioning\nRotation\nScaling','None','3D cursor (virtual hands) \nTarget highlighting (bounding box)','Arm-length','Asymmetric-synchron','First Hand\nSecond Hand','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','1 Button (Selection)',1,'{P,R}, {P,R,S}','Partial','Isomorph','Isomorph','Isomorph','Distance','None','None','On Button Press','On Button Release','Grab, move, rotate and scale an object with two hands or one hand rotation and translation','Move and twist upper arms, forearms, hands and fingers','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry, Rz), (Px, Py, Pz, Rx, Ry, Rz, S)','1:1 position-to-position \n1:1 orientation-to-orientation\n1:1 distance-to-scale','Press button',4.33333,4,5,4,5,5,3,'Mid-high'),(31,'Virtual Hand (Finger-based)','The virtual hand technique maps the movements of the real hand and fingers to a virtual representation. An object can be grabbed by intersecting the virtual hand with the object and performing a grabbing gesture. If the user opens the hand, the object is released.','Creates a virtual representation of the real hand, including the fingers, to allow a direct and natural interaction',NULL,'Grasping/Finger-based','Selection\nPositioning\nRotation','None','3D cursor (virtual hand)','Arm-length','Single-handed','Hand\nFingers','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{P,R}','None','Isomorph','Isomorph','Isomorph','None','None','None','Gesture','Gesture','Grab, move and rotate an object with one hand','Move and twist upper arm, forearm, hand and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz, Rx, Ry, Rz)','1:1 position-to-position \n1:1 orientation-to-orientation','Release object',5,5,5,5,5,5,5,'High'),(32,'Rigid-Body Fingers','The technique maps the movements of the real hand and fingers to a virtual representation. An object can be grabbed by intersecting the virtual hand with the object and performing a grabbing gesture. Spring-dampers are used to map the movements of the real fingers to the virtual fingers. If the fingers collide with an object, they stick to the surface of the object to prevent penetration. If the user opens the hand, the object is released.','Prevents the intersection of the virtual fingers with the help of rigid-bodies and spring-dampers',NULL,'Grasping/Finger-based','Selection\nPositioning\nRotation','None','3D cursor (virtual hand)\nAdditional cursor (second hand not penetrating object)','Arm-length','Single-handed','Hand\nFingers','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{P,R}','None','Isomorph','Isomorph','Isomorph','None','None','None','Gesture','Gesture','Grab, move and rotate an object with one hand','Move and twist upper arm, forearm, hand and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz, Rx, Ry, Rz)','1:1 position-to-position \n1:1 orientation-to-orientation','Release object',5,5,5,5,5,5,5,'High'),(33,'Intent Driven Selection','The Intent Driven Selection technique uses a proximity sphere which is generated at the inner face of the hand so that fingers touch the interior surface of the sphere. The size of the sphere changes according to the confidence of the user. The position and the grip strength of the hand indicate the confidence.','Tries to determine the intended object the user wants to select by considering the placement of the user\'s hand',NULL,'Grasping/Finger-based','Selection','Snap to object','3D cursor (virtual hand, guiding beam between the center of grasp and target) \nAdditional cursor (proximity sphere which adapts to the finger positions)\nTarget highlighting (change of color)','Arm-length','Single-handed','Hand\nFingers','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'-','None','Isomorph','None','None','None','Continuously','Behavioural','Gesture','Gesture','Grab an object with one hand','Move and twist upper arm, forearm, hand and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz, Rx, Ry, Rz)','1:1 position-to-position \n1:1 orientation-to-orientation','Release object',5,5,5,5,5,5,5,'High'),(34,'Extendo Hands','The technique maps the movements of the real hand and fingers to a virtual representation. If the hand faces an object, a second hand moves to the object. The virtual hands are connected by a ray. A grabbing gesture selects the object. The object can be moved around the user. The distance between the object and the real hand is scaled so that the object can be moved in front of the user. If the user opens the hand, the object is released.','Allows the selection of distance objects by moving a second virtual hand to the object the hand faces',NULL,'Grasping/Finger-based','Selection\nPositioning\nRotation','Snap to object','3D cursor (virtual hand) \nAdditional cursor (second hand moving to the target, rope between first and second hand) Target highlighting (bounding box)','Scaled','Single-handed','Hand\nFingers','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{P,R}','None','Remapped','Target-oriented','Isomorph','None','None','None','Gesture','Gesture','Grab, move and rotate an object with one hand','Move and twist upper arm, forearm, hand and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz, Rx, Ry, Rz)','1:N position-to-position \n1:1 orientation-to-orientation','Release object',4.66667,5,5,5,5,3,5,'High'),(35,'Crank Handle (Finger-based)','The user can translate an object after closing the Hand. Opening and closing the hand again switches to the rotation mode, where rotations on the three primarily axes are possible by moving the hand around the particular axis. The movements feel like turning a crank. To visually support the user, a bar is visible in the translation mode. In rotation mode, three crank handles are visible. One for each axis. Only the crank handle representing the axis the user currently rotates around is opaque. This technique das not directly support selection tasks as no object can be targeted.','Allows separated translation and rotation on each axis. Rotation is possible by rotating the hand around a primary axis like using a crank handle',NULL,'Grasping/Finger-based','Positioning\nRotation','DoF reduction','3D cursor (point cursor) \nWidget (bar on one side of the object indicating the current mode)','Infinite','Single-handed','Hand\nFingers','(x, y, z)\n(x, y, z, rX, rY, rZ)','(x, y, z)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{P}, {Rx}, {Ry}, {Rz}','Full','None','Isomorph','Remapped','None','None','None','Gesture','Gesture','Grab and move an object with one hand and rotate it with the help of crank handles','Move and twist upper arm, forearm, hand and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz), (Rx), (Ry), (Rz)','1:1 position-to-position \n1:1 position-to-orientation (constrained)','Release object',5,5,5,5,5,5,5,'High'),(36,'Knob','The technique maps the movements of the real hand and fingers to a virtual representation. An object can be grabbed by intersecting the virtual hand with the object and performing a grabbing gesture. If the object is moved, the target position is predicted. If the movement speed falls below a given threshold, a schematic version of the object is generated at this position. Rotating the object is possible by performing a knob gesture. It is only possible to rotate around the z- or x-axis and only around one axis at a time. The scaling mode is activated if at least two fingers are stretched out. Movements to the left or right scale the object down or up.','Single-handed technique allowing the separate translation, rotation, and scaling of objects',NULL,'Grasping/Finger-based','Selection\nPositioning\nRotation\nScaling','DoF reduction,\nSnap to position','3D cursor (virtual hand) \nTarget highlighting (shematic rendering of object at predicted target position, Increasing brightness of the selected object when scaling mode is active)\nWidget (rotating arrows show rotation direction)','Arm-length','Single-handed','Hand\nFingers','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{P}, {Rx}, {Rz}, {S}','Full','Isomorph','Isomorph','Isomorph','Distance','None','None','Gesture','Gesture','Grab, move and rotate an object with one hand','Move and twist upper arm, forearm, hand and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz), (Rx), (Rz), (S)','1:1 position-to-position \n1:1 position-to-orientation (constrained)\n1:1 distance-to-scale','Release object',4.16667,5,5,5,3,2,5,'Mid-high'),(37,'Voodoo Dolls','The technique uses dolls to allow the translation and rotation of objects. “Dolls are hand held, transient objects: users create dolls to represent specific objects, and the dolls vanish when they are no longer needed. Visually, dolls are small copies of the objects they represent. Functionally, dolls are used in pairs, one in each hand, and serve two different yet complementary purposes depending on the hand holding them.[…] The doll held in the right hand determines the position and orientation of the object it represents, while the doll held in the left hand sets the reference frame. In other words, moving the doll in the right hand relative to the doll in the left hand moves the object represented by the doll in the right hand to the same position and orientation relative to the object represented by the doll in the left hand.” [1]','Allows the translation and rotation of object by dolls',NULL,'Grasping/Finger-based','Selection\nPositioning\nRotation','None','3D cursor (virtual hands) \nProxy objects (minuature models of the target objects)','Scaled','Asymmetric-synchron','First Hand\nFingers\nSecond Hand\nFingers','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{P,R}','None','Isomorph','Remapped','Remapped','None','None','None','Gesture','Gesture','Grab, move and rotate an object with one hand','Move and twist upper arm, forearm, hand and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz, Rx, Ry, Rz)','1:1 proxy-position-to-position \n1:1 proxy-orientation-to-orientation','Release object',4.66667,5,5,5,5,3,5,'High'),(38,'Grab-And-Carry','Beide Hände greifen Objekt  und ermöglichen Positionierung indem beide Hände in die gleiche Richtung bewegt werden. Drehen über entgegengesetzte Bewegung. Drehung geht nicht um Achse die beide Hände verbindet.','Both hands grab the object, and the positions of the hands determine the position, orientation, and scale of the object',NULL,'Grasping/Finger-based','Selection\nPositioning\nRotation','None','3D cursor (virtual hands) ','Arm-length','Symmetric-synchron','First Hand\nFingers\nSecond Hand\nFingers','(x, y, z)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','(x, y, z)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{P,Ryz}','None','Isomorph','Isomorph','Remapped','None','None','None','Gesture','Gesture','Grab, move and rotate an object with two hands','Move upper arms, forearms, hands and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz, Ry, Rz)','1:1 position-to-position \n1:1 position-to-orientation (no Rx)','Release object',4.66667,5,5,5,4,4,5,'High'),(39,'Handle-Bar','In the Handle Bar technique, a virtual handle is pierced through the object the user wants to manipulate. The handle is grabbed on both ends by the hands. Moving the hands around each other rotates the object in the y and z axes. Moving the hands simultaneously in the same direction moves the object. The distance between the hands controls the scale of the object. Incremental rotation in the x-axis is possible by rotating the hands in the y and z axes.','Both hands grab the object, and the positions of the hands determine the position, orientation, and scale of the object',NULL,'Grasping/Finger-based','Selection\nPositioning\nRotation\nScaling','None','3D cursor (virtual hands) ','Arm-length','Symmetric-synchron','First Hand\nFingers\nSecond Hand\nFingers','(x, y, z)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','(x, y, z)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{P,Ryz,S}, {Rx}','Partial','Isomorph','Isomorph','Remapped','Distance','None','None','Gesture','Gesture','Grab, move, rotate and scale an object with two hands','Move upper arms, forearms, hands and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz, Ry, Rz, S), (Rx)','1:1 position-to-position \n1:1 position-to-orientation \n1:N position-to-orientation (Ry)\n1:1 distance-to-scale','Release object',4.5,5,5,5,4,3,5,'High'),(40,'Slide-And-Turn','The technique was developed for a stereoscopic table top allowing the interaction with three-dimensional objects but can be used in any spatial context. “The slide-and-turn allows the user to perform a steering-wheel motion on the table top. […] The user pinches with both hands, which locks the scene to the center of the line connecting the two hands. The scene’s movement is defined by a translation of the center of the line segment and a rotation around the center. The axis of rotation is fixed to be perpendicular to the table top, and the translation is constrained to the table plane.” [1] ','Allows the translation of an object on one layer and the rotation of the object with a steering-wheel motion',NULL,'Grasping/Finger-based','Selection\nPositioning\nRotation','DoF reduction','3D cursor (virtual hands) ','Arm-length','Symmetric-synchron','First Hand\nFingers\nSecond Hand\nFingers','(x, y, z)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','(x, y, z)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{P,Ry}','None','Isomorph','Isomorph','Remapped','None','None','None','Gesture','Gesture','Grab an object and move and rotate it on a surface','Move upper arms, forearms, hands and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz, Ry)','1:1 position-to-position \n1:1 position-to-orientation (only Ry)','Release object',5,5,5,5,5,5,5,'High'),(41,'Symmetric Scale','The technique was developed for a stereoscopic table top allowing the interaction with three-dimensional objects but can be used in any spatial context. After selection, this technique only allows to shrink and enlarge an object by moving the hands together or apart.','Allows to shrink and enlarge objects by moving the hands together or apart',NULL,'Grasping/Finger-based','Selection\nScaling','None','3D cursor (virtual hands) ','Arm-length','Symmetric-synchron','First Hand\nFingers\nSecond Hand\nFingers','(x, y, z)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','(x, y, z)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{S}','None','Isomorph','None','None','Distance','None','None','Gesture','Gesture','Scale an object with two hands','Move upper arms, forearms, hands and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(S)','1:1 distance-to-scale','Release object',5,5,5,5,5,5,5,'High'),(42,'Turntable','The technique was developed for a stereoscopic table top allowing the interaction with three-dimensional objects but can be used in any spatial context. After selection, this technique only allows the rotation of an object around one axis.','Allows the rotation of an object around one axis',NULL,'Grasping/Finger-based','Selection\nRotation','DoF reduction','3D cursor (virtual hands) ','Arm-length','Symmetric-synchron','First Hand\nFingers\nSecond Hand\nFingers','(x, y, z)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','(x, y, z)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{Ry}','None','Isomorph','None','Remapped','None','None','None','Gesture','Gesture','Rotate an object as if it is placed on a turntable','Move upper arms, forearms, hands and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Ry)','1:1 position-to-orientation (only Ry)','Release object',5,5,5,5,5,5,5,'High'),(43,'6-DOF Hand','The 6-DOF hand is a bimanual interaction technique. The hand grabbing the object controls the position and the rotation of the object by translating and rotating the hand. At any time, the second hand can grab somewhere in the air outside the object to change the size of the object. The distance between both hands controls the size.','One hand controls the position, and the rotation of the object and the distance between both hands controls the scale of the object',NULL,'Grasping/Finger-based','Selection\nPositioning\nRotation\nScaling','None','3D cursor (virtual hands) \nTarget highlighting (bounding box)','Arm-length','Asymmetric-synchron','First Hand\nFingers\nSecond Hand\nFingers','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{P,R}, {P,R,S}','Partial','Isomorph','Isomorph','Isomorph','Distance','None','None','Gesture','Gesture','Grab, move, rotate and scale an object with two hands','Move and twist upper arm, forearm, hand and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz, Rx, Ry, Rz), (Px, Py, Pz, Rx, Ry, Rz, S)','1:1 position-to-position \n1:1 orientation-to-orientation\n1:1 distance-to-scale','Release object',4.83333,5,5,5,4,5,5,'High'),(44,'Grab-And-Scale','The technique was developed for a stereoscopic table top allowing the interaction with three-dimensional objects but can be used in any spatial context. The left hand is used to position the object while the right hand moves towards or away from it to scale the object.','Left hand positions object while right hand moves towards or away from it to scale the object',NULL,'Grasping/Finger-based','Selection\nPositioning\nScaling','None','3D cursor (virtual hands) ','Arm-length','Asymmetric-synchron','First Hand\nFingers\nSecond Hand\nFingers','(x, y, z)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','(x, y, z)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{P}, {P,S}','Partial','Isomorph','Isomorph','None','Distance','None','None','Gesture','Gesture','Grab, move, rotate and scale an object with two hands','Move upper arms, forearms, hands and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz), (Px, Py, Pz, S)','1:1 position-to-position \n1:1 distance-to-scale','Release object',4.83333,5,5,5,4,5,5,'High'),(45,'Trackball','The technique was developed for a stereoscopic table top allowing the interaction with three-dimensional objects but can be used in any spatial context. The left hand is used to position the object while the right hand rotates about its center to rate the object.','Left hand positions object while right hand rotates about its center to rate the object',NULL,'Grasping/Finger-based','Selection\nRotation','None','3D cursor (virtual hands) ','Arm-length','Asymmetric-synchron','First Hand\nFingers\nSecond Hand\nFingers','(x, y, z)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','(x, y, z)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{P}, {P,R}','Partial','Isomorph','None','Remapped','None','None','None','Gesture','Gesture','Grab, move and rotate an object with two hands','Move and twist upper arms, forearms, hands and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz), (Px, Py, Pz, Rx, Ry, Rz)','1:1 position-to-position \n1:1 position-to-orientation','Release object',4.83333,5,5,5,4,5,5,'High'),(46,'Free Rotation','The technique was developed for a stereoscopic table top allowing the interaction with three-dimensional objects but can be used in any spatial context. “The left hand translates the model but also specifies the position and orientation of the rotation axis by holding onto a virtual axis. The right hand performs the actual rotation by circling around this virtual axis. The non-dominant hand provides the reference frame for the dominant hand in three different ways.” [1]','Left hand positions the model. The axis of rotation is specified by the left hand\'s orientation. Right hand rotates around left hand',NULL,'Grasping/Finger-based','Selection\nPositioning\nRotation','DoF reduction','3D cursor (virtual hands) ','Arm-length','Asymmetric-synchron','First Hand\nFingers\nSecond Hand\nFingers','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{P}, {P,Ra}','Partial','Isomorph','Isomorph','Remapped','None','None','None','Gesture','Gesture','Grab, move and rotate an object with two hands','Move and twist upper arms, forearms, hands and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz), (Px, Py, Pz, Ra)','1:1 position-to-position \n1:1 position-to-orientation (constrained)','Release object',4.66667,5,5,5,4,4,5,'High'),(47,'Axis Rotation','The technique was developed for a stereoscopic table top allowing the interaction with three-dimensional objects but can be used in any spatial context. “The left hand translates the model, but also specifies the position and orientation of the rotation axis by holding onto a virtual axis. The right hand performs the actual rotation by circling around this virtual axis. The non-dominant hand provides the reference frame for the dominant hand in three different ways. […] The rotation snaps to one of the principal axes.” [1]','Left hand positions the model. The axis of rotation is specified by the left hand\'s orientation. Right hand rotates around left hand. Rotation snaps to a principle Axis',NULL,'Grasping/Finger-based','Selection\nPositioning\nRotation','DoF reduction','3D cursor (virtual hands) ','Arm-length','Asymmetric-synchron','First Hand\nFingers\nSecond Hand\nFingers','(x, y, z)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','(x, y, z)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{P}, {P, {{Rx}, {Ry}, {Rz}}}, ','Partial','Isomorph','Isomorph','Remapped','None','None','None','Gesture','Gesture','Grab, move and rotate an object with two hands','Move upper arms, forearms, hands and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz, Rx, Ry, Rz), (Px, Py, Pz, ((Rx), (Ry), (Rz)))','1:1 position-to-position \n1:1 position-to-orientation (constrained)','Release object',4.5,5,5,5,3,4,5,'High'),(48,'Heuristic Rotation','The technique was developed for a stereoscopic table top allowing the interaction with three-dimensional objects but can be used in any spatial context. The left hand translates the object and the right hand rotates the object by rotating around the left hand. The rotation axis is inferred by the motion of the right hand.','Left hand positions the model. Right hand rotates around left hand. Rotation axis is inferred from the motion of the right hand',NULL,'Grasping/Finger-based','Selection\nPositioning\nRotation','DoF reduction','3D cursor (virtual hands) ','Arm-length','Asymmetric-synchron','First Hand\nFingers\nSecond Hand\nFingers','(x, y, z)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','(x, y, z)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{P}, {P, {{Rx}, {Ry}, {Rz}}}, ','Partial','Isomorph','Isomorph','Remapped','None','None','None','Gesture','Gesture','Grab, move and rotate an object with two hands','Move upper arms, forearms, hands and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz, Rx, Ry, Rz), (Px, Py, Pz, ((Rx), (Ry), (Rz)))','1:1 position-to-position \n1:1 position-to-orientation (constrained)','Release object',4.5,5,5,5,3,4,5,'High'),(49,'Constrained Translation','The technique was developed for a stereoscopic table top allowing the interaction with three-dimensional objects but can be used in any spatial context. “[The Technique] determines the line or plane from the orientation of the non-dominant hand. An open palm signifies planar translations while a closed fist denotes movements along a line.” [1] The right hand moves the object.','Left hand specifies a line or plane constraint, right hand translates',NULL,'Grasping/Finger-based','Selection\nPositioning','DoF reduction','3D cursor (virtual hands) ','Arm-length','Asymmetric-synchron','First Hand\nFingers\nSecond Hand\nFingers','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{Pa}','None','Isomorph','Isomorph','None','None','None','None','Gesture','Gesture','Grab, move and rotate an object with one hand','Move and twist upper arms, forearms, hands and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Pa)','1:1 position-to-position (constrained)','Release object',4.66667,5,5,5,4,4,5,'High'),(50,'3-DOF Hand',' “After grabbing the object with one hand, the user can translate it by moving that hand. The rotation is achieved by rotating the wrist corresponding to the other hand, by grabbing somewhere in space, while keeping the object selected with the first hand. Similarly to the 6-DOF technique, varying the distance between hands will uniformly scale the object, while the grabbed point in the object will remain as the center of all transformations.” [1]','One hand translates the object and the other hand rotates it. The distance between both hands scales the object',NULL,'Grasping/Finger-based','Selection\nPositioning\nRotation\nScaling','None','3D cursor (virtual hands) \nTarget highlighting (bounding box)','Arm-length','Asymmetric-synchron','First Hand\nFingers\nSecond Hand\nFingers','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{P}, {P,R,S}','Partial','Isomorph','Isomorph','Isomorph','None','None','None','Gesture','Gesture','Grab, move, rotate and scale an object with two hands','Move and twist upper arms, forearms, hands and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz), (Px, Py, Pz, Rx, Ry, Rz, S)','1:1 position-to-position \n1:1 orientation-to-orientation\n1:1 distance-to-scale','Release object',4.83333,5,5,5,4,5,5,'High'),(51,'Air TRS','“The hand that grabs the object moves it. The other hand, after pinching somewhere in space, allows the user to manipulate the object rotation and scale. These two transformations are centered in the object pinched point. The rotation angle is defined by the variation in the position of one hand relatively to the other. For scaling, the distance between both hands is used.“ [1]','One hand translates the object. The other hand controls the rotation and scale of the object by its position relative to the other hand',NULL,'Grasping/Finger-based','Selection\nPositioning\nRotation\nScaling','None','3D cursor (virtual hands) \nTarget highlighting (bounding box)','Arm-length','Asymmetric-synchron','First Hand\nFingers\nSecond Hand\nFingers','(x, y, z)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','(x, y, z)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{P}, {P,R,S}','Partial','Isomorph','Isomorph','Remapped','None','None','None','Gesture','Gesture','Grab, move, rotate and scale an object with two hands','Move upper arms, forearms, hands and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz), (Px, Py, Pz, Rx, Ry, Rz, S)','1:1 position-to-position \n1:1 position-to-orientation\n1:1 distance-to-scale','Release object',4.83333,5,5,5,4,5,5,'High'),(52,'Grab-And-Twirl','The technique was developed for a stereoscopic table top allowing the interaction with three dimensional objects but can be used in any spatial context. “The user first grabsan object with either hand and manipulates the object as a one-handed 6 DOF grab. At some point, the user pins the object with the other hand and performs a symmetric object twirl. “ [1]','Carry and turn an object around with both hands. Each hand can also be used independently as a one-handed grab tool',NULL,'Grasping/Finger-based','Selection\nPositioning\nRotation','None','3D cursor (virtual hands) ','Arm-length','Asymmetric-synchron','First Hand\nFingers\nSecond Hand\nFingers','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{P}, {P,R,S}','Partial','Isomorph','Isomorph','Remapped','None','None','None','Gesture','Gesture','Grab, move, rotate and scale an object with two hands','Move and twist upper arms, forearms, hands and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz), (Px, Py, Pz, Rx, Ry, Rz, S)','1:1 position-to-position \n1:1 position-to-orientation','Release object',4.83333,5,5,5,4,5,5,'High'),(53,'Automatic Adjustments','The technique supports the manipulation of objects by four types of automatic adjustments based on the hand speed. Release adjustment: If the release of an object is detected, the position of the object is set to a prior point in time to compensate unintended hand movements on release. Position adjustments: Slower movements are further slowed down to increase precision. Viewpoint adjustment: A zoom on the object is initiated on slower movements. Size Adjustments: The virtual hand is scaled done to avoid that it occludes the object on zoom.','Uses release adjustment, position adjustment, viewpoint adjustment, and hand size adjustment based on the hand speed',NULL,'Grasping/Finger-based','Selection\nPositioning','Snap to position','3D cursor (virtual hand) \nTarget highlighting (zoom on object when on slower movement)\nAdopting cursor (decrease virtual hand size to compensate zoom)','Arm-length','Single-handed','Hand\nFingers','(x, y, z)\n(x, y, z, rX, rY, rZ)','(x, y, z)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{P}','None','Velocity-oriented','Velocity-oriented','None','None','None','None','Gesture','Gesture','Grab, move and rotate an object with one hand','Move and twist upper arm, forearm, hand and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz)','1:N position-to-position ','Release object',4.5,5,5,5,4,3,5,'High'),(54,'Ray-Casting (Selection)','A ray starts at the hand and ends at the object which is hit by the ray. By pressing a button, the user can select the currently hit object. ','Allows the selection of distant objects with the help of a ray originating from the hand',NULL,'Pointing/Vector-based','Selection','None','3D cursor (virtual ray)','Infinite','Single-handed','Hand','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','None','None','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry, Rz)','1:1 position-to-position \n1:1 orientation-to-orientation','Press button',4.33333,4,5,4,5,5,3,'Mid-high'),(55,'Ray-Casting (Selection + Positioning)','A ray starts at the hand and ends at the object which is hit by the ray. By pressing a button, the user can select the currently hit object. The object is then attached to the end of the ray and can be moved spherically around the user.','Allows the interaction with distant objects with the help of a ray originating from the hand',NULL,'Pointing/Vector-based','Selection\nPositioning\nRotation','None','3D cursor (virtual ray)','Infinite','Single-handed','Hand','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection)',1,'{P,R}','None','Isomorph','Remapped','None','None','None','None','On Button Press','On Button Release','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry, Rz)','1:1 position-to-position \n1:1 orientation-to-orientation\n1:1 position-and-orientation-to-position ','Press button',4,4,5,4,5,3,3,'Mid-high'),(56,'Head Based Selection (Button Selection) ','An object is focused by turning the head in its direction and placing a cursor on it. The object is selected when a button is pressed','Allows the selection of an object with the view direction of the head. Selection is triggered by a button press',NULL,'Pointing/Vector-based','Selection','None','3D cursor (point cursor in the center of the view)','Infinite','None','Head','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','None','None','On Button Press','None','Gaze at an object','Only Head Movements','Moderate muscle forces','Head','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:1 orientation-to-orientation','Press button',4,3,5,3,5,5,3,'Mid-high'),(57,'Head Based Selection (Dwell Selection)','An object is focused by turning the head in its direction and placing a cursor on it. The object is selected when the cursor was placed a definite time on the object. ','Allows the selection of an object with the view direction of the head. Selection is triggered by dwell time','The implementation of the technique used in the study generates a small yellow sphere at the position the user looks at. This position is determined by an invisible ray originating at the center of the head with the same direction as the head. If an object is focused a circle-shaped timer appears indicating how long the object needs to be focused. After one second the object is selected.','Pointing/Vector-based','Selection','None','3D cursor (point cursor in the center of the view)','Infinite','None','Head','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','None',0,'-','None','Isomorph','None','None','None','None','None','Dwell','None','Gaze at an object','Only Head Movements','Moderate muscle forces','Head','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:1 orientation-to-orientation','Dwell',4.16667,3,5,3,5,5,4,'Mid-high'),(58,'Eye Based Selection','Eye-based selection uses eye-tracking to determine the object the user is looking at. A button press selects the object.','Allows the selection of objects by looking at them',NULL,'Pointing/Vector-based','Selection','None','3D cursor (point cursor)','Infinite','None','Eyes','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','None','None','On Button Press','None','Gaze at an object','Only Eye Movements','Moderate muscle forces','Eyes','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:1 orientation-to-orientation','Press button',4,3,5,3,5,5,3,'Mid-high'),(59,'Head + Eye Based Selection','Head + Eye-based selection uses eye-tracking to determine the object the user is looking at. Additionally, the head is tracked. A button press selects the object.','Allows the selection of objects by looking at them. The eyes and the head are tracked',NULL,'Pointing/Vector-based','Selection','None','3D cursor (point cursor)','Infinite','None','Head\nEyes','(rX, rY)\n(rX, rY)','(x, y, z, rX, rY)\n(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','None','None','On Button Press','None','Gaze at an object','Head and Eye Movements','Moderate muscle forces','Head and Eyes','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:1 orientation-to-orientation','Press button',4.66667,5,5,5,5,5,3,'High'),(60,'Finite Ray-Casting','“The interaction metaphor is not a ray of light, but a virtual pointing staff which can be arbitrarily extended and shortened. This holds two advantages: The first is that objects can be manipulated in an easier way because the user can, for example, pull objects closer to himself. Furthermore, the selection of covered objects is possible because the ray can pass through the objects in front. When the end of the staff hits an object, its bounding box becomes visible to the user and the ray changes its colour. The user can then press a specific button to attach the highlighted object to the staff’s end. By pressing another specific button and moving the hand forwards or backwards, he can scale the staff’s length. A slow movement causes only a small adaption of the length, whereas a fast one allows rapid scaling proportional to the speed of the movement. The adjustment lasts until the button used for scaling is released. Scaling the staff to its minimal size allows for rotation of the selected object around all axes, which gives the impression of a hand-centered manipulation.” [1]','Instead of a ray a pointing staff is used which can be arbitrarily extended and shortened',NULL,'Pointing/Vector-based','Selection\nPositioning\nRotation','None','3D cursor (finite virtual ray)\nTarget highlighting (bounding box)\nAdopting cursor (ray changes color on hit)','Scaled','Single-handed','Hand','(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','1 Button (Selection)\n1 Button (Scale Mode)',2,'{P,R}','None','Isomorph, \nVelocity-oriented','Isomorph, \nVelocity-oriented','Isomorph','None','None','None','On Button Press','On Button Release','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry, Rz)','1:N position-to-position \n1:1 orientation-to-orientation\n1:1 position-and-orientation-to-position ','Press button',4,4,5,4,5,3,3,'Mid-high'),(61,'Fishing Reel','This technique extends the Ray-Casting technique. After selection, the object is appended to the ray. Two buttons can then be used to enlarge or contract the ray to move the object further away or to pull it closer.','Selected objects are appended to the ray and can then be reeled closer or further away with two buttons',NULL,'Pointing/Vector-based','Selection\nPositioning\nRotation','None','3D cursor (virtual ray)','Infinite','Single-handed','Hand','(rX, rY)','(x, y, z, rX, rY, rZ)','Rotation','Position\nRotation','1 Button (Selection) \n2 Buttons (Position Control)',3,'{P,R}','None','Isomorph','Remapped','Isomorph','None','None','None','On Button Press','On Button Release','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry, Rz)','1:1 position-to-position \n1:1 orientation-to-orientation\n1:N position-and-orientation-to-position ','Press button',4,4,5,4,5,3,3,'Mid-high'),(62,'Image-Plane Pointing','Image plane techniques summarize techniques that enable the user to select objects an invisible ray. The Ray starts at the eyes and goes through a point defined by the hand. In the Sticky Finger technique (also called occlusion selection), the finger is placed on the object to select it. In the Head Crusher technique, the thumb and the forefinger are placed around the target object. In the Lifting Palm technique, the hand is placed below the object while the palm is facing upwards. ','The selected object is determined by a ray which stars at the eyes and goes through a point defined by the hand',NULL,'Pointing/Vector-based','Selection','None','3D cursor (virtual hand) ','Scaled','Single-handed','Hand\nFingers','(x, y, z)\n(x, y, z, rX, rY, rZ)','(x, y, z)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'-','None','Isomorph','None','None','None','None','None','Gesture','Gesture','Point at an object with a pointer ','Move and twist upper arm, forearm, hand and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz, Rx, Ry, Rz)','1:1 position-to-position \n1:1 orientation-to-orientation','None',5,5,5,5,5,5,5,'High'),(63,'Depth Ray','This technique was initially developed to select 3D objects in a volumetric display but can be adapted to work in other three-dimensional contexts. “The depth ray augments the ray cursor with a depth marker, visualized as a small sphere, existing along the length of the ray. Along with the standard control of the ray cursor, the position of the depth marker can also be controlled dynamically. The distance between the hand and the surface of the volumetric display is mapped to the position of the depth marker, using an absolute mapping. Moving the hand forwards and backwards will move the depth marker in the same manner.” [1]','Extends the Ray-Casting technique with a depth marker. The object closest to the marker is selected',NULL,'Pointing/Vector-based','Selection','Snap to object','3D cursor (virtual ray)\nAdditional cursor (red depth marker)\nTarget highlighting (bounding box)','Scaled','Single-handed','Hand','(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','Continuously','Manual','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry, Rz)','1:1 position-to-position \n1:1 orientation-to-orientation','Press button',4.33333,4,5,4,5,5,3,'Mid-high'),(64,'Lock Ray','This technique was initially developed to select 3D objects in a volumetric display but can be adapted to work in other three-dimensional contexts. “With the lock ray, all intersected targets are also highlighted green; however no depth marker is visualized. To specify the target, the user clicks and holds the button down. At this point, the position of the ray is locked, and only then does the depth marker appear. The user adjusts the depth marker in a similar manner to the depth ray, and the intersected target which is closest to the depth marker is highlighted red indicating that it can be selected by releasing the button. Keeping the button down during the disambiguation phase provides a kinesthetically held mode, avoiding confusion between selection and disambiguation phases.” [1]','When the selection button is held down, the ray is locked, and a depth marker is shown. The object closest to the marker is selected on button release',NULL,'Pointing/Vector-based','Selection','Snap to object','3D cursor (virtual ray)\nAdditional cursor (red depth marker)\nTarget highlighting (bounding box)','Infinite','Single-handed','Hand','(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','Continuously','Manual','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry, Rz)','1:1 position-to-position \n1:1 orientation-to-orientation','Press button',4.33333,4,5,4,5,5,3,'Mid-high'),(65,'Flower Ray','This technique was initially developed to select 3D objects in a volumetric display but can be adapted to work in other three-dimensional contexts. “The flower ray is another two-step selection technique, similar to the lock ray. The selection phases of the techniques are the same. However, with the flower ray, when the user clicks and holds the button, all intersected targets animate towards the user’s viewpoint, and flower out into a marking menu. The rationale behind this design is that a marking menu selection should be faster than the disambiguation phase of the lock ray, which is much like selecting an item from a linear menu.“ [1]','When the selection button is held down, all highlighted objects are arranged in front of the user. On button release, the object closest to the ray is selected',NULL,'Pointing/Vector-based','Selection','None','3D cursor (virtual ray)\nAdditional cursor (red depth marker)\nTarget highlighting (bounding box)\nWidget (flower menu)','Infinite','Single-handed','Hand','(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','Discrete/Multiple steps','Manual','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry, Rz)','1:1 position-to-position \n1:1 orientation-to-orientation','Press button',4.33333,4,5,4,5,5,3,'Mid-high'),(66,'Smart Ray','This technique was initially developed to select 3D objects in a volumetric display but can be adapted to work in other three-dimensional contexts. “The design of the smart ray is based on the idea that the intersection of two rays could define a point in 3D space. Instead of taking the intersection of two simultaneously defined rays, which would require a second input device [23], the smart ray takes the intersection of a single ray over a length of time. […] In our implementation, we use an algorithm based on target weights to determine which target should be selected when multiple targets are intersected. Target weights are continuously updated based on their proximity to the ray cursor, and are visualized with small spheres at the center of the target. The closer the ray comes to the center of the target, the larger the weight increase will be.” [1]','When the selection button is hold down the objects ar continuously ranked by the distance to the ray',NULL,'Pointing/Vector-based','Selection','None','3D cursor (virtual ray)\nTarget highlighting (bounding box)','Infinite','Single-handed','Hand','(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','Continuously','Behavioural','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry, Rz)','1:1 position-to-position \n1:1 orientation-to-orientation','Press button',4.33333,4,5,4,5,5,3,'Mid-high'),(67,'Bendcast','This technique extends the Ray-Casting technique. An additional bendable ray snaps to the object, which is closest to the primary ray. This object will be selected when the selection button is pressed.','An additional ray snaps to the object, which is closest to the primary ray',NULL,'Pointing/Vector-based','Selection','Snap to object','3D cursor (virtual ray)\nAdopting cursor (ray bends to target)','Infinite','Single-handed','Hand','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','Discrete/Single step','Heuristic','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:1 orientation-to-orientation','Press button',4.33333,4,5,4,5,5,3,'Mid-high'),(68,'Sticky Ray / Snap-To Ray','This technique extends the Ray-Casting technique. An additional bendable ray snaps to the object, which was hit last by the primary ray. This object will be selected when the selection button is pressed.','An additional ray snaps to the object, which was hit last by the primary ray indicating the object that will be selected',NULL,'Pointing/Vector-based','Selection','Snap to object','3D cursor (virtual rays)\nAdditional cursor (second ray bends to target)','Infinite','Single-handed','Hand','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','None','None','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:1 orientation-to-orientation','Press button',4.33333,4,5,4,5,5,3,'Mid-high'),(69,'VOTE Ray-Casting','“[…] VOTE was designed around the fact that users often indicate their desired target while using a selection technique, but other objects may be inadvertently selected during the confirmation step. To leverage this, VOTE maintains a queue of votes and uses a popular vote to select the object with the most votes. Every interaction frame, VOTE adds a timestamped vote to the queue for the object being indicated by the ray-casting technique’s indication method. If an object is not indicated by the indication method (i.e., no objects are currently being intersected by the virtual ray), a timestamped “abstain” vote is added to the queue instead. When the confirmation method is called, VOTE first expires any votes older than a predefined threshold. For the presented study, we used a threshold of 0.2 seconds, which we chose after some preliminary pilot testing of our VOTE ray-casting technique […]. Once old votes are expired, VOTE then selects and returns the object with the most votes, as opposed to the currently intersected object.” [1]','Maintains a queue of votes and selects the objects with the most votes',NULL,'Pointing/Vector-based','Selection','Snap to object','3D cursor (virtual ray)\nAdopting cursor (ray changes color)','Infinite','Single-handed','Hand','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','Continuously','Behavioural','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:1 orientation-to-orientation','Press button',4.33333,4,5,4,5,5,3,'Mid-high'),(70,'PRISM enhanced Ray-Casting','“Our solution to improve the accuracy of ray casting employs PRISM rotation to control the angles swept out by the ray. When the user slows the rotation of their wrist the orientation changes are scaled down which offsets the amplification of these rotations at the other end of the ray.” [1]','Extends Ray-Casting and applies PRISM to the rotation of the ray',NULL,'Pointing/Vector-based','Selection','None','3D cursor (virtual ray)','Infinite','Single-handed','Hand','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection)',1,'-','None','Velocity-oriented','None','None','None','None','None','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:N orientation-to-orientation','Press button',4,4,5,4,5,3,3,'Mid-high'),(71,'Adaptive Pointing','“The basic idea is to improve pointing performance for absolute input devices by implicitly adapting the CD gain to the current user\'s needs without violating the user\'s mental model of absolute-device operation. Users expect a 1:1 mapping between their device movement in motor space and the resulting pointer movement in display space when using an absolute pointing device. Adaptive Pointing appears to provide this pure absolute behavior but imperceptibly lowers the CD gain when higher precision is needed. […] The Adaptive Pointing technique dynamically adjusts the CD gain depending on the movement velocity and the current offset between the motor-space position and display-space position. […] As soon as a predefined minimal velocity threshold is met the CD gain is smoothly decreased.” [1]','Adapts the control-display gain in dependence of the velocity and the offset between the real and virtual position of the cursor',NULL,'Pointing/Vector-based','Selection','None','3D cursor (virtual ray)','Infinite','Single-handed','Hand','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection)',1,'-','None','Velocity-oriented','None','None','None','None','None','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:N orientation-to-orientation','Press button',4,4,5,4,5,3,3,'Mid-high'),(72,'Smoothed Pointing','“Smoothed Pointing adopts a velocity-based C-D ratio adaptation to smooth the cursor movement. It uses two speed thresholds to determine the gain value: a minimum speed (vmin) below which any motion is considered a tracking error; and a maximum speed (vmax), which is the hand speed at which the offset recovery is automatically triggered. In fact, if a user moves slowly, the gain scaling produces the accumulation of an offset between the device position in the motor space and the cursor position in the display space. This offset, the maximum value of which is limited to dmax, is recovered by setting the C-D gain to gmax. To smooth the cursor movement, in the [vmin,vmax] interval, a modulated sine wave is used as the gain damping function.” [1]','Adapts the control-display gain in dependence of the velocity the cursor',NULL,'Pointing/Vector-based','Selection','None','3D cursor (virtual ray)','Infinite','Single-handed','Hand','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection)',1,'-','None','Velocity-oriented','None','None','None','None','None','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:N orientation-to-orientation','Press button',4,4,5,4,5,3,3,'Mid-high'),(73,'ARM','Absolute and Relative Mapping (ARM) enables the user to activate a precision mode by pressing a button. In this mode, a zoom lens is displayed and the movements are mapped with a 1:10 ratio.','Allows to manually switch to a precision mode, which displays a zoom lens and changes the mapping between real and virtual movements ',NULL,'Pointing/Vector-based','Selection','None','3D cursor (virtual ray)\nTarget highlighting (optional zoom lense)','Infinite','Single-handed','Hand','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection)\n1 Button (Precision Mode)\n1 Scrollwheel (Scale)',3,'-','None','Manual Switching','None','None','None','Continuously','Manual','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:N orientation-to-orientation','Press button',4,4,5,4,5,3,3,'Mid-high'),(74,'Discrete Zoom','This 3D selection technique was developed for 2D screens but can be adapted to work in other three-dimensional contexts. “The discrete zoom technique uses a type of 2D menu for specification of the zooming area, discrete actions to zoom in and out, and ray-casting for final target selection. The user can choose to point directly to an object to select it, or to point to the region of the screen that contains it and zoom to increase the target size. Once the object is selected, the initial unzoomed view is returned. The menu is an overlay on the screen and contains four quadrants, similar to the quad menu in SQUAD, that are always visible. Unlike SQUAD, the menu is translucent and the objects in the environment are always visible. The quadrant containing the cursor is highlighted and is used to determine the region of the screen that will be magnified. Once the quadrant is selected, the system performs a quick (0.25 s) animation from the current frustum to the magnified version of the selected quadrant. This animation helps users to keep track of the context and also the location of the object they want to select. The user can continue refinement by repeatedly selecting quadrants. However, instead of refining until there is only one object in the quadrant like in SQUAD, users can decide how much magnification is enough, and then select the object directly using ray-casting. The technique also allows zooming out to the previous set of quadrants if the wrong quadrant is selected.” [1]','Allows to zoom into the environment with multiple steps',NULL,'Pointing/Vector-based','Selection','None','3D cursor (virtual cursor)\nWidget (zoom menu)','Infinite','Single-handed','Hand','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection)\n2 Buttons (Zoom)',3,'-','None','Isomorph','None','None','None','Discrete/Multiple steps','Manual','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:1 orientation-to-orientation','Press button',4.33333,4,5,4,5,5,3,'Mid-high'),(75,'Continuous Zoom','This 3D selection technique was developed for 2D screens but can be adapted to work in other three-dimensional contexts. “The continuous zoom technique is similar to discrete zoom, but instead of using quadrants, it zooms in the direction of the cursor continuously. This way, users can simply point roughly toward the object and zoom in until the target is large enough for selection. Just like with the discrete zoom technique, traditional raycasting is used for selecting targets. The continuous zoom can be stopped at any level so that the user can use ray-casting. To zoom, users first have to roughly position the cursor over the region they intend to magnify. Once the zoom in button is pressed, the system starts to magnify the region of the screen around the cursor such that objects under the cursor remain in that position independent of the zoom level. While zooming, users can adjust the position of the cursor to change the region of the screen that they are zooming into. In order to minimize precision issues while zooming, this technique doubles magnification in both dimensions once per second, up to 256 x magnification. As with discrete zoom, users can choose to zoom out, and they have to decide how much magnification is needed, if any.” [1]','Allows to zoom into the environment continuously ',NULL,'Pointing/Vector-based','Selection','None','3D cursor (virtual cursor)\nTarget highlighting  (zoom)','Infinite','Single-handed','Hand','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection)\n2 Buttons (Zoom)',3,'-','None','Isomorph','None','None','None','Continuously','Manual','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:1 orientation-to-orientation','Press button',4.33333,4,5,4,5,5,3,'Mid-high'),(76,'Summoning Selection','In this technique, a ray is generated starting from the palm. The direction is determined by the shoulder (approximated by the head position) and the hand position. The ray snaps to nearby objects. The object is selection by closing the hand. The “summoning” is an additional step, where the user can curl the fingers to pull the objects towards her.','Uses a ray and gestures to select distant objects',NULL,'Pointing/Vector-based','Selection','Snap to object','3D cursor (virtual ray)\nAdopting cursor (ray bends to target)\nTarget highlighting  (change of color)\nAdopting cursor (ray changes color)','Infinite','Single-handed','Hand\nFingers','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'-','None','Isomorph','None','None','None','None','None','Gesture','None','Point at an object with a pointer ','Move and twist upper arm, forearm, hand and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:1 orientation-to-orientation','Grab object',5,5,5,5,5,5,5,'High'),(77,'EZCursorVR','“Like screen-based techniques  EZCursorVR uses ray-casting and relies on the concept of image plane selection. From the user’s perspective, they appear to select targets using a 2D cursor to overlap the 2D “screen-space” projection of targets. The plane the cursor resides in appears to be fixed to the head. Rotating or moving the head also results in cursor movement, although the cursor itself appears fixed in this plane. Unlike classical image-plane interaction, where the user can line up their hand with virtual objects for selection, our technique instead does this indirectly via an external controller that controls the cursor position, similar to desktop environments. In actuality, the rendered cursor is displayed in world-space at the intersection point of a ray originating at the head and directed towards an invisible control cursor that moves in a head-coupled plane. The control cursor is constrained to move from one extent of the user’s field of view to the other. The ray from the head to the control cursor is used to determine which object is selected, and where to position the rendered cursor.” [1]','Uses a 2D cursor projected on a plane in 3D space to select objects',NULL,'Pointing/Vector-based','Selection','None','3D cursor (point cursor)','Infinite','Single-handed','Hand','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection)',1,'-','None','Remapped','None','None','None','None','None','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:N orientation-and-position-to-position ','Press button',4,4,5,4,5,3,3,'Mid-high'),(78,'RayCursor',' RayCursor extends the Ray-Casting technique. A cursor is added to the ray, which can be manipulated by the user. A disambiguation strategy selects the closest target to the cursor. A non-isomorph transfer function is used to control the cursor. Filtering techniques are used to reduce the tremor effect.','Adds a controllable cursor to the ray and selects the object closest to the cursor',NULL,'Pointing/Vector-based','Selection','Snap to object','3D cursor (virtual ray)\nAdditional cursor (marker on ray)\nTarget highlighting  (change of color)','Infinite','Single-handed','Hand','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection)\n1 Scrollwheel (Marker position)',2,'-','None','Isomorph, \nRemapped','None','None','None','Discrete/Single step','Heuristic','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:N orientation-and-position-and-1DInput-to-position ','Press button',3.83333,4,5,4,5,2,3,'Mid-high'),(79,'Dynamic Scaling','Dynamic scaling increases the size of the objects near the ray. The further away the objects are from the ray, the less they are increased in size. ','Increases the size of the objects near the ray to support the selection',NULL,'Pointing/Vector-based','Selection','None','3D cursor (virtual ray)\nTarget highlighting  (change of color, change of size)','Infinite','Single-handed','Hand','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','None','None','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:1 orientation-to-orientation','Press button',4.33333,4,5,4,5,5,3,'Mid-high'),(80,'Forced Disocclusion','Forces disocclusion in a circular region around the intersection point of the ray and an object.  ','Forces disocclusion in a circular region around the intersection point of the ray and an object',NULL,'Pointing/Vector-based','Selection','None','3D cursor (virtual ray)\nTarget highlighting  (hide other objects)','Infinite','Single-handed','Hand','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','None','None','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:1 orientation-to-orientation','Press button',4.33333,4,5,4,5,5,3,'Mid-high'),(81,'Mesh-Grab','“In […] Mesh-grab, the user casts a ray from a handheld wand (Wiimote in our implementation). The ray intersects the mesh at some point. With the simultaneous press of buttons A+B (thumb and forefinger) the user can “skewer” the mesh at that point. While the buttons are pressed the mesh behaves as if the ray was a solid link that hinges on the mesh with freedom to move on one hemisphere, like a ball-point joint (Figure 4). Calculation of the behavior of the object is based on a constraint solver that ensures that, while the buttons are pressed, the acquired point always remains under the ray, at the same, locked, distance from the wand.” [1]','Allows to move and rotate an object like it is skewered by a ray',NULL,'Pointing/Vector-based','Selection\nPositioning\nRotation','DoF reduction','3D cursor (virtual ray)','Infinite','Single-handed','Hand','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection/Position Mode)\n1 Button (Selection/Rotation Mode)\n2 Buttons (Position Control)',4,'{P,R}, {P}, {R}','Full','Isomorph','Isomorph,\nRemapped','Remapped','None','None','None','On Button Press','On Button Release','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry, Rz), (Px, Py, Pz), (Rx, Ry, Rz)','1:N position-and-1DInput-to-position \n1:N orientation-and-position-to-orientation','Press button',3.66667,4,5,4,4,2,3,'Mid-high'),(82,'Arcball-3D','“The design rationale behind Arcball-3D was that for simple meshes, it would be easy to predict how the mesh would behave when hit with the ray and “pulled” or “pushed”, but for a complicated mesh with holes and extrusions the users might struggle to hit the mesh or manipulate it in the desired way. As such we hypothesized that a sphere bounding the mesh would result in an interaction that is more predictable and consistent across different mesh types. Arcball-3D works in exactly the same way as Mesh-Grab. The ray cast from the wand intercepts a sphere, one that tightly encloses the manipulated mesh. The interaction modalities available following acquisition of the sphere are identical to Mesh-Grab. Arcball-3D is fundamentally different from the original Arcball technique by Shoemake [15]. In the original Arcball, the screen location of the 2D cursor is projected onto a sphere and the resulting motion is an interpretation of the 2D mouse motion. In Arcball-3D the ray-sphere intersection is calculated from real 3D inputs and the resulting motion is not a result of mathematical interpretation. It’s the result of the actual motion, in 3D, of the intersection point. Unlike the original Arcball, in Arcball-3D the ray can be cast from an arbitrary point in 3D space and thus it is possible to achieve manipulation from skewed positions, as opposed to the original Arcball which only considers manipulation from the front.” [1]','Allows to move and rotate an object like the bounding sphere of it is skewered by a ray',NULL,'Pointing/Vector-based','Selection\nPositioning\nRotation','DoF reduction','3D cursor (virtual ray)\nTarget highlighting  (bounding sphere)','Infinite','Single-handed','Hand','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection/Position Mode)\n1 Button (Selection/Rotation Mode)\n2 Buttons (Position Control)',4,'{P,R}, {P}, {R}','Full','Isomorph','Isomorph,\nRemapped','Remapped','None','None','None','On Button Press','On Button Release','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry, Rz), (Px, Py, Pz), (Rx, Ry, Rz)','1:N position-and-1DInput-to-position \n1:N orientation-and-position-to-orientation','Press button',3.66667,4,5,4,4,2,3,'Mid-high'),(83,'Framing Hands','Framing Hands is an image plane selection technique where both hands are used. The hands are used to form the corners of an image frame. The selected object is determined by the ray, starting from the user\'s eyes and going through the midpoint of the hands.  ','Uses a framing hands gesture to select an object',NULL,'Pointing/Vector-based','Selection','None','No','Infinite','Symmetric-synchron','Hand\nFingers','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'-','None','Isomorph','None','None','None','Discrete/Single step','Heuristic','Gesture','None','Framing a object with the hands','Move and twist upper arm, forearm, hand and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz, Rx, Ry, Rz)','1:1 position-to-position \n1:1 position-to-orientation','None',5,5,5,5,5,5,5,'High'),(84,'iSith ','In this technique, two rays are used, one cast from each hand. The projected intersection point  (shortest point between both rays) can be used to select an object. When an object is selected it can be moved by translating the projected intersection point. ','Rays originate from both hands. The projected intersection point can be used to select and translate objects.',NULL,'Pointing/Vector-based','Selection\nPositioning','None','3D cursor (virtual rays)\nAdditional cursor (point cursor at closest intersection point of both rays)\nTarget highlighting  (change of color)','Infinite','Symmetric-synchron','First Hand \nSecond Hand ','(rX, rY)\n(rX, rY)','(x, y, z, rX, rY)\n(x, y, z, rX, rY)','Rotation','Position\nRotation','2 Button (Selection)',2,'{P}','None','Remapped','Remapped','None','None','None','None','Gesture','Gesture','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:N position-and orientation-to-position','Increase distance between rays',3.83333,4,5,4,5,3,2,'Mid-high'),(85,'Bimanual Fishing Reel + Scale','After selecting an object with a ray, it is attached to the ray which allows controlling the position of the object. Pressing the touchpad of the controller on the top or the bottom changes the length of the ray and therefore moves the object away or to the user. Scaling is possible by pressing the touchpad on the left or right. Additionally, while a button on the second controller is pressed its rotation is transferred to the rotation of the object. This technique is used in the application Engage.','Selection with a ray, positioning with the primary hand, changing distance and scale of the object with buttons and rotation with the secondary hand','The implementation of the technique used in the study generates a ray originating from the hand. The ray fades out at the end. Pressing the trigger attaches the object to the ray, which allows moving the object. Then the object can be scaled by pressing left or right on the touchpad. Pressing the top or bottom on the touchpad moves the object away or to the user. Pressing and holding the trigger of the secondary controller maps the rotation of the controller on the object. ','Pointing/Vector-based','Selection\nPositioning\nRotation\nScaling','None','3D cursor (virtual ray)\nTarget highlighting  (bounding box)','Infinite','Asymmetric-synchron','First Hand \nSecond Hand ','(rX, rY)\n(rX, rY)','(x, y, z, rX, rY)\n(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection)\n2 Buttons (Distance)\n2 Buttons (Scale)\n1 Button (Rotation)',6,'{P}, {P,S}, {P,R}, {P,S,R}','Partial','Isomorph','Remapped','Remapped','Remapped','None','None','On Button Press','On Button Press','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz), (Px, Py, Pz, S), (Px, Py, Pz, Rx, Ry, Rz, S)','1:N orientation-and-position-and-1DInput-to-position \n1:1 orientation-to-orientation\n1:N 1DInput-to-scale','Press button',3.33333,4,5,4,3,1,3,'Moderate'),(86,'Flexible Pointer','“The flexible pointer allows the user to point around objects with a curved arrow, to select fully or partially obscured objects, and to point out objects of interest more clearly to other users in a collaborative environment. […] We track hand position and orientation to control the length and curvature of our flexible pointer. Hand orientation determines the amount of curvature, and position is mapped to length. For increased precision and comfort, our current implementation uses twohanded control of the pointer, where the vector formed by the hands determines the pointer’s length and orientation, and the relative orientation determines the curvature” [1]','Allows the user to point around objects with a curved arrow',NULL,'Pointing/Vector-based','Selection','None','3D cursor (virtual ray)\nAdopting cursor (bending ray in dependence of controller movements)','Scaled','Asymmetric-synchron','First Hand \nSecond Hand ','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY)\n(x, y, z, rX, rY)','Position\nRotation','Position\nRotation','1 Button (Selection)',1,'-','None','Remapped','None','None','None','None','None','On Button Press','None','Point at an object with a pointer ','Move and twist upper arms, forearms, and hands (no fingers)','Moderate muscle forces','Upper arms, forearms, and hands','(Px, Py, Pz, Rx, Ry, Rz)','1:N position-to-position \n1:N orientation-and-position-to-orientation','Press button',3.33333,3,5,3,4,2,3,'Moderate'),(87,'Raycasting from the eye','This technique casts an invisible ray from the eyes. The object hit by the ray will be selected on a button press. A display ray is rendered originating from the hand and ending at the first intersection point of the selection ray with an object.','Uses a selection ray starting from the eyes instead of the hand to determine the selected object',NULL,'Pointing/Vector-based','Selection','None','3D cursor (virtual ray)','Infinite','Single-handed','First Hand \nSecond Hand ','(rX, rY)\n(x, y, z)','(x, y, z, rX, rY)\n(x, y, z)','Rotation\nPosition','Position\nRotation','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','None','None','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:1 orientation-to-orientation','Press button',4.33333,4,5,4,5,5,3,'Mid-high'),(88,'Flashlight','The flashlight technique works similarly to the Ray-Casting technique. However, a cone is displayed instead of a ray originating from the user\'s hand. Potentially multiple objects can fall into the cone. Therefore, when pressing a button the object is selected, which is the closest to the center of the cone.','Uses a cone and selects the objects closest to the center of the cone','The implementation of the technique used in the study generates a grey semi-transparent cone originating from the hand with a cone angle of 12.5 degrees and a length of 7 m. The object closest to the center of the cone is considered as the target object. Pressing the trigger selects this object','Pointing/Volume-based','Selection','Snap to object','3D cursor (cone)','Infinite','Single-handed','Hand','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','Discrete/Single step','Heuristic','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:1 orientation-to-orientation','Press button',4.33333,4,5,4,5,5,3,'Mid-high'),(89,'IntenSelect','The IntenSelect technique displays a ray originating from the hand and additionally generates an invisible cone. The objects inside the cone get a score based on the distance to the center of the cone.  The score is accumulated over time. A bent ray snaps to the object with the highest score. This object is selected when the user presses the selection button.','Uses a bent ray which snaps to the object the user most likely wants to select','The implementation of the technique used in the study uses an invisible cone with an angle of 15 degrees. Every object inside this cone is considered in the target calculation. A grey ray originating from the hand visualizes the pointing direction. If a target object is determined, a red bendable ray originating from the hand snaps to this object. The target object is calculated, as stated in the definition of IntenSelect. The following values are used for the constants used in the calculation: k = 4/5, c_s = 0.9 and c_g = 0.9.','Pointing/Volume-based','Selection','Snap to object','3D cursor (virtual rays)\nAdditional cursor (second bending ray in highest ranked object)\nAdopting cursor (second bending ray in highest ranked object)','Infinite','Single-handed','Hand','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','Continuously','Behavioural','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:1 orientation-to-orientation','Press button',4.33333,4,5,4,5,5,3,'Mid-high'),(90,'Guidance Ray','“[Guidance Rays] consists of one normal straight ray and two bendable rays with different colors (red line for straight ray, yellow line and blue line for two bendable rays respectively). […] Apart from one ordinary straight ray, it adopts two bendable rays to “guide” user\'s hand-held device to the specific targets. These specific targets are usually difficult to be selected in ambiguous situation, such as occluded or small/remote object. The normal straight ray uses traditional one-to-one mapping with the hand-held device. This straight ray, like other raycasting technique, points and selects target directly by intersecting the object. At the beginning of a selection task, the two bendable rays are rendered exactly overlapping with the straight ray. During a selection period, our algorithm records user’s behavior, and arranges all objects in the selection volume by evaluating the captivation ability between object and the guidance rays. After that, guidance rays will point toward the TOP2 objects with different colors respectively.” [1]','Extends Ray-Casting with two bendable rays snapping to possibly targeted objects',NULL,'Pointing/Volume-based','Selection','Snap to object','3D cursor (virtual rays)\nAdditional cursor (two bendable guidance rays)\nAdopting cursor (two bendable guidance rays)\nTarget highlighting (semitransparent sphere around intersected objects)','Infinite','Single-handed','Hand','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Main Ray Selection)\n2 Buttons (Bendable Ray selection)\n3 Buttons (Lock Mode Control)',6,'-','None','Isomorph','None','None','None','Discrete/Single step','Heuristic','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:1 orientation-to-orientation','Press button',4.33333,4,5,4,5,5,3,'Mid-high'),(91,'Shadow Cone Selection','“Shadow Cone is actually a group object selection technique, but it works in reverse. All the objects with a cone are selected, and as the user moves their hand only objects that are always within the cone are selected when the button is released.” [1]','A cone based technique selecting all objects that are always in the cone',NULL,'Pointing/Volume-based','Selection','None','3D cursor (cone)','Infinite','Single-handed','Hand','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','Continuously','Manual','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:1 orientation-to-orientation','Press button',4.33333,4,5,4,5,5,3,'Mid-high'),(92,'Enhanced Cone Selection','Enhanced Cone Selection is based on Shade Cone Selection. “Firstly fS is shaped like a cone where the scalar value depends on both angle from the centre ray and the distance from the ray origin. It is restricted to a 30o angle around the direction of pointing. This still allows us to use the shadow-cone like property of easy discard of objects by moving objects outside the boundary. An object’s influence is modeled as distance from the surface outside the object, and a constant inside the object. The constant value for inside the object is scaled by 1/√volume of object, thus small objects have a high constant, large ones a low constant. Figure 6 gives a simplified illustration where the scalar values have been banded. The aggregate relevance function takes in to account velocity, by making the scale of immediate relevance as 1/velocity. This would scaling need to account for jitter and error in the system. Our highlighting functions and final selection functions prioritize objects that are increasing in relevance and above a threshold. Final selection chooses just one object.” [1]','Extends Shadow Cone Selection by a disambiguation function',NULL,'Pointing/Volume-based','Selection','Snap to object','3D cursor (cone)','Infinite','Single-handed','Hand','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','Continuously','Behavioural','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:1 orientation-to-orientation','Press button',4.33333,4,5,4,5,5,3,'Mid-high'),(93,'Aperture Selection','“The aperture selection technique is a modification of the spotlight [(flashlight)] selection technique. In aperture selection, the apex of the conic selection volume, the from point, is set to the location of the participant’s dominant eye and the direction vector of the cone is the vector from that eye through the tracker’s location (represented in the VE by a cursor). The aperture cursor is a circle offixed radius and a crosshair that is aligned with the film plane (Figure 1). The size of the selection volume is determined by the distance between the eye point and the aperture cursor. A participant can adjust the scope of the selection by moving her hand in and out, thus changing this distance.” [1]','Uses a moveable aperture to modify the soze of the cone shaped selection volume',NULL,'Pointing/Volume-based','Selection','Snap to object','3D cursor (cone)','Infinite','Single-handed','Hand\nEyes','(rX, rY)\n(x, y, z)','(x, y, z, rX, rY)\n(x, y, z)','Rotation\nPosition','Position\nRotation','1 Button (Selection)',1,'-','None','Remapped','None','None','None','Discrete/Single step','Heuristic','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:1 position-to-orientation','Press button',4,4,5,4,5,3,3,'Mid-high'),(94,'Precious','“In order to support an Iterative Progressive Refinement strategy in VR for out-of-reach object selection, we developed PRE-CIOUS (Progressive REfinement using Cone-casting in Immersive virtual environments for OUt-of-reach object Selection). It offers Infinite Reach, using an egocentric virtual pointer metaphor. We use a cone as a selection volume, casted from users’ hand. While pointing, users can make the cone aperture wider or smaller, and change the cone’s reach. Objects that fall inside the cone will be selected. Users are then moved closer to the selected objects for a more accurate selection. As such, this can be considered as a possible VR implementation of Discrete Zoom, although we modify users’ position instead of the FoV. This process is repeated until a single object is selected or, if users desire, can be stopped at any time to select a group of objects, supporting both Single and Multiple Cardinality. To help users better understand which objects are inside the cone volume, our approach highlights them showing their bounding boxes as semi-transparent green cubes. In the following sections we detail how the selection process can be performed with PRECIOUS. We first describe how the cone can be manipulated, then we specify how the progressive refinement works, and how users can select multiple objects simultaneously.” [1]','Cone-based selection technique with a modifiable selection volume and a discrete multiple-step disambiguation technique',NULL,'Pointing/Volume-based','Selection','None','3D cursor (cone)\nWidget (widget with 3 regions for the cone reach with a marker indicating the current region)','Infinite','Single-handed','Hand','(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','Discrete/Multiple steps','Manual','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:1 orientation-to-orientation','Press button',4.33333,4,5,4,5,5,3,'Mid-high'),(95,'Marker Cone','“With marker cone, the user controls the cone direction to contain the target inside, and disambiguates the selection by moving a marker forward and backward along the cone center. The closest object in the cone to the marker is selected. The direction is controlled by moving the hand in a vertical plane, and the marker is controlled by moving the hand perpendicular to this 2D plane. […] The marker cone requires the user to move her hand continuously in 3D space to select the target, which means it is difficult to make the confirm gesture using the same hand. Any movement with this hand will change the marker position and selection. One advantage of freehand interaction is that the motion of both hands can be tracked. So to address this challenge, we introduce a ‘‘hands up’’ gesture performed with the other hand as confirmation. When the target is selected, the user can confirm the selection by raising her other hand. Thus, the user can control the marker cone with one hand without needing an extra movement of that hand as a confirmation gesture.” [1]','Cone-based selection technique using a moveable marker inside the cone to determine the target object',NULL,'Pointing/Volume-based','Selection','Snap to object','3D cursor (cone)\nTarget highlighting  (change of color)','Infinite','Asymmetric-asynchron','First Hand \nSecond Hand ','(x, y)\n(y)','(x, y, z, rX, rY)\n(y)','Position','Position\nRotation','None',0,'-','None','Isomorph','None','None','None','Continuously','Manual','Gesture','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:1 orientation-to-orientation','Gesture',4.33333,4,5,4,5,5,3,'Mid-high'),(96,'Menu Cone','“With the menu disambiguation method, after the selection confirmation a menu pops out with the selected objects as menu items, and the user disambiguates the target by a menu selection. As two selections are required, so two selection confirmation gestures are needed. The menu used in the disambiguation phase is normally designed as a marking menu for fast selection. As marking menus also have the potential to enable selection with just a directional action rather than a selection action followed by a confirmation action, we used a marking menu in the menu cone technique for freehand selection. To confirm the first cone selection, an extra action, e.g. button click, is typically used with hand held devices, however, as no handheld device is available in freehand gestural interaction, we cannot directly carry over these selection techniques. Similar to marker cone, the menu cone direction is controlled by moving the hand in an X–Y vertical plane. Thus, we use a quick hand movement perpendicular to this 2D plane along the Z dimension to confirm the first selection, as a ‘‘pull’’ or ‘‘push’’. We chose ‘‘pull’’ to confirm the initial selection because it aligns with the visual perception of the marking menu popping out towards the user. Users can cancel and go back with a ‘‘push’’ gesture in the reverse direction if they make a wrong selection. To confirm selection in a marking menu, a button click or finger touch/lift can be used to point to the menu item or specify the end point of the directional selection gesture. But again these methods cannot be used in freehand interaction, and we have to use hand motion. To determine the direction of the marking menu selection gesture, we use hand motion speed as the trigger: the user moves her hand in a direction, and the directional gesture end position is determined when the hand movement speed is faster than a threshold. The direction is then calculated using this end position and the hand position 0.1 s earlier. With this method, the marking menu selection and confirmation can be performed by a small, quick movement in the direction of the target.” [1]','Cone-based selection technique using a menu to select the target object',NULL,'Pointing/Volume-based','Selection','Snap to object','3D cursor (cone)\nTarget highlighting  (change of color)\nWidget (selection menu)','Infinite','Single-handed','Hand','(x, y, z)','(x, y, z, rX, rY)','Position','Position\nRotation','None',0,'-','None','Isomorph','None','None','None','Discrete/Multiple steps','Manual','Gesture','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:1 orientation-to-orientation','Gesture',4.33333,4,5,4,5,5,3,'Mid-high'),(97,'SenseShapes','“SenseShapes are volumetric primitives (spheres, cubes, cylinders, and cones) that we attach to the user (e.g., a pointing cone attached to the hand). Previous work in AR and VR has included selection of objects using rays or cones attached to the user’s hand and head and computing object intersections with these volumes, or has used the projection of a tracked point on a glove to perform selection on the image plane. In contrast, a SenseShape keeps a history of all objects in the scene that intersect it, and stores statistical data about these objects. Our statistical data currently provides us with five different rankings for an object, which are relative to a specific object’s behavior in a certain SenseShape during a time period.” [1] The rankings incorporate time, distance, stability, visibility and center-proximity. ','Uses volumetric primitives to select objects based on multiple ranking functions',NULL,'Pointing/Volume-based','Selection','Snap to object','3D cursor (cone or other volume)','Infinite','Single-handed','Hand','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','Continuously','Behavioural','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:1 orientation-to-orientation','Press button',4.33333,4,5,4,5,5,3,'Mid-high'),(98,'Probabilistic Pointing','“To deal with selection ambiguity, we designed a probabilistic selection algorithm that generates lists of candidate objects the user may have meant to select, and probability estimates of how likely it is the user meant to select each object. The algorithm combines several intersection algorithms and the hierarchical structure of the dataset, and then integrates the resulting candidate selections.” [1]','Uses a probabilistic selection algorithm to determine the target object',NULL,'Pointing/Volume-based','Selection','Snap to object','3D cursor (selection frustrum)','Infinite','Single-handed','Hand','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','Discrete/Single step','Heuristic','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:1 orientation-to-orientation','Press button',4.33333,4,5,4,5,5,3,'Mid-high'),(99,'SQUAD','“We designed a progressive refinement selection technique that falls in the middle of the gradualness continuum. It uses discrete progression, a combination of spatial and out-of-context refinement methods, and a combination of in-context and out-of-context display of the subset of selectable objects. […] The first step uses a modified version of ray-casting that casts a sphere onto the nearest intersecting surface to determine which objects will be selectable. We call this subtask sphere-casting. The user simply has to ensure that the desired object is inside or touching the sphere, so that it can be picked from among the other objects in the next phase. Items that will be made selectable are highlighted. In order to improve confidence that the desired object will be available, the sphere’s radius increases the farther the user is from the nearest intersecting surface, thus increasing the overall number of objects available in the second phase. […] Upon completion of the first phase, all objects that were inside or touching the sphere are evenly distributed among four quadrants on the screen, without regard for the spatial locations of the objects in the 3D environment. We call this the quad-menu, and note its similarity to marking menus. Contrary to zone menus, where breadth of selection is achieved by relative position of multiple marking gestures, in the quad menu phase users refine the selection by repeatedly pointing anywhere in the quadrant that contains the item they are looking for, each time reducing the number of objects per quadrant until the desired object is the only one left.” [1]','Uses a menu with four quadrants to manually determine the target objects in multiple steps',NULL,'Pointing/Volume-based','Selection','None','3D cursor (sphere)\nWidget (selection menu)','Infinite','Single-handed','Hand','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','Discrete/Multiple steps','Manual','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:1 orientation-to-orientation','Press button',4.33333,4,5,4,5,5,3,'Mid-high'),(100,'Expand','Expand is an interaction technique with two steps. At first, the user selects multiple objects with a cone-shaped cursor. These objects are then moved in front of the user and arranged in the form of a grid. The user can then select the target object.','Arranges all objects selected by a cone in front of the user and then allows the selection of the target object','The implementation of the technique used in the study generates a grey semi-transparent cone originating from the hand with a cone angle of 12.5 degrees and a length of 7 m. All objects inside of the cone are arranged as a grid in front of the user after pressing the trigger. The distance between the user and the grid is 50 cm. The technique tries to accomplish a grid with the same width and height. The place of an object in the grid depends on its distance to the center of the cone on selection. During the grid phase all other objects a semi-transparent. The transition time after selecting the objects for the grid phase is 0.5 s and the distance between the objects in the grid is 2.5 cm. In the grid phase, the object is selected, which is closest to the center of the cone. If only one object is inside the cone before the grid phase, then this object is selected directly. ','Pointing/Volume-based','Selection','None','3D cursor (sphere)\nWidget (3d selection menu)','Infinite','Single-handed','Hand','(rX, rY)','(x, y, z, rX, rY)','Rotation','Position\nRotation','1 Button (Selection)',1,'-','None','Isomorph','None','None','None','Discrete/Multiple steps','Manual','On Button Press','None','Point at an object with a pointer ','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:1 orientation-to-orientation','Press button',4.33333,4,5,4,5,5,3,'Mid-high'),(101,'Action-At-A-Distance (AAAD)','“During Action-At-A-Distance interaction, objects are selected via ray casting (depicted by a laser beam emanating from the user\'s hand). Once selected they can then be remotely manipulated by moving the user\'s hand (with the user\'s hand motion mapped to object motion) or by using the laser beam to interact with some form of control widgets.” [1]','Uses a ray for selecting an object and a virtual hand metaphor for moving the object absolutely to the user`s body',NULL,'Hybrid','Selection\nPositioning\nRotation','None','3D cursor (virtual ray)','Infinite','Single-handed','Hand','(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','1 Button (Selection)',1,'{P,R}','None','Isomorph','Isomorph','Isomorph','None','None','None','On Button Press','None','Point at an object with a pointer and then move and rotate the object with the hand','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry, Rz)','1:1 position-to-position \n1:1 orientation-to-orientation','Press button',4.33333,4,5,4,5,5,3,'Mid-high'),(102,'Direct HOMER','Uses a ray for selecting an object and a virtual hand metaphor for moving the object. “Object manipulation is done relative to the user’s body, instead of absolutely. The grabbed object’s position is determined by the vector from the user’s body to his hand, and the current distance of the object. Therefore, one can quickly place the object anywhere on a sphere surrounding the user at the current distance, while controlling object rotations independently. […] The direct HOMER technique maps the object-to-user distance onto the initial hand-to-user distance, so that positioning the hand twice as far from the body also places the object twice as far away. For more precise control and unbounded distances, the object may be reeled using mouse buttons as previously described, which we call indirect HOMER.” [1]','Uses a ray for selecting an object and a virtual hand metaphor for moving the object relatively to the user`s body',NULL,'Hybrid','Selection\nPositioning\nRotation','None','3D cursor (virtual ray)','Infinite','Single-handed','Hand','(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','1 Button (Selection)',1,'{P,R}','None','Isomorph','Target-oriented','Isomorph','None','None','None','On Button Press','On Button Release','Point at an object with a pointer and then move and rotate the object with the hand','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry, Rz)','1:1 position-to-position \n1:N position-to-position \n1:1 orientation-to-orientation','Press button',4.16667,4,5,4,5,4,3,'Mid-high'),(103,'Indirect HOMER','Uses a ray for selecting an object and a virtual hand metaphor for moving the object. “Object manipulation is done relative to the user’s body, instead of absolutely. The grabbed object’s position is determined by the vector from the user’s body to his hand, and the current distance of the object. Therefore, one can quickly place the object anywhere on a sphere surrounding the user at the current distance, while controlling object rotations independently. […] The direct HOMER technique maps the object-to-user distance onto the initial hand-to-user distance, so that positioning the hand twice as far from the body also places the object twice as far away. For more precise control and unbounded distances, the object may be reeled using mouse buttons as previously described, which we call indirect HOMER.” [1]','Uses a ray for selecting an object and a virtual hand metaphor for moving the object relatively to the user`s body and can be reeled by using buttons',NULL,'Hybrid','Selection\nPositioning\nRotation','None','3D cursor (virtual ray)','Infinite','Single-handed','Hand','(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','1 Button (Selection)\n2 Buttons (Distance)',3,'{P,R}','None','Isomorph','Remapped','Isomorph','None','None','None','On Button Press','On Button Release','Point at an object with a pointer and then move and rotate the object with the hand','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry, Rz)','1:N position-and-1DInput-to-position \n1:1 orientation-to-orientation','Press button',3.83333,4,5,4,5,2,3,'Mid-high'),(104,'Scaled HOMER','Scaled Homer is an extension of the homer technique. Therefore, it uses ray casting for selection and the virtual hand technique to manipulate objects. Additionally, slow movements of the real hand lead to even slower movements of the virtual hand. The scaling was introduced to compensate for the imprecise positioning of distant objects when using the HOMER technique.','Uses ray casting for selection and the Virtual Hand technique for manipulation. Additionally, scales translations to allow a more precise interaction','The implementation of the technique used in the study displays a whit ray originating from the hand. If the trigger is pressed and held while the ray hits an object, the object can be moved around. The translation of the object is scaled according to the definition of the technique. The following constants are used in the implementation for scaling the translation: minV = 0.01 m/s and SC = 1.5. ','Hybrid','Selection\nPositioning\nRotation','None','3D cursor (virtual ray)','Infinite','Single-handed','Hand','(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','1 Button (Selection)',1,'{P,R}','None','Isomorph','Target-oriented,\nVelocity-oriented','Isomorph','None','None','None','On Button Press','On Button Release','Point at an object with a pointer and then move and rotate the object with the hand','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry, Rz)','1:1 position-to-position \n1:N position-to-position \n1:1 orientation-to-orientation','Press button',4.16667,4,5,4,5,4,3,'Mid-high'),(105,'Scaled HOMER + Scale','Scaled HOMER + Scale is an extension of the Scaled HOMER technique. Therefore, it uses ray casting for selection and the virtual hand technique to manipulate objects. Slow movements of the real hand lead to even slower movements of the virtual hand. The scaling was introduced to compensate for the imprecise positioning of distant objects when using the HOMER technique. Additionally, pressing and holding a button on the secondary controller while am object is grabbed allows scaling the object. The distance between both hands influences the size of the object. Furthermore, in this technique, the rotation of objects is scaled. Slow rotations are further slowed down, and fast rotations are amplified. ','Uses ray casting for selection and the Virtual Hand technique for manipulation. Additionally, scales translations to allow a more precise interaction and enables scaling of objects by the distance between the hands','The implementation of the technique used in the study displays a whit ray originating from the hand. If the trigger is pressed and held while the ray hits an object, the object can be moved around. The translation of the object is scaled according to the definition of the technique. Additionally, the rotation of the object is scaled similarly. Furthermore, if the trigger of the second controller is pressed and held while an object is grabbed, the distance between the controller can be used to scale the object. The following constants are used in the implementation for scaling the translation: minV = 0.01 m/s and SC = 1.5. For scaling the rotation: minV = 3 degrees/s and SC = 30.','Hybrid','Selection\nPositioning\nRotation\nScaling','None','3D cursor (virtual ray)','Infinite','Asymmetric-synchron','Hand\nHand','(x, y, z, rX, rY, rZ)\n(x, y, z)','(x, y, z, rX, rY, rZ)\n(x, y, z)','Position\nRotation','Position\nRotation','1 Button (Selection)\n1 Button (Selection)',2,'{P,R}, {P,R,S}','Partial','Isomorph','Target-oriented,\nVelocity-oriented','Isomorph','Distance','None','None','On Button Press','On Button Release','Point at an object with a pointer and then move and rotate the object with the hand','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry, Rz), (Px, Py, Pz, Rx, Ry, Rz, S)','1:1 position-to-position \n1:N position-to-position \n1:N orientation-to-orientation\n1:1 distance-to-scale','Press button',3.83333,4,5,4,4,3,3,'Mid-high'),(106,'Scaled-World Grab','“The scaled-world grab technique is based on principles similar to HOMER. The user starts by selecting an object using some selection technique. In Mine’s implementation, an image-plane selection technique is used. After successful selection, the interface switches into manipulation mode, and the user can position and rotate the virtual object in space. However, instead of scaling the user’s hand motion, as in HOMER, the scaled-world grab technique scales down the entire VE around the user’s virtual viewpoint. The scaling coefficient is calculated so that the manipulated object is brought within the user’s area of reach and, therefore, can be manipulated using the simple virtual hand technique. An interesting property of this technique is that as long as the center of the scaling operation is the point midway between the user’s eyes, the user will often not even notice that scaling actually took place, because the world does not change visually.” [1]','Brings objects in reach of the user by scaling down the environment',NULL,'Hybrid','Selection\nPositioning\nRotation','None','3D cursor (virtual hand)','Scaled','Single-handed','Hand','(x, y, z, rX, rY)','(x, y, z, rX, rY)','Position\nRotation','Position\nRotation','None',0,'{P,R}','None','Isomorph','Target-oriented','Isomorph','None','None','None','Gesture','Gesture','Point at an object with a pointer and then move and rotate the object with the hand','Move and twist upper arm, forearm, and hand (no fingers)','Moderate muscle forces','Upper arm, forearm, and hand','(Px, Py, Pz, Rx, Ry, Rz)','1:1 position-to-position \n1:N position-to-position \n1:1 orientation-to-orientation','Release object',4.5,4,5,4,5,4,5,'High'),(107,'Seamless Remote and Close Range Interaction','This technique uses three states. “[…] 1) the user grabbed an object and is actually moving/dragging it, 2) the user is pointing, or 3) the system waits for a transition to any of the other two. […] For the user it simply means, when I point at an object and close my hand it gets draggable and can be moved (or selected, see below) as long as my hand is closed, or when my hand is close to an object and I close my hand it gets draggable as well. Both interactions are possible at all times. [… Two postures are used to switch between the states.] These postures are, either the hand is closed and all fingers of a hand are not extended (grabbing), or only the index finger is extended (pointing). All other hand posture are interpreted as no posture (none). Therefore, to grab a pointed at (focused) object, the user only has to move in the index finger to grab it and thus has not to open the hand and close it again to perform a complete grabbing gesture.” [1]','Uses Ray-Casting and the Virtual Hand technique simultaneously to select and move objects',NULL,'Hybrid','Selection\nPositioning','Snap to object','3D cursor (virtual ray)\nAdditional Cursor (virtual hand, point cursor)\nTarget highlighting  (change of color)','Infinite','Single-handed','Hand\nFingers','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{P,R}','None','Isomorph,\nArea-oriented','Isomorph','None','None','Discrete/Single step','Heuristic','On Button Press','On Button Release','Point at an object with a pointer and then move and rotate the object with the hand','Move and twist upper arm, forearm, hand and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz, Rx, Ry)','1:1 position-to-position \n1:N position-to-position\n1:1 orientation-to-orientation','Release object',4.83333,5,5,5,5,4,5,'High'),(108,'Grasping Object','”The technique starts in the idle mode and returns to it whenever the user opens his or her hand. In the idle mode the user can aim a virtual ray with his or her hand. When the ray intersects a point of the object, a blue sphere is drawn in this point. Subsequently, the user can grab the object by closing the hand. The virtual ray will disappear and the blue sphere will turn green to indicate the change to the transformation mode. Then, the object will be modified in translation and rotation according to the hand trajectory. The grabbed point will follow the trajectory of the hand […]. In order to facilitate the pointing of the virtual ray, its range is limited to the bounding box of the object. This technique manipulates translation and rotation simultaneously; however, it was not feasible for the users to precisely manipulate the object in this way. A previous study reported the same issue with the technique and added a translation-only mode; we proceeded likewise. Namely, if the selection ray intersects a translucent sphere centered in the object, the system changes to translation mode and only translation is modified. The diameter of the sphere is 30% of the object size and was chosen to be large enough to enable a good selection and sufficiently small to allow the user to grasp any corner of the object.” [1]','Uses two modes to either translate and rotate an object or to only translate it',NULL,'Hybrid','Selection\nPositioning\nRotation','None','3D cursor (virtual ray)\nAddition cursor (sphere)','Infinite','Single-handed','Hand\nFingers','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{P,R}, {P}',NULL,'Isomorph','Remapped','Isomorph','None','None','None','Gesture','Gesture','Point at an object with a pointer and then move and rotate the object with the hand','Move and twist upper arm, forearm, hand and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz, Rx, Ry, Rz), (Px, Py, Pz)','1:1 position-to-position \n1:1 orientation-to-orientation\n1:1 position-and-orientation-to-position ','Release object',4.5,5,5,5,4,3,5,'High'),(109,'GitDVR-G','”The GITDVR technique requires only one positioning tracking sensor to provide the selection and manipulation functions. In the GITDVR, the virtual hand penetrates into the object and the colour changes once the user makes the selection by closing his physical hand. In this case, the virtual hand does not visualise the grasping action. A grasping visual feedback has added to the GITDVR technique to provide a more natural feedback to the user, turning it into the GITDVR-G technique. The difference between the GITDVR and GITDVR-G is that the latter provides a grasping visual feedback during the selection, while the GITDVR does not. In addition, a GITDVR-G that has been enhanced with normal and precise manipulation functions by triggering it with hand gestures is known as a Precise GITDVR-G. A viewpoint in a virtual environment is important. An enlarged viewpoint around the object is helpful to the user in performing precise manipulations. Thus, the Precise GITDVR-G comes with an inset view to enlarge the surrounding view ofthe object to help the user to perform the precise manipulation task.” [1]','A ray is used to indicate the pointing direction. and the virtual hand automatically flies to the object hit by the ray',NULL,'Hybrid','Selection\nPositioning\nRotation','None','3D cursor (virtual hand)\nTarget highlighting  (change of color)','Infinite','Single-handed','Hand\nFingers','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{P,R}','None','Isomorph','Isomorph','Isomorph','None','None','None','Gesture','Gesture','Point at an object with a pointer and then move and rotate the object with the hand','Move and twist upper arm, forearm, hand and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz, Rx, Ry, Rz)','1:1 position-to-position \n1:1 orientation-to-orientation','Release object',5,5,5,5,5,5,5,'High'),(110,'Precise GITDVR-G','”The GITDVR technique requires only one positioning tracking sensor to provide the selection and manipulation functions. In the GITDVR, the virtual hand penetrates into the object and the colour changes once the user makes the selection by closing his physical hand. In this case, the virtual hand does not visualise the grasping action. A grasping visual feedback has added to the GITDVR technique to provide a more natural feedback to the user, turning it into the GITDVR-G technique. The difference between the GITDVR and GITDVR-G is that the latter provides a grasping visual feedback during the selection, while the GITDVR does not. In addition, a GITDVR-G that has been enhanced with normal and precise manipulation functions by triggering it with hand gestures is known as a Precise GITDVR-G. A viewpoint in a virtual environment is important. An enlarged viewpoint around the object is helpful to the user in performing precise manipulations. Thus, the Precise GITDVR-G comes with an inset view to enlarge the surrounding view ofthe object to help the user to perform the precise manipulation task. The Precise GITDVR-G has a similar process flow, except that it offers two manipulation modes, namely a normal manipulation and a precise manipulation mode. The main difference is during the manipulation process. When a user has selected a virtual object, an inset view appears at the top right corner of the display. The inset view follows the selected object to provide a clear view around it to the user. After the selection, the object can be manipulated directly by the virtual hand. The user is able to activate the precise manipulation mode using hand gestures” [1]','A ray is used to indicate the pointing direction, and the virtual hand automatically flies to the object hit by the ray. Additionally incorporates a precision mode.',NULL,'Hybrid','Selection\nPositioning\nRotation','None','3D cursor (virtual hand)\nTarget highlighting  (change of color)','Infinite','Single-handed','Hand\nFingers','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{P,R}','None','Isomorph','Target-oriented','Isomorph','None','None','None','Gesture','Gesture','Point at an object with a pointer and then move and rotate the object with the hand','Move and twist upper arm, forearm, hand and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz, Rx, Ry, Rz)','1:1 position-to-position \n1:1 orientation-to-orientation','Release object',5,5,5,5,5,5,5,'High'),(111,'Gaze-Supported Mid-Air Gestures','”The user looks at the object he wishes to select, pinch, move his hand to translate the object, and releases the pinch to disengage from the interaction.” [1]','The user looks at the object he wishes to select, pinch, move his hand to translate the object, and releases the pinch to disengage from the interaction',NULL,'Hybrid','Selection\nPositioning','None','None','Infinite','Single-handed','Eyes\nHand\nFingers','(rX, rY)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY)\n(x, y, z)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{P}','None','Isomorph','Isomorph','None','None','None','None','Gesture','Gesture','Gaze at an object and then move and rotate the object with the hand','Move and twist upper arm, forearm, hand, fingers and eyes','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz, Rx, Ry, Rz)','1:1 position-to-position \n1:1 orientation-to-orientation','Release object',5,5,5,5,5,5,5,'High'),(112,'Gaze + Pinch (Single-handed)','”Gaze + Pinch is an egocentric (first-person view) input method based on the virtual pointer metaphor (where the pointer is eye gaze). However, the manipulation is similar to direct manipulation— hence it inherits much of the characteristics of the virtual hand technique. […] Single-target interaction can be decomposed in three subtasks: (1) looking at the target, (2) pinching to select the target, and (3) spatial motion with the hand to manipulate it. The interaction finishes at pinch release. That the three sub tasks are cognitively phrased together [6], as users principally look at the target of interest with minimal cognitive effort, and the pinch gesture with follow-up manipulation is performed as one continuous action.” [1]','Uses the gaze and a pinch gesture to select an object and to translate it with hand movements',NULL,'Hybrid','Selection\nPositioning\nRotation','Snap to object','3D cursor (virtual hand)\nAdditional cursor (Ray)\nTarget highlighting  (change of color, bounding box)','Infinite','Single-handed','Eyes\nHand\nFingers','(rX, rY)\n(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY)\n(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{P,R}','None','Isomorph','Isomorph,\nArea-oriented','Isomorph','None','Discrete/Single step','Heuristic','Gesture','Gesture','Gaze at an object and then move and rotate the object with the hand','Move and twist upper arm, forearm, hand, fingers and eyes','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz, Rx, Ry, Rz)','1:N position-to-position \n1:1 orientation-to-orientation','Release object',4.83333,5,5,5,5,4,5,'High'),(113,'Gaze + Pinch (Bimanual)','”Gaze + Pinch is an egocentric (first-person view) input method based on the virtual pointer metaphor (where the pointer is eye gaze). However, the manipulation is similar to direct manipulation— hence it inherits much of the characteristics of the virtual hand technique. […] In bimanual UIs, each hand can be assigned the same role for symmetric manipulation. Gaze + Pinch supports this interaction by default through modal gestures. Pinching two hands will allow them to immediately connect with the viewed target and begin manipulation. The manipulation includes any integral or separate execution of the three canonical translation, rotate, and scale tasks similar to Turner et al.’s multitouch techniques [44].” [1]','Uses the gaze and a pinch gesture to select an object and translate, rotate and scale it with both hands',NULL,'Hybrid','Selection\nPositioning\nRotation\nScaling','Snap to object','3D cursor (virtual hand)\nTarget highlighting  (change of color, bounding box)','Infinite','Symmetric-synchron','Eyes\nHand\nFingers\nHand\nFingers','(rX, rY)\n(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY)\n(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{P,R,S}','None','Isomorph','Isomorph,\nArea-oriented','Isomorph','Isomorph','Discrete/Single step','Heuristic','Gesture','Gesture','Gaze at an object and then move and rotate the object with the hand','Move and twist upper arm, forearm, hand, fingers and eyes','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz, Rx, Ry, Rz, S)','1:N position-to-position \n1:1 orientation-to-orientation\n1:1 distance-to-scale','Release object',4.83333,5,5,5,5,4,5,'High'),(114,'Asymmetric Bimanual Gestural Interface','”In this design, users perform static hand gestures to interact with the environment. It is based on Guiard’s kinematic chain model, not in the way that objects are manipulated, but rather by the way interactions are initiated and completed by the hands. […] The left hand plays the role of a mode switcher and most of the direct manipulations are executed by the right hand. Hand gestures are executed by the left hand to select interaction modes, while the right hand performs the interaction itself, e.g. pointing, moving or scaling the desired object.”','The left hand determines the transformation mode, and the right hand executes the transformation',NULL,'Grasping/Finger-based','Selection\nPositioning\nRotation\nScaling','None','3D cursor (virtual hands)\nTarget highlighting  (change of color)','Infinite','Asymmetric-asynchron','First Hand\nFingers\nSecond Hand\nFingers','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)\n(x, y, z, rX, rY, rZ)','Position\nRotation','Position\nRotation','None',0,'{P,R},{R},{S}','Partial','Isomorph','Remapped','Remapped, Isomorph','Distance','None','None','Gesture','Gesture','Point at an object with a pointer and then move and rotate the object with the hand','Move and twist upper arm, forearm, hand and fingers','Moderate muscle forces','Upper arm, forearm, hand, and fingers','(Px, Py, Pz, Rx, Ry, Rz, S), (Rx, Ry, Rz), (S)','1:1 position-to-position \n1:1 orientation-to-position-and-orientation \n1:1 orientation-to-orientation \n1:1 distance-to-scale','Gesture',4,5,5,5,3,3,3,'Mid-high');
/*!40000 ALTER TABLE `techniques_new` ENABLE KEYS */;
UNLOCK TABLES;
/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;

/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;
/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;
/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;
/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;

-- Dump completed on 2020-11-26 13:15:32
